[ { "title": "graphcodebert+pairwise ensemble 0.8462", "url": "/posts/ai4code-cb-pw-ensemble/", "categories": "NLP, KAGGLE, AI4CODE", "tags": "nlp, kaggle, graphcodebert, pairwise, ensemble", "date": "2022-09-10 11:15:04 +0900", "snippet": "codebertì— model.from_pretrainedì—ì„œ, ë‹¨ìˆœíˆ codebertë¥¼ graphcodebertë¡œ ë°”ê¾¸ê³  pairwiseì˜ ê²°ê³¼ì™€ì˜ ë‹¨ìˆœ ê°€ì¤‘ì¹˜ ì•™ìƒë¸”Rank Ensembleìºê¸€ ë¦¬ë”ë³´ë“œì— ì € ë¹„ìœ¨ì„ ì“°ë”ë¼# Reading the submissionsdf_1 = pd.read_csv('submission1.csv')df_2 = pd.read_csv('submission2.csv')# Averaging the indices and sorting the resulting submission by the aggregated ensembled indicesnew_samples = []for sample_idx in range(len(df_1)): # {'0a226b6a': 0, ...} sample_1 = {k: v for v, k in enumerate(df_1.iloc[sample_idx]['cell_order'].split(' '))} sample_2 = {k: v for v, k in enumerate(df_2.iloc[sample_idx]['cell_order'].split(' '))} for key in sample_1: sample_1[key] = ((sample_1[key] * 0.748) + (sample_2[key] * 0.252)) new_samples.append(' '.join([i[0] for i in list(sorted(sample_1.items(), key = lambda x: x[1]))]))df_1['cell_order'] = new_samplesResultpublic: 0.8462private: 0.8410 (holy shitâ€¦)" }, { "title": "codebert(base) - [1md+20code]â€™s CLS ranking 0.8412", "url": "/posts/ai4code-codebert/", "categories": "NLP, KAGGLE, AI4CODE", "tags": "nlp, kaggle, codebert", "date": "2022-09-10 11:15:03 +0900", "snippet": "Preprocessê¸°ë³¸ì ì¸ ë°ì´í„° ì¶”ì¶œì€ baselineì˜ ê·¸ê²ƒê³¼ ê°™ë‹¤class Preprocessor: def __init__(self, **args): self.__dict__.update(args) self.data_dir = Path(self.input_path) def read_notebook(self, path): return ( pd.read_json(path, dtype={'cell_type': 'category', 'source': 'str'}) .assign(id=path.stem) .rename_axis('cell_id') ) def get_ranks(self, base, derived): return [base.index(d) for d in derived] def run(self, mode='train', nvalid=0.1): if os.path.exists(self.train_path) and os.path.exists(self.val_path): print('train_df, val_df are already exits') train_df = pd.read_csv(self.train_path) val_df = pd.read_csv(self.val_path) train_df_mark = pd.read_csv(self.train_mark_path) val_df_mark = pd.read_csv(self.val_mark_path) return train_df, val_df, train_df_mark, val_df_mark paths = list((self.data_dir / mode).glob('*.json')) notebooks = [self.read_notebook(path) for path in tqdm(paths, desc=f'{mode} NBs')] df = (pd.concat(notebooks) .set_index('id', append=True) .swaplevel() .sort_index(level='id', sort_remaining=False)) df_orders = pd.read_csv( self.data_dir / 'train_orders.csv', index_col='id', squeeze=True).str.split() df_orders_ = df_orders.to_frame().join( df.reset_index('cell_id').groupby('id')['cell_id'].apply(list), how='right' ) ranks = {} for id_, cell_order, cell_id in df_orders_.itertuples(): ranks[id_] = {'cell_id': cell_id, 'rank': self.get_ranks(cell_order, cell_id)} df_ranks = ( pd.DataFrame .from_dict(ranks, orient='index') .rename_axis('id') .apply(pd.Series.explode) .set_index('cell_id', append=True) ) df_ancestors = pd.read_csv( self.data_dir / 'train_ancestors.csv', index_col='id') df = df.reset_index().merge( df_ranks, on=['id', 'cell_id']).merge(df_ancestors, on=['id']) df['pct_rank'] = df['rank'] / \\ df.groupby('id')['cell_id'].transform('count') splitter = GroupShuffleSplit( n_splits=1, test_size=nvalid, random_state=0) train_ind, val_ind = next(splitter.split(df, groups=df['ancestor_id'])) train_df = df.loc[train_ind].reset_index(drop=True) val_df = df.loc[val_ind].reset_index(drop=True) train_df_mark = train_df[train_df['cell_type'] == 'markdown'].reset_index(drop=True) val_df_mark = val_df[val_df['cell_type'] == 'markdown'].reset_index(drop=True) train_df_mark.to_csv(self.train_mark_path + f'_fold{i}') val_df_mark.to_csv(self.val_mark_path + f'_fold{i}') train_df.to_csv(self.train_path + f'_fold{i}') val_df.to_csv(self.val_path + f'_fold{i}') return train_df, val_df, train_df_mark, val_df_markì—¬ê¸°ì— ì¶”ê°€ì ìœ¼ë¡œ ë…¸íŠ¸ë¶ ë‹¹ ìµœëŒ€ 20ê°œì˜ ì½”ë“œì…€ê³¼ ì½”ë“œ ì…€ ê°œìˆ˜, ë§ˆí¬ ë‹¤ìš´ ì…€ì˜ ê°œìˆ˜ë¥¼ ì¶”ì¶œclass _20CodeCellPreprocessor(Preprocessor): def __init__(self, **args): self.__dict__.update(args) super(_20CodeCellPreprocessor, self).__init__(**args) def clean_code(self, cell): return str(cell).replace('\\\\n', '\\n') def sample_cells(self, cells, n=20): cells = [self.clean_code(cell) for cell in cells] if n &gt;= len(cells): # ì½”ë“œ ì…€ì´ 20ê°œ ì´í•˜ë¼ë©´ ê·¸ëƒ¥ ë°˜í™˜ return [cell[:200] for cell in cells] else: results = [] step = len(cells) / n # ì´ 20ê°œì˜ ì½”ë“œì…€ì´ ìƒ˜í”Œë§ ë˜ë„ë¡ ìŠ¤í…ì„ ì¡°ì ˆ idx = 0 while int(np.round(idx) &lt; len(cells)): results.append(cells[int(np.round(idx))]) idx += step assert cells[0] in results # ì²«ë²ˆì¨° ì½”ë“œì…€ì€ ë°˜ë“œì‹œ ë“¤ì–´ê°€ì•¼ í•œë‹¤? if cells[-1] not in results: # ë§ì „ ì½”ë“œì…€ì€ ë°˜ë“œì‹œ ë“¤ì–´ê°€ì•¼ í•œë‹¤? results[-1] = cells[-1] return results def get_features(self, df): features = dict() df = df.sort_values('rank').reset_index(drop=True) for idx, sub_df in tqdm(df.groupby('id')): features[idx] = dict() total_md = sub_df[sub_df.cell_type == 'markdown'].shape[0] code_sub_df = sub_df[sub_df.cell_type == 'code'] total_code = code_sub_df.shape[0] codes = self.sample_cells(code_sub_df.source.values, 20) features[idx]['total_code'] = total_code features[idx]['total_md'] = total_md features[idx]['codes'] = codes # features = { # ë…¸íŠ¸ë¶id: { # 'total_code': ì½”ë“œ ì…€ì˜ ê°œìˆ˜, # 'total_md': ë§ˆí¬ë‹¤ìš´ ìƒì˜ ê°œìˆ˜, # 'codes': [ì½”ë“œì…€0, ì½”ë“œì…€1, ... , ì½”ë“œì…€ 19] # }, # ... # } return features def run(self): train_df, val_df, train_df_mark, val_df_mark = super().run() if os.path.exists(self.train_features_path) and os.path.exists(self.val_features_path): print('train_fts, val_fts are already exists') train_fts = json.load(open(self.train_features_path)) val_fts = json.load(open(self.val_features_path)) else: train_fts = self.get_features(train_df) val_fts = self.get_features(val_df) json.dump(train_fts, open(self.train_features_path,\"wt\")) json.dump(val_fts, open(self.val_features_path,\"wt\")) return train_df, val_df, train_df_mark, val_df_mark, train_fts, val_ftsDatasetBERTì— ì…ë ¥í•  ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ì„ ë§Œë“¤ì–´ì¤˜ì•¼ í•œë‹¤í•˜ë‚˜ì˜ ì…ë ¥ ì‹œí€€ìŠ¤ : [ë§ˆí¬ë‹¤ìš´ì…€ 1ê°œ, ì½”ë“œì…€ 0, ì½”ë“œì…€ 1, â€¦ , ì½”ë“œì…€ 19]class _20SampleDataset(Dataset): def __init__(self, df, model_name_or_path, total_max_len, md_max_len, fts): super().__init__() self.df = df.reset_index(drop=True) self.md_max_len = md_max_len self.total_max_len = total_max_len self.fts = fts self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path) def __getitem__(self, index): row = self.df.iloc[index] inputs = self.tokenizer.encode_plus( row.source, None, add_special_tokens=True, max_length=self.md_max_len, padding='max_length', return_token_type_ids=True, truncation=True ) code_inputs = self.tokenizer.batch_encode_plus( [str(x) for x in self.fts[row.id]['codes']], add_special_tokens=True, max_length=23, padding='max_length', truncation=True ) n_md = self.fts[row.id]['total_md'] n_code = self.fts[row.id]['total_code'] if n_md + n_code == 0: fts = torch.FloatTensor([0]) else: fts = torch.FloatTensor([n_md / (n_md + n_code)]) ids = inputs['input_ids'] for x in code_inputs['input_ids']: ids.extend(x[:-1]) ids = ids[:self.total_max_len] if len(ids) != self.total_max_len: ids = ids + [self.tokenizer.pad_token_id, ] * (self.total_max_len - len(ids)) ids = torch.LongTensor(ids) mask = inputs['attention_mask'] for x in code_inputs['attention_mask']: mask.extend(x[:-1]) mask = mask[:self.total_max_len] if len(mask) != self.total_max_len: mask = mask + [self.tokenizer.pad_token_id, ] * (self.total_max_len - len(mask)) mask = torch.LongTensor(mask) assert len(ids) == len(mask) return ids, mask, fts, torch.FloatTensor([row.pct_rank]) def __len__(self): return self.df.shape[0]Modelìœ„ ì…ë ¥ ì‹œí€€ìŠ¤ì˜ [cls]ì˜ í‘œí˜„ ë²¡í„°ë¥¼ ì¶”ì¶œclass _20SampleModel(nn.Module): def __init__(self, model_path): super(_20SampleModel, self).__init__() config = AutoConfig.from_pretrained(model_path) self.model = AutoModel.from_pretrained(model_path) self.dropout1 = nn.Dropout(0.1) self.dropout2 = nn.Dropout(0.2) self.dropout3 = nn.Dropout(0.3) self.dropout4 = nn.Dropout(0.4) self.dropout5 = nn.Dropout(0.5) self.top = nn.Linear(config.hidden_size+1, 1) # for train_fts def forward(self, ids, mask, fts, labels=None): x = self.model(ids, mask)[0] x = torch.cat((x[:, 0, :], fts), 1) # [CLS]ë§Œ ì“¸ê±°ì„. x1 = self.top(self.dropout1(x)) x2 = self.top(self.dropout2(x)) x3 = self.top(self.dropout3(x)) x4 = self.top(self.dropout4(x)) x5 = self.top(self.dropout5(x)) x = (x1 + x2 + x3 + x4 + x5) / 5 return xTrainí›ˆë ¨ ì‹œ í•„ìš”í•œ ê²ƒë“¤ ì„¸íŒ…def train_setup(args): model = _20SampleModel(model_path=args.model_name_or_path) param_optimizer = list(model.named_parameters()) no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight'] optimizer_grouped_parameters = [ {'params': [p for n, p in param_optimizer if not any( nd in n for nd in no_decay)], 'weight_decay': 0.01}, {'params': [p for n, p in param_optimizer if any( nd in n for nd in no_decay)], 'weight_decay': 0.0} ] num_train_optimization_steps = args.num_train_steps optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5, correct_bias=False) scheduler = ( CosineAnnealingWarmupRestarts( optimizer=optimizer, first_cycle_steps=num_train_optimization_steps, cycle_mult=1, max_lr=args.max_lr, min_lr=args.min_lr, warmup_steps=num_train_optimization_steps * 0.2, gamma=1., last_epoch=-1 )) # Pytorch scheduler # scheduler = get_linear_schedule_with_warmup( # optimizer=optimizer, # num_warmup_steps=0.05*num_train_optimization_steps, # num_training_steps=num_train_optimization_steps, # ) scaler = torch.cuda.amp.GradScaler() return model, optimizer, scheduler, scalerdef read_data(data): return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()def validate(model, val_loader): model.eval() tbar = tqdm(val_loader, file=sys.stdout, position=0, leave=True) preds = [] labels = [] with torch.no_grad(): for idx, data in enumerate(tbar): inputs, target = read_data(data) with torch.cuda.amp.autocast(): pred = model(*inputs) preds.append(pred.detach().cpu().numpy().ravel()) labels.append(target.detach().cpu().numpy().ravel()) return np.concatenate(labels), np.concatenate(preds)def train(model, train_loader, val_loader, optimizer, scheduler, scaler, val_df, df_orders, args): criterion = torch.nn.L1Loss() for e in range(args.epoch, 100): model.train() tbar = tqdm(train_loader, file=sys.stdout, position=0, leave=True) loss_list = [] preds = [] labels = [] for idx, data in enumerate(tbar): inputs, target = read_data(data) with torch.cuda.amp.autocast(): pred = model(*inputs) loss = criterion(pred, target) scaler.scale(loss).backward() if idx % args.accumulation_steps == 0 or idx == len(tbar) - 1: scaler.step(optimizer) scaler.update() optimizer.zero_grad() scheduler.step() loss_list.append(loss.detach().cpu().item()) preds.append(pred.detach().cpu().numpy().ravel()) labels.append(target.detach().cpu().numpy().ravel()) avg_loss = np.round(np.mean(loss_list), 4) tbar.set_description( f'Epoch {e+1} Loss: {avg_loss} lr: {scheduler.get_lr()}') y_val, y_pred = validate(model, val_loader) val_df['pred'] = val_df.groupby(['id', 'cell_type'])['rank'].rank(pct=True) val_df.loc[val_df['cell_type'] == 'markdown', 'pred'] = y_pred y_dummy = val_df.sort_values('pred').groupby('id')['cell_id'].apply(list) preds_score = kendall_tau(df_orders.loc[y_dummy.index], y_dummy) print(\"Preds score\", preds_score) if not os.path.exists(args.output_path): os.mkdir(args.output_path) torch.save(model.state_dict(), args.output_path + f'/model_epoch_{e}_{preds_score}.bin')Resultpublic score : 0.8412" }, { "title": "distillbert(small) - pairwise 0.8171", "url": "/posts/ai4code-pairwise/", "categories": "NLP, KAGGLE, AI4CODE", "tags": "nlp, kaggle, distillbert, pairwise", "date": "2022-09-10 11:15:02 +0900", "snippet": "Preprocessì´ê²ƒì €ê²ƒ ê±¸ëŸ¬ë‚´ê¸°class PairwisePreprocessor(Preprocessor): def __init__(self, **args): self.__dict__.update(args) super(PairwisePreprocessor, self).__init__(**args) nltk.download('wordnet') nltk.download('omw-1.4') self.stemmer = WordNetLemmatizer() def preprocess_text(self, document): # Remove all the special characters document = re.sub(r'\\W', ' ', str(document)) # remove all single characters document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document) # Remove single characters from the start document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) # Substituting multiple spaces with single space document = re.sub(r'\\s+', ' ', document, flags=re.I) # Removing prefixed 'b' document = re.sub(r'^b\\s+', '', document) # Converting to Lowercase document = document.lower() # return document # Lemmatization tokens = document.split() tokens = [self.stemmer.lemmatize(word) for word in tokens] tokens = [word for word in tokens if len(word) &gt; 3] preprocessed_text = ' '.join(tokens) return preprocessed_text def run(self): if os.path.exists(self.pairwise_train_path) and os.path.exists(self.pairwise_val_path): print('pairwise_train_df and val_df already exists') train_df = pd.read_csv(self.pairwise_train_path) val_df = pd.read_csv(self.pairwise_val_path) else: print('generate_train_df and val_df') train_df, val_df, _, _ = super().run() train_df.source = train_df.source.apply(self.preprocess_text) val_df.source = val_df.source.apply(self.preprocess_text) train_df.to_csv(self.pairwise_train_path) val_df.to_csv(self.pairwise_val_path) if os.path.exists(self.dict_cellid_source_path): dict_cellid_source = joblib.load(self.dict_cellid_source_path) else: df = pd.concat([train_df, val_df]) dict_cellid_source = dict(zip(df['cell_id'].values, df['source'].values)) joblib.dump(dict_cellid_source, self.dict_cellid_source_path) return train_df, val_df, dict_cellid_sourcePairwise datasetTripletpairwise ì´ë‹ˆ triplet:(ë¬¸ì¥ A, ë¬¸ì¥ B, isNext or notNext)ë“¤ì„ ì¤€ë¹„í•´ì¤€ë‹¤. ì‹¤í—˜ ê²°ê³¼ ìµœì  ë¹„ìœ¨ì€ True:False = 1:9ì´ê³ , 5:5ëŠ” ë°ì´í„°ì˜ ê°œìˆ˜ê°€ ë„ˆë¬´ ì ì–´ì§„ë‹¤.def generate_triplets(df, args, mode='train'): print(f'generate {mode} triplets') triplets = [] drop_sz = 1000 if args.debug else 10000 random_drop = np.random.random(size=drop_sz) &gt; .9 count = 0 for id, df_tmp in tqdm(df.groupby('id')): df_tmp_markdown = df_tmp[df_tmp['cell_type'] == 'markdown'] df_tmp_code = df_tmp[df_tmp['cell_type'] == 'code'] df_tmp_code_rank = df_tmp_code['rank'].values df_tmp_code_cell_id = df_tmp_code['cell_id'].values for cell_id, rank in df_tmp_markdown[['cell_id', 'rank']].values: # cell_idì˜ ë§ˆí¬ë‹¤ìš´ ë°”ë¡œ ë’¤ì— ë‚˜ì˜¤ëŠ” ì½”ë“œì…€ì´ë©´ True labels = np.array([(r == (rank+1)) for r in df_tmp_code_rank]).astype(int) for cid, label in zip(df_tmp_code_cell_id, labels): count += 1 if label == 1 or random_drop[count % drop_sz] or mode=='test': triplets.append([cell_id, cid, label]) return tripletsPairwise-datasetclass PairwiseDataset(Dataset): def __init__(self, df, args): self.df = df self.max_len = args.total_max_len self.tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path) self.dict_cellid_source = joblib.load(args.dict_cellid_source_path) def __getitem__(self, index): row = self.df[index] label = row[-1] txt = self.dict_cellid_source[row[0]] + \\ '[SEP]' + self.dict_cellid_source[row[1]] inputs = self.tokenizer.encode_plus( txt, None, add_special_tokens=True, max_length=self.max_len, padding='max_length', return_token_type_ids=True, truncation=True ) ids = torch.LongTensor(inputs['input_ids']) mask = torch.LongTensor(inputs['attention_mask']) return ids, mask, torch.FloatTensor([label]) def __len__(self): return len(self.df)í• ê±° í•˜ê³  ë°ì´í„° ë¡œë” ë°˜í™˜def pairwise_data_setup(train_df, val_df, args): train_triplets = generate_triplets(train_df, args, mode='train') # test ëª¨ë“œëŠ” dropì—†ì´ ë‹¤ ë•Œë ¤ë°•ê¸° ë•Œë¬¸ì— ë°ì´í„° ê°œìˆ˜ê°€ ë§ë‹¤. val_triplets = generate_triplets(val_df, args, mode='test') train_ds = PairwiseDataset(train_triplets, args) val_ds = PairwiseDataset(val_triplets, args) train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True, num_workers=8, pin_memory=False, drop_last=True) val_loader = DataLoader(val_ds, batch_size=args.batch_size, shuffle=False, num_workers=8, pin_memory=False, drop_last=False) return train_loader, val_loaderTrainí•™ìŠµì— í•„ìš”í•œ ì´ê²ƒì €ê²ƒ ì¤€ë¹„def pairwise_train_setup(args): model = PairwiseModel(model_path=args.model_name_or_path) num_train_optimization_steps = args.num_train_steps optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=3e-4, betas=(0.9, 0.999), eps=1e-8) # 1e-08) scheduler = get_linear_schedule_with_warmup( optimizer=optimizer, num_warmup_steps=0.05*num_train_optimization_steps, num_training_steps=num_train_optimization_steps, ) scaler = torch.cuda.amp.GradScaler() return model, optimizer, scheduler, scalertrain í•¨ìˆ˜ ë³¸ë¬¸ì´ì§„ ë¶„ë¥˜ ë¬¸ì œë¡œ ì¹˜í™˜í•˜ë©´ì„œ BCELossë¥¼ ì‚¬ìš©í•˜ê²Œ ë˜ì—ˆëŠ”ë°, BCELossëŠ” ampë¥¼ ëª»ì“´ë‹¤. ë”°ë¼ì„œ BCEwithLogitLossì¸ê°€ ë­”ê°€ ê·¸ê±¸ ì‚¬ìš©í•˜ê³ , ìœ„ ëª¨ë¸ ì•„ì›ƒí’‹ì—ë„ ì¢€ ì†ëŒ€ì„œ ampë¡œ ëŒë ¸ë‹¤. ë°”ê¾¼ ì½”ë“œëŠ” ì–´ë”¨ëŠ”ì§€ ê¹Œë¨¹ì—ˆê³ , ì°¾ê¸° ê·€ì°®ë‹¤. ì•„ë˜ ì½”ë“œë„ ì˜ ëŒì•„ê°„ë‹¤ (ëŒ€ì‹  ì˜¤ë˜ê±¸ë¦¼)def pairwise_train(model, train_loader, val_loader, optimizer, scheduler, scaler, val_df, df_orders, args): criterion = torch.nn.BCELoss() for e in range(args.epoch, args.epochs): model.train() tbar = tqdm(train_loader, file=sys.stdout, position=0, leave=True) loss_list = [] preds = [] labels = [] for idx, data in enumerate(tbar): inputs, target = read_data(data) # with torch.cuda.amp.autocast(): # pred = model(*inputs) # loss = criterion(pred, target) # scaler.scale(loss).backward() optimizer.zero_grad() pred = model(*inputs) loss = criterion(pred, target) loss.backward() # scaler.step(optimizer) # scaler.update() optimizer.step() scheduler.step() loss_list.append(loss.detach().cpu().item()) preds.append(pred.detach().cpu().numpy().ravel()) labels.append(target.detach().cpu().numpy().ravel()) avg_loss = np.round(np.mean(loss_list), 4) tbar.set_description( f\"Epoch {e+1} Loss: {avg_loss} lr: {scheduler.get_last_lr()}\") y_val, y_pred = pairwise_validate(model, val_loader) y_pred = get_preds(y_pred, val_df) val_df['pred'] = val_df.groupby(['id', 'cell_type'])['rank'].rank(pct=True) val_df.loc[val_df['cell_type'] == 'markdown', 'pred'] = y_pred y_dummy = val_df.sort_values('pred').groupby('id')['cell_id'].apply(list) print(\"Preds score\", kendall_tau(df_orders.loc[y_dummy.index], y_dummy)) if not os.path.exists(args.output_path): os.mkdir(args.output_path) torch.save({ 'epoch': e, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'scheduler_state_dict': scheduler.state_dict(), 'scaler_state_dict': scaler.state_dict(), }, args.output_path + f'/chekcpoint_{e}.pt') torch.save(model.state_dict(), args.output_path + f'/model_epoch_{e}.bin')Validatepairwise ì˜ˆì¸¡ìœ¼ë¡œ ìƒê¸´ ë¡œì§“ì„ ê°€ì§€ê³  ë‹¤ì‹œ ìˆœì„œë¥¼ ë§¤ê²¨ì•¼í•œë‹¤. ì¡°ê¸ˆ ê³¨ë•Œë¦¬ëŠ” ë¶€ë¶„. ì›ë³¸ ì½”ë“œ ì‘ì„±ìì˜ ë°©ë²•ê³¼ ë‹¤ë¥¸ ë°©ì‹ë„ ì´ê²ƒì €ê²ƒ ì‹œë„í•´ ë³´ì•˜ìœ¼ë‚˜ í° ì„±ëŠ¥í–¥ìƒì„ ëŠë¼ì§€ ëª»í•˜ì˜€ë‹¤.def validate(model, val_loader, mode='train'): model.eval() tbar = tqdm(val_loader, file=sys.stdout) preds = np.zeros(len(val_loader.dataset), dtype='float32') labels = [] count = 0 with torch.no_grad(): for idx, data in enumerate(tbar): inputs, target = read_data(data) pred = model(inputs[0], inputs[1]).detach().cpu().numpy().ravel() preds[count:count+len(pred)] = pred count += len(pred) if mode=='test': labels.append(target.detach().cpu().numpy().ravel()) if mode=='test': return preds else: return np.concatenate(labels), np.concatenate(preds)preds_copy = y_testpred_vals = []count = 0for id, df_tmp in tqdm(test_df.groupby('id')): df_tmp_mark = df_tmp[df_tmp['cell_type']=='markdown'] df_tmp_code = df_tmp[df_tmp['cell_type']!='markdown'] df_tmp_code_rank = df_tmp_code['rank'].rank().values N_code = len(df_tmp_code_rank) N_mark = len(df_tmp_mark) preds_tmp = preds_copy[count:count+N_mark * N_code] count += N_mark * N_code for i in range(N_mark): pred = preds_tmp[i*N_code:i*N_code+N_code] softmax = np.exp((pred-np.mean(pred)) *20)/np.sum(np.exp((pred-np.mean(pred)) *20)) rank = np.sum(softmax * df_tmp_code_rank) pred_vals.append(rank)del modeldel test_triplets[:]del dict_cellid_sourcegc.collect()Resultpublic score - 0.8171" }, { "title": "distillbert(small) - baseline 0.7499", "url": "/posts/ai4code-baseline/", "categories": "NLP, KAGGLE, AI4CODE", "tags": "nlp, kaggle, distillbert", "date": "2022-09-10 11:15:01 +0900", "snippet": "Load dataraw dataë¥¼ dataframeìœ¼ë¡œ ë°”ê¿”ì£¼ëŠ” í•¨ìˆ˜def get_df(data_dir, num_rows, folder='train'): paths_train = list((data_dir / folder).glob('*.json'))[:num_rows] notebooks_train = [ read_notebook(path) for path in tqdm(paths_train, desc='Train NBs') ] df = ( pd.concat(notebooks_train) .set_index('id', append=True) .swaplevel() .sort_index(level='id', sort_remaining=False) ) return dftrain datasetì˜ ì •ë‹µ (ë§ˆí¬ë‹¤ìš´ ì…€ì˜ ìˆœì„œ)ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜def get_df_orders(data_dir): df_orders = pd.read_csv( data_dir / 'train_orders.csv', index_col='id', squeeze=True ).str.split() return df_ordersì¸ìˆ˜ë¡œ ë°›ì•„ë“¤ì¸ dfì˜ ìˆœì„œë¥¼ êµ¬í•˜ëŠ” í•¨ìˆ˜def get_ranks(base, derived): return [base.index(d) for d in derived]def get_df_ranks(df, data_dir): df_orders = get_df_orders(data_dir) df_orders_ = df_orders.to_frame().join( df.reset_index('cell_id').groupby('id')['cell_id'].apply(list), how='right' ) ranks = {} for id_, cell_order, cell_id in df_orders_.itertuples(): ranks[id_] = {'cell_id': cell_id, 'rank': get_ranks(cell_order, cell_id)} df_ranks = ( pd.DataFrame .from_dict(ranks, orient='index') .rename_axis('id') .apply(pd.Series.explode) .set_index('cell_id', append=True) ) return df_rankstrain_datasetì˜ ë¶€ëª¨ ë…¸íŠ¸ë¶(fork from)ì„ êµ¬í•˜ëŠ” í•¨ìˆ˜def get_df_ancestors(data_dir): df_ancestors = pd.read_csv(data_dir / 'train_ancestors.csv', index_col='id') return df_ancestorsdfë¥¼ trainê³¼ validë¡œ ë‚˜ëˆ„ëŠ” í•¨ìˆ˜def get_df_train_valid(df, valid_size, random_state): NVALID = valid_size # size of validation set splitter = GroupShuffleSplit(n_splits=1, test_size=NVALID, random_state=0) train_ind, val_ind = next(splitter.split(df, groups=df[\"ancestor_id\"])) train_df = df.loc[train_ind].reset_index(drop=True) val_df = df.loc[val_ind].reset_index(drop=True) return train_df, val_dfëŒ€ì¶© ì „ì²˜ë¦¬í•˜ê³ , trainê³¼ validë¡œ ë‚˜ëˆˆë‹¤.from sklearn.model_selection import GroupShuffleSplitNUM_TRAIN = 10000df = get_df(data_dir, num_rows=NUM_TRAIN)# NUM_TRAIN = 10000df_orders = get_df_orders(data_dir)df_ranks = get_df_ranks(df, data_dir)df_ancestors = get_df_ancestors(data_dir)df = df.reset_index().merge(df_ranks, on=['id', 'cell_id']).merge(df_ancestors, on=['id'])df['pct_rank'] = df['rank'] / df.groupby('id')['cell_id'].transform('count')train_df, val_df = get_df_train_valid(df, valid_size=.1, random_state=0)train_df_mark = train_df[train_df['cell_type'] == 'markdown'].reset_index(drop=True)val_df_mark = val_df[val_df['cell_type'] == 'markdown'].reset_index(drop=True)Trainí”í•œ bert ëª¨ë¸ fine tuning ì˜ ëª¨ì˜¤ìŠµfrom torch.utils.data import Datasetclass MarkdownDataset(Dataset): def __init__(self, df, max_len, tokenizer): super().__init__() self.df = df.reset_index(drop=True) self.max_len = max_len self.tokenizer = tokenizer def __getitem__(self, index): row = self.df.iloc[index] inputs = self.tokenizer.encode_plus( row.source, None, add_special_tokens=True, max_length=self.max_len, padding='max_length', return_token_type_ids=True, truncation=True ) ids = torch.LongTensor(inputs['input_ids']) mask = torch.LongTensor(inputs['attention_mask']) return ids, mask, torch.FloatTensor([row.pct_rank]) def __len__(self): return self.df.shape[0]class MarkdownModel(nn.Module): def __init__(self, distill_bert): super(MarkdownModel, self).__init__() self.distill_bert = distill_bert self.top = nn.Linear(768, 1) def forward(self, ids, mask): # (32, 128, 768) x = self.distill_bert(ids, mask)[0] # (32, 1, 768): [CLS] x = self.top(x[:, 0, :]) return xfrom torch.utils.data import DataLoaderBS = 32NW = 8MAX_LEN = 128# 1.Get bert &amp; tokenizerdistill_bert = DistilBertModel.from_pretrained(BERT_PATH)tokenizer = DistilBertTokenizer.from_pretrained(BERT_PATH, do_lower_case=True)# 2.Get Datasettrain_ds = MarkdownDataset(train_df_mark, max_len=MAX_LEN, tokenizer=tokenizer)val_ds = MarkdownDataset(val_df_mark, max_len=MAX_LEN, tokenizer=tokenizer)# 3.Get DataLoadertrain_loader = DataLoader(train_ds, batch_size=BS, shuffle=True, num_workers=NW, pin_memory=False, drop_last=True)val_loader = DataLoader(val_ds, batch_size=BS, shuffle=False, num_workers=NW, pin_memory=False, drop_last=False)ê°„ë‹¨í•œ ìŠ¤ì¼€ì¤„ëŸ¬, ì˜µí‹°ë§ˆì´ì € ë“±ë“± í•„ìš”í•œ í•¨ìˆ˜ì™€ validate ë° train í•¨ìˆ˜from sklearn.metrics import mean_squared_errordef adjust_lr(optimizer, epoch): if epoch &lt; 1: lr = 5e-5 elif epoch &lt; 2: lr = 1e-3 elif epoch &lt; 3: lr = 1e-4 else: lr = 1e-5 for p in optimizer.param_groups: p['lr'] = lr return lrdef get_optimizer(net): optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=3e-4, betas=(.9, .999), eps=1e-08) return optimizer# divide input and target from train_loaderdef read_data(data): return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()def validate(model, val_loader): model.eval() tbar = tqdm(val_loader, file=sys.stdout) preds = [] labels = [] with torch.no_grad(): for idx, data in enumerate(tbar): inputs, target = read_data(data) pred = model(inputs[0], inputs[1]) preds.append(pred.detach().cpu().numpy().ravel()) labels.append(target.detach().cpu().numpy().ravel()) return np.concatenate(labels), np.concatenate(preds)def train(model, train_loader, val_loader, epochs): np.random.seed(0) optimizer = get_optimizer(model) criterion = torch.nn.MSELoss() for e in range(epochs): model.train() tbar = tqdm(train_loader, file=sys.stdout) lr = adjust_lr(optimizer, e) loss_list = [] preds = [] labels = [] for idx, data in enumerate(tbar): # inputs = (ids, mask) # target = torch.FloatTensor([row.pct_rank]) inputs, target = read_data(data) optimizer.zero_grad() pred = model(inputs[0], inputs[1]) loss = criterion(pred, target) loss.backward() optimizer.step() loss_list.append(loss.detach().cpu().item()) preds.append(pred.detach().cpu().numpy().ravel()) labels.append(target.detach().cpu().numpy().ravel()) avg_loss = np.round(np.mean(loss_list), 4) tbar.set_description(f'Epoch {e+1} Loss: {avg_loss} lr: {lr}') y_val, y_pred = validate(model, val_loader) print('Validation MSE: ', np.round(mean_squared_error(y_val, y_pred), 4)) print() return model, y_predmodel = MarkdownModel(distill_bert)model = model.cuda()model, y_pred = train(model, train_loader, val_loader, epochs=1)Epoch 1 Loss: 0.0584 lr: 5e-05: 100% 4439/4439 [14:54&lt;00:00, 5.25it/s]100% 461/461 [00:41&lt;00:00, 16.33it/s]Validation MSE: 0.051Evaluatefrom bisect import bisectdef count_inversions(a): inversions = 0 sorted_so_far = [] for i, u in enumerate(a): j = bisect(sorted_so_far, u) inversions += i - j sorted_so_far.insert(j, u) return inversionsdef kendall_tau(ground_truth, predictions): total_inversions = 0 total_2max = 0 # twice the maximum possible inversions across all instances for gt, pred in zip(ground_truth, predictions): ranks = [gt.index(x) for x in pred] # rank predicted order in terms of ground truth total_inversions += count_inversions(ranks) n = len(gt) total_2max += n * (n - 1) return 1 - 4 * total_inversions / total_2maxval_df['pred'] = val_df.groupby(['id', 'cell_type'])['rank'].rank(pct=True)val_df.loc[val_df['cell_type'] == 'markdown', 'prde'] = y_predy_dummy = val_df.sort_values('pred').groupby('id')['cell_id'].apply(list)kendall_tau(df_orders.loc[y_dummy.index], y_dummy)0.9221784760258563test_df = get_df(data_dir, num_rows=None, folder='test').reset_index()test_df[\"rank\"] = test_df.groupby([\"id\", \"cell_type\"]).cumcount()test_df[\"pred\"] = test_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)test_df[\"pct_rank\"] = 0test_ds = MarkdownDataset(test_df[test_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True), max_len=MAX_LEN, tokenizer=tokenizer)test_loader = DataLoader(test_ds, batch_size=BS, shuffle=False, num_workers=NW, pin_memory=False, drop_last=False)len(test_ds), test_ds[0]Train NBs: 100% 4/4 [00:00&lt;00:00, 44.16it/s](43, (tensor([ 101, 1001, 25169, 2951, 100, 2292, 1005, 1055, 4094, 1996, 2951, 2061, 7473, 2050, 2064, 2022, 4162, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), tensor([0.])))_, y_test = validate(model, test_loader)100% 2/2 [00:01&lt;00:00, 1.13it/s]test_df.loc[test_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_testtest_dfSubmitsub_df = test_df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()sub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)sub_df.head()ResultRun: 1068.6s - GPUPublic score : 0.7499Link" }, { "title": "Google AI4Code", "url": "/posts/ai4code/", "categories": "NLP, KAGGLE, AI4CODE", "tags": "nlp, kaggle", "date": "2022-09-10 11:15:00 +0900", "snippet": "Overviewì´ ëŒ€íšŒì˜ ëª©ì ì€ íŒŒì´ì¬ (ì£¼í”¼í„°) ë…¸íŠ¸ë¶ì˜ ì½”ë“œì™€ ì½”ë©˜íŠ¸ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ ì´í•´í•˜ëŠ” ê²ƒì´ë‹¤. ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ë…¸íŠ¸ë¶ì˜ ì½”ë“œì…€ì˜ ìˆœì„œì— ë”°ë¼, ì–´ë–¤ ìì—°ì–´ê°€ ì½”ë“œì™€ ì—°ê´€ë˜ëŠ”ì§€ íŒŒì•…í•˜ì—¬ ë§ˆí¬ë‹¤ìš´ ì…€ì˜ ìˆœì„œë¥¼ ì¬êµ¬ì„± í•´ì•¼í•œë‹¤.Contextêµ¬ê¸€ê³¼ ì•ŒíŒŒë²³ì˜ ë¦¬ì„œì¹˜ íŒ€ì€ ë¨¸ì‹ ëŸ¬ë‹ì´ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œìë“¤ì„ ë³´ì¡°í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ë°©ë²•ì„ ì°¾ê³ ìˆìœ¼ë©°, ë” ë§ì€ ê°œë°œì ì»¤ë®¤ë‹ˆí‹°ì˜ êµ¬ì„±ì›ë“¤ì´ ì´ ë¶„ì•¼ë¥¼ íƒí—˜í•˜ëŠ” ê²ƒì„ ë•ê³  ì‹¶ì–´í•œë‹¤. íŒŒì´ì¬ ë…¸íŠ¸ë¶ì€ ë§ì€ í‘œì¤€ ì†ŒìŠ¤ ì½”ë“œì™€ ë‹¬ë¦¬ ì„œìˆ í˜• í˜•ì‹ì„ ë”°ë¥´ëŠ” ê²½ìš°ê°€ ë§ìœ¼ë©°, í•´ë‹¹ ì½”ë“œ ì…€ì— ëŒ€í•œ í”„ë¡œê·¸ë˜ë¨¸ì˜ ì˜ë„ë¥¼ ì„¤ëª…í•˜ëŠ” ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ êµ¬í˜„ëœ ì£¼ì„ ì…€ì´ ìˆê¸° ë•Œë¬¸ì—, ì¢‹ì€ í•™ìŠµê¸°íšŒë¥¼ ì œê³µí•œë‹¤. ì½”ë“œì™€ ë§ˆí¬ë‹¤ìš´ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ ì´í•´í•˜ë©´ ëª¨ë¸ í•™ìŠµì„ ìœ„í•œ ë” ë‚˜ì€ ë°ì´í„° í•„í„°ë§ ë° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì˜ êµ¬ì¶• ë˜ëŠ” ë…¸íŠ¸ë¶ì˜ ê°€ë…ì„±ì— ëŒ€í•œ ìë™ í‰ê°€ì™€ ê°™ì€ AI ë³´ì¡° ê°œë°œì˜ ë§ì€ ì¸¡ë©´ì— ìƒˆë¡œìš´ ê°œì„ ì„ ì œê³µí•  ìˆ˜ ìˆë‹¤.Metricsfrom bisect import bisectdef count_inversions(a): inversions = 0 sorted_so_far = [] for i, u in enumerate(a): j = bisect(sorted_so_far, u) inversions += i - j sorted_so_far.insert(j, u) return inversionsdef kendall_tau(ground_truth, predictions): total_inversions = 0 total_2max = 0 # twice the maximum possible inversions across all instances for gt, pred in zip(ground_truth, predictions): ranks = [gt.index(x) for x in pred] # rank predicted order in terms of ground truth total_inversions += count_inversions(ranks) n = len(gt) total_2max += n * (n - 1) return 1 - 4 * total_inversions / total_2maxSubmission Fileí…ŒìŠ¤íŠ¸ ì…‹ì˜ ê° ë…¸íŠ¸ë¶ id ë³„ë¡œ, cell_order ì»¬ëŸ¼ì„ ì˜ˆì¸¡í•´ì•¼ í•˜ë©°, ì´ ì…€ë“¤ì˜ ì˜¬ë°”ë¥¸ ìˆœì„œëŠ” cell idsì˜ ì¸¡ë©´ì—ì„œì—¬ì•¼ í•œë‹¤. ì´ íŒŒì¼ì€ ë‹¤ìŒê³¼ ê°™ì€ ë¨¸ë¦¿ë§ì„ í¬í•¨í•´ì•¼ í•˜ë©° ë‹¤ìŒì˜ í˜•ì‹ì„ ë”°ë¼ì•¼ í•œë‹¤.ğŸ’¡ id,cell_order0009d135ece78d,ddfd239c c6cd22db 1372ae9b ...0010483c12ba9b,54c7cab3 fe66203e 7844d5f8 ...0010a919d60e4f,aafc3d23 80e077ec b190ebb4 ...0028856e09c5b7,012c9d02 d22526d1 3ae7ece3 ...etc." }, { "title": "BERT ì‚¬ì „í•™ìŠµ", "url": "/posts/bert-pretrain/", "categories": "NLP, BERT", "tags": "nlp, bert", "date": "2022-09-09 12:40:00 +0900", "snippet": "ì´ ì ˆì—ì„œëŠ” BERTë¥¼ ì‚¬ì „í•™ìŠµ ì‹œí‚¤ëŠ” ë°©ë²•ì„ ì•Œì•„ë³¸ë‹¤. ê·¸ëŸ°ë° ì‚¬ì „ í•™ìŠµì´ë€ ë¬´ì—‡ì¼ê¹Œ? ëª¨ë¸ì„ í•˜ë‚˜ í•™ìŠµì‹œì¼œì•¼ ëœë‹¤ê³  ê°€ì •í•´ë³´ì. ì¼ë‹¨ íŠ¹ì • íƒœìŠ¤í¬ì— ëŒ€í•œ ë°©ëŒ€í•œ ë°ì´í„°ì…‹ìœ¼ë¡œ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê³  í•™ìŠµëœ ëª¨ë¸ì„ ì €ì¥í•œë‹¤. ê·¸ ë‹¤ìŒìœ¼ë¡œ, ìƒˆ íƒœìŠ¤í¬ê°€ ì£¼ì–´ì§€ë©´ ì„ì˜ ê°€ì¤‘ì¹˜ë¡œ ëª¨ë¸ì„ ì´ˆê¸°í™”í•˜ëŠ” ëŒ€ì‹  ì´ë¯¸ í•™ìŠµëœ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¡œ ëª¨ë¸ì„ ì´ˆê¸°í™”í•œë‹¤. ì¦‰, ëª¨ë¸ì´ ì´ë¯¸ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì—ì„œ í•™ìŠµë˜ì—ˆìœ¼ë¯€ë¡œ ìƒˆ íƒœìŠ¤í¬ë¥¼ ìœ„í•´ ìƒˆë¡œìš´ ëª¨ë¸ë¡œ ì²˜ìŒë¶€í„° í•™ìŠµì‹œí‚¤ëŠ” ëŒ€ì‹  ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê³  ìƒˆë¡œìš´ íƒœìŠ¤í¬ì— ë”°ë¼ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •í•œë‹¤. ì´ëŸ° ë°©ì‹ì´ ì‚¬ì „í•™ìŠµì˜ ëŒ€í‘œì ì¸ ìœ í˜•ì´ë‹¤.BERTëŠ” MLMê³¼ NSPë¼ëŠ” ë‘ ê°€ì§€ ì¬ë¯¸ìˆëŠ” íƒœìŠ¤í¬ë¥¼ ì´ìš©í•´ ê±°ëŒ€í•œ ë§ë­‰ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ì „ í•™ìŠµëœë‹¤. ì‚¬ì „ í•™ìŠµ í›„ ì‚¬ì „ í•™ìŠµëœ BERTë¥¼ ì €ì¥í•´ë‘ê³ , ìƒˆë¡œìš´ íƒœìŠ¤í¬ê°€ ì£¼ì–´ì§ˆ ê²½ìš° BERTë¥¼ ì²˜ìŒë¶€í„° í•™ìŠµì‹œí‚¤ëŠ” ëŒ€ì‹  ì‚¬ì „ í•™ìŠµëœ BERTë¥¼ ì‚¬ìš©í•œë‹¤. ì¦‰, ì‚¬ì „ í•™ìŠµëœ BERTë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒˆ íƒœìŠ¤í¬ì— ëŒ€í•œ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì • (íŒŒì¸ íŠœë‹)í•œë‹¤.ì´ì œ BERTê°€ ì–´ë–»ê²Œ ì‚¬ì „ í•™ìŠµë˜ëŠ”ì§€ ìì„¸íˆ ì•Œì•„ë³¼ ê²ƒì´ë‹¤. ê·¸ì „ì— ë¨¼ì € BERTê°€ í—ˆìš©í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì…ë ¥ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”í•˜ëŠ” ë°©ë²•ë¶€í„° ì‚´í´ë³´ì.2.4.1 BERTì˜ ì…ë ¥ í‘œí˜„BERTì— ë°ì´í„°ë¥¼ ì…ë ¥í•˜ê¸° ì „ì— ë‹¤ìŒ ì„¸ ê°€ì§€ ì„ë² ë”© ë ˆì´ì–´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì…ë ¥ ë°ì´í„°ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•œë‹¤. í† í° ì„ë² ë”© (token embedding) ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© (segment embedding) ìœ„ì¹˜ ì„ë² ë”© (position embedding)í† í° ì„ë² ë”©ë¨¼ì €, í† í° ì„ë² ë”© ë ˆì´ì–´ ì°¨ë¡€ë‹¤. ë‹¤ìŒ ë‘ ë¬¸ì¥ìœ¼ë¡œ ì‚´í´ë³´ì. A ë¬¸ì¥: Paris is a beautiful city. B ë¬¸ì¥: I love Paris.ë¨¼ì € ì—¬ê¸°ì— í‘œì‹œëœ ê²ƒì²˜ëŸ¼ ë‘ ë¬¸ì¥ ëª¨ë‘ í† í°í™”í•´ í† í°ë“¤ì„ ì¶”ì¶œí•œë‹¤. ì´ ì˜ˆì—ì„œëŠ” í† í°ì„ ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ì§€ ì•Šì„ ê²ƒì´ë‹¤.ë‹¤ìŒìœ¼ë¡œ, ì²« ë²ˆì§¸ ë¬¸ì¥ì˜ ì‹œì‘ ë¶€ë¶„ì—ë§Œ [CLS] í† í°ì´ë¼ëŠ” ìƒˆ í† í°ì„ ì¶”ê°€í•œë‹¤.tokens = [\"[CLS]\", \"Paris\", \"is\", \"a\", \"beautiful\", \"city\", \"I\", \"love\", \"Paris\"]ê·¸ëŸ° ë‹¤ìŒ ëª¨ë“  ë¬¸ì¥ ëì— [SEP]ë¼ëŠ” ìƒˆ í† í°ì„ ì¶”ê°€í•œë‹¤.tokens = [\"[CLS]\", \"Paris\", \"is\", \"a\", \"beautiful\", \"city\", \"[SEP]\", \"I\", \"love\", \"Paris\", \"[SEP]\"][CLS] í† í°ì€ ì²« ë²ˆì§¸ ë¬¸ì¥ì˜ ì‹œì‘ ë¶€ë¶„ì—ë§Œ ì¶”ê°€ë˜ê³  [SEP] í† í°ì€ ëª¨ë“  ë¬¸ì¥ì˜ ëì— ì¶”ê°€í•œë‹¤. [CLS] í† í°ì€ ë¶„ë¥˜ ì‘ì—…ì— ì‚¬ìš©ë˜ë©° [SEP] í† í°ì€ ëª¨ë“  ë¬¸ì¥ì˜ ëì„ ë‚˜íƒ€ë‚´ëŠ” ë° ì‚¬ìš©ëœë‹¤. ì´ ë‘ ìŠ¤í˜ì…œ í† í°ì¸ [CLS]ì™€ [SEP]ê°€ ì–´ë–¤ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•˜ëŠ”ì§€ ì´ ì¥ì—ì„œ ìì„¸íˆ ì•Œì•„ë³¼ ê²ƒì´ë‹¤.ì´ì œ ëª¨ë“  í† í°ì„ BERTì— ì…ë ¥í•˜ê¸° ì „ì— í† í° ì„ë² ë”©ì´ë¼ëŠ” ì„ë² ë”© ë ˆì´ì–´ë¥¼ ì‚¬ìš©í•´ í† í°ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•œë‹¤. í† í° ì„ë² ë”©ì˜ ë³€ìˆ˜ë“¤ì€ ì‚¬ì „í•™ìŠµì´ ì§„í–‰ë˜ë©° í•™ìŠµëœë‹¤. [ê·¸ë¦¼ 2-8]ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ ëª¨ë“  í† í°ì— ëŒ€í•œ ì„ë² ë”©ì´ ìˆë‹¤. ì¦‰, $E_{cls}$ëŠ” [CLS] í† í°ì˜ ì„ë² ë”©ì„ ë‚˜íƒ€ë‚´ë©°, $E_{paris}$ëŠ” Paris í† í°ì˜ ì„ë² ë”©ì„ ë‚˜íƒ€ë‚¸ë‹¤. ê·¸ë¦¼ 2-8 í† í° ì„ë² ë”©ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”©ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”©ì€ ì£¼ì–´ì§„ ë‘ ë¬¸ì¥ì„ êµ¬ë³„í•˜ëŠ” ë° ì‚¬ìš©ë˜ë‚Ÿ. ì•ì—ì„œ í™œìš©ëœ ë¬¸ì¥ìœ¼ë¡œ ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”©ì„ ì‚´í´ë³´ì.tokens = [\"[CLS]\", \"Paris\", \"is\", \"a\", \"beautiful\", \"city\", \"[SEP]\", \"I\", \"love\", \"Paris\", \"[SEP]\"]ì´ì œ [SEP] í† í°ê³¼ ë³„ë„ë¡œ ë‘ ë¬¸ì¥ì„ êµ¬ë¶„í•˜ê¸° ìœ„í•´ ëª¨ë¸ì— ì¼ì¢…ì˜ ì§€í‘œë¥¼ ì œê³µí•´ì•¼ í•œë‹¤. ì´ë¥¼ ìœ„í•´ ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ë ˆì´ì–´ì— ì…ë ¥ í† í°ì„ ì œê³µí•œë‹¤.ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ë ˆì´ì–´ëŠ” ì…ë ¥ì— ëŒ€í•œ ì¶œë ¥ìœ¼ë¡œ $E_A, E_B$ë§Œ ë°˜í™˜í•œë‹¤. ì…ë ¥ í† í°ì´ A ë¬¸ì¥ì— ì†í•˜ë©´ $E_A$ì— ë§¤í•‘ë˜ê³ , B ë¬¸ì¥ì— ì†í•˜ë©´ $E_B$ì— ë§¤í•‘ëœë‹¤.[ê·¸ë¦¼ 2-9]ì— í‘œì‹œëœ ëŒ€ë¡œ ë¬¸ì¥ Aì˜ ëª¨ë“  í† í°ì€ $E_A$ì— ë§¤í•‘ë˜ê³ , B ë¬¸ì¥ì˜ ëª¨ë“  í† í°ì€ $E_B$ì— ë§¤í•‘ëœë‹¤. ê·¸ë¦¼ 2-9 ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”©: ë¬¸ì¥ì´ 2ê°œì¸ ê²½ìš°ê·¸ëŸ¼ ë¬¸ì¥ì´ í•˜ë‚˜ë§Œ ìˆëŠ” ê²½ìš° ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”©ì€ ì–´ë–»ê²Œ ë ê¹Œ? â€œParis is a beautiful cityâ€ë¼ëŠ” ë¬¸ì¥ë§Œ ìˆë‹¤ê³  ê°€ì •í•˜ë©´, ë‹¤ìŒê³¼ ê°™ì´ ë¬¸ì¥ì˜ ëª¨ë“  í† í°ì´ $E_A$ì— ë§¤í•‘ëœë‹¤. ê·¸ë¦¼ 2-10 ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”©: ë¬¸ì¥ì´ 1ê°œì¸ ê²½ìš°ìœ„ì¹˜ ì„ë² ë”©ë‹¤ìŒìœ¼ë¡œ ìœ„ì¹˜ ì„ë² ë”©ì´ ìˆë‹¤. ì „ ì¥ì—ì„œ íŠ¸ëœìŠ¤í¬ë¨¸ê°€ ì–´ë–¤ ë°˜ë³µ ë©”ì»¤ë‹ˆì¦˜ë„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ëª¨ë“  ë‹¨ì–´ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ë¯€ë¡œ ë‹¨ì–´ ìˆœì„œì™€ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì œê³µí•´ì•¼ í•œë‹¤ëŠ” ê²ƒì„ ë°°ì› ë‹¤. ì´ë•Œ ìœ„ì¹˜ ì¸ì½”ë”©ì„ ì‚¬ìš©í–ˆë‹¤.BERTëŠ” ë³¸ì§ˆì ìœ¼ë¡œ íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ì¸ì½”ë”ì´ë¯€ë¡œ BERTì— ë°ì´í„°ë¥¼ ì§ì ‘ ì…ë ¥í•˜ê¸° ì „ì— ë¬¸ì¥ì—ì„œ ë‹¨ì–´ (í† í°)ì˜ ìœ„ì¹˜ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•´ì•¼ í•œë‹¤. ê²°êµ­ ìš°ë¦¬ëŠ” ìœ„ì¹˜ ì„ë² ë”©ì´ë¼ëŠ” ë ˆì´ì–´ë¥¼ ì‚¬ìš©í•´ ë¬¸ì¥ì˜ ê° í† í°ì— ëŒ€í•œ ìœ„ì¹˜ ì„ë² ë”© ì¶œë ¥ì„ ì–»ê²Œ ëœë‹¤.[ê·¸ë¦¼ 2-11]ì—ì„œ [CLS]ì˜ ìœ„ì¹˜ ì„ë² ë”©ì¸ $E_0$ì™€ Paris í† í°ì˜ ìœ„ì¹˜ ì„ë² ë”©ì¸ $E_1$ ë“±ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ê·¸ë¦¼ 2-11 ìœ„ì¹˜ ì„ë² ë”©ìµœì¢… ì…ë ¥ ë°ì´í„° í‘œí˜„ì´ì œ ìµœì¢… ì…ë ¥ ë°ì´í„° í‘œí˜„ì„ ì‚´í´ë³´ì. [ê·¸ë¦¼ 2-12]ì— í‘œì‹œëœ ê²ƒì²˜ëŸ¼ ë¨¼ì € ì£¼ì–´ì§„ ì…ë ¥ ë¬¸ì¥ì„ í† í°ìœ¼ë¡œ ë³€í™˜í•˜ê³  í† í°ì„ í† í° ì„ë² ë”©, ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”©, ìœ„ì¹˜ ì„ë² ë”© ë ˆì´ì–´ì— ê³µê¸‰í•˜ê³  ì„ë² ë”©ì„ ì–»ëŠ”ë‹¤. ê·¸ ë‹¤ìŒìœ¼ë¡œ ëª¨ë“  ì„ë² ë”©ì„ í•©ì‚°í—¤ BERTì— ì…ë ¥ìœ¼ë¡œ ì œê³µí•œë‹¤. ê·¸ë¦¼ 2-12 ì…ë ¥ì˜ ìµœì¢… í‘œí˜„ì§€ê¸ˆê¹Œì§€ ì„¸ ê°€ì§€ ì„ë² ë”© ë ˆì´ì–´ë¥¼ ì‚¬ìš©í•´ ì…ë ¥ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë°©ë²•ì„ ë°°ì› ë‹¤. ë‹¤ìŒìœ¼ë¡œ BERTì—ì„œ ì‚¬ìš©í•˜ëŠ” ì›Œë“œí”¼ìŠ¤ í† í¬ë‚˜ì´ì €ì— ëŒ€í•´ ì•Œì•„ë³´ì.ì›Œë“œí”¼ìŠ¤ í† í¬ë‚˜ì´ì €BERTëŠ” ì›Œë“œí”¼ìŠ¤ í† í¬ë‚˜ì´ì €ë¼ëŠ” íŠ¹ë³„í•œ ìœ í˜•ì˜ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ë©°, ì´ëŠ” í•˜ìœ„ ë‹¨ì–´ í† í°í™” ì•Œê³ ë¦¬ì¦˜ì„ ê¸°ë°˜ìœ¼ë¡œ í•œë‹¤. ì˜ˆì œë¥¼ í†µí•´ ì›Œë“œí”¼ìŠ¤ í† í¬ë‚˜ì´ì €ê°€ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ ì´í•´í•´ë³´ì. ë¨¼ì € ë‹¤ìŒ ë¬¸ì¥ì´ ì£¼ì–´ì¡Œë‹¤ê³  ê°€ì •í•˜ì. Let us start pretraining the model.ì›Œë“œí”¼ìŠ¤ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•´ ë¬¸ì¥ì„ í† í°í™”í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ í† í°ì„ ì–»ì„ ìˆ˜ ìˆë‹¤.tokens = [\"let\", \"us\", \"start\", \"pre\", \"##train\", \"##ing\", \"the\", \"model\"]ì›Œë“œí”¼ìŠ¤ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•´ ë¬¸ì¥ì„ í† í°í™”í•˜ë©´ ê°œë³„ ë‹¨ì–´ê°€ pre, ##train, ##ingì™€ ê°™ì€ í•˜ìœ„ë‹¨ì–´(subword)ë¡œ ë¶„í• ë˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ìˆë”°. ì™œ í•˜ìœ„ ë‹¨ì–´ë¡œ ë¶„í• í•˜ëŠ” ê²ƒì¼ê¹Œ?BERTëŠ” ì›Œë“œí”¼ìŠ¤ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•´ í† í°í™”í•  ë•Œ ë‹¨ì–´ê°€ ì–´íœ˜ ì‚¬ì „ì— ìˆëŠ”ì§€ í™•ì¸í•œë‹¤. ë‹¨ì–´ê°€ ì–´íœ˜ ì‚¬ì „ì— ìˆìœ¼ë©´ ê·¸ ë‹¨ì–´ë¥¼ í† í°ìœ¼ë¡œ ì‚¬ìš©í•˜ê³ , ë‹¨ì–´ê°€ ì–´íœ˜ ì‚¬ì „ì— ì—†ìœ¼ë©´ ê·¸ ë‹¨ì–´ë¥¼ í•˜ìœ„ ë‹¨ì–´ë¡œ ë¶„í• í•´ í•˜ìœ„ ë‹¨ì–´ê°€ ì–´íœ˜ ì‚¬ì „ì— ìˆëŠ”ì§€ í™•ì¸í•œë‹¤. í•˜ìœ„ ë‹¨ì–´ê°€ ì–´íœ˜ ì‚¬ì „ì— ìˆìœ¼ë©´ ì´ë¥¼ í† í°ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤. ë§Œì•½ í•˜ìœ„ ë‹¨ì–´ê°€ ì–´íœ˜ ì‚¬ì „ì— ì—†ìœ¼ë©´ ë‹¤ì‹œ í•˜ìœ„ ë‹¨ì–´ë¡œ ë¶„í• í•˜ì—¬ ë‹¤ì‹œ í•˜ìœ„ ë‹¨ì–´ë¡œ ë¶„í• í•œë‹¤. ì´ëŸ° ì‹ìœ¼ë¡œ ê°œë³„ ë¬¸ìì— ë„ë‹¬í•  ë•Œ ê¹Œì§€ ì–´íœ˜ ì‚¬ì „ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ìœ„ ë‹¨ì–´ë¥¼ ê³„ì† ë¶„í• í•˜ê³  í™•ì¸í•œë‹¤. ì´ ë°©ì‹ì€ ì–´íœ˜ ì‚¬ì „ ì´ì™¸(out-of-vocabulary, OOV)ì˜ ë‹¨ì–´ë¥¼ ì²˜ë¦¬í•˜ëŠ”ë° íš¨ê³¼ì ì´ë‹¤.BERT ì–´íœ˜ ì‚¬ì „ í¬ê¸°ëŠ” 3ë§Œ í† í°ì´ë‹¤. ì…ë ¥ ë‹¨ì–´ê°€ 3ë§Œ í† í°ì— ì†í•˜ë©´ ì´ë¥¼ í† í°ìœ¼ë¡œ ì‚¬ìš©í•˜ê³  ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ í•˜ìœ„ ë‹¨ì–´ë¡œ ë¶„í• í•˜ì—¬ í•˜ìœ„ ë‹¨ì–´ê°€ ì´ 3ë§Œ í† í°ì— ì†í•˜ëŠ”ì§€ í™•ì¸í•œë‹¤. ì•Œê³ ë¦¬ì¦˜ì€ ê°œë³„ ë¬¸ìì— ë„ë‹¬í•  ë•Œê¹Œì§€ ì–´íœ˜ ì‚¬ì „(3ë§Œ í† í°)ìœ¼ë¡œ í•˜ìœ„ ë‹¨ì–´ë¥¼ ê³„ì† ë¶„í• í•˜ê³  í™•ì¸í•œë‹¤.ì´ ì˜ˆì—ì„œ pretrainingì´ë¼ëŠ” ë‹¨ì–´ëŠ” BERTì˜ ì–´íœ˜ì‚¬ì „ì— ì—†ê¸° ë•Œë¬¸ì— ì´ ë‹¨ì–´ë¥¼ pre, ##train, ##ingì™€ ê°™ì€ í•˜ìœ„ë‹¨ì–´ë¡œ ë‚˜ëˆˆë‹¤. ##trainê³¼ ##ing í† í° ì•ì˜ í•´ì‹œ ê¸°í˜¸ëŠ” í•˜ìœ„ ë‹¨ì–´ì„ì„ ë‚˜íƒ€ë‚´ê³  ì•ì— ë‹¤ë¥¸ ë‹¨ì–´ê°€ ìˆìŒì„ ì˜ë¯¸í•œë‹¤. ì´ì œ ì–´íœ˜ ì‚¬ì „ì— ##trainê³¼ ##ingí•˜ìœ„ ë‹¨ì–´ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ì´ë“¤ì€ ì–´íœ˜ ì‚¬ì „ì— ì¡´ì¬í•˜ê¸° ë•Œë¬¸ì— ë‹¤ì‹œ ë‚˜ëˆ„ì§€ ì•Šê³  í† í°ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤.ê²°êµ­, ì›Œë“œí”¼ìŠ¤ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•´ ë‹¤ìŒê³¼ ê°™ì€ í† í°ë“¤ì„ ì–»ê²Œ ëœë‹¤.tokens = [\"let\", \"us\", \"start\", \"pre\", \"##train\", \"##ing\", \"the\", \"model\"]ì´í›„ ë¬¸ì¥ ì‹œì‘ ë¶€ë¶„ì— [CLS] í† í°ì„ ì¶”ê°€í•˜ê³  ë¬¸ì¥ ë ë¶€ë¶„ì— [SEP] í† í°ì„ ì¶”ê°€í•œë‹¤.ì•ì—ì„œ ë°°ìš´ ê²ƒì²˜ëŸ¼ ì…ë ¥ í† í°ì„ í† í°, ì„¸ê·¸ë¨¼íŠ¸, ìœ„ì¹˜ ì„ë² ë”© ë ˆì´ì–´ì— ì…ë ¥í•´ ê° ì„ë² ë”©ì„ ì–»ê³  ì´ë“¤ ì„ë² ë”©ì„ í•©í•œ ë‹¤ìŒ BERTì— ì…ë ¥í•œë‹¤. ì›Œë“œí”¼ìŠ¤ í† í¬ë‚˜ì´ì €ì˜ ì‘ë™ ë°©ì‹ê³¼ ì–´íœ˜ ì‚¬ì „ êµ¬ì¶• ë°©ì‹ì€ 2.5ì ˆ ë‹¤ë¥¸ í† í¬ë‚˜ì´ì €ì™€ í•¨ê»˜ ìì„¸íˆ ë‹¤ë£¬ë‹¤.2.4.2 í•™ìŠµ ì „ëµBERTëŠ” ë‹¤ìŒ ë‘ ê°€ì§€ íƒœìŠ¤í¬ì— ëŒ€í•´ ì‚¬ì „ í•™ìŠµëœë‹¤. ë§ˆìŠ¤í¬ ì–¸ì–´ ëª¨ë¸ë§ (Masked Language Modeling, MLM) ë‹¤ìŒ ë¬¸ì¥ ì˜ˆì¸¡ (Next Sentence Prediction, NSP)ì´ ë‘ ê°€ì§€ í•™ìŠµ ì „ëµì„ ì°¨ë¡€ë¡œ ì‚´í´ ë´„ìœ¼ë¡œì¨ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ ì´í•´í•´ë³´ì. MLM íƒœìŠ¤í¬ë¥¼ ì„¤ëª…í•˜ê¸° ì „ì— ë¨¼ì € ì–¸ì–´ ëª¨ë¸ë§ íƒœìŠ¤í¬ë¥¼ ì‚´í´ë³¸ë‹¤.ì–¸ì–´ ëª¨ë¸ë§ì–¸ì–´ ëª¨ë¸ë§ (Language Modeling)ì€ ì¼ë°˜ì ìœ¼ë¡œ ì„ì˜ì˜ ë¬¸ì¥ì´ ì£¼ì–´ì§€ê³  ë‹¨ì–´ë¥¼ ìˆœì„œëŒ€ë¡œ ë³´ë©´ì„œ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ê²ƒì´ë‹¤. ì–¸ì–´ ëª¨ë¸ë§ì€ ë‹¤ìŒ ë‘ ê°€ì§€ë¡œ ë¶„ë¥˜í•  ìˆ˜ ìˆë‹¤. ìë™ íšŒê·€ ì–¸ì–´ ëª¨ë¸ë§ (auto-regressive language modeling) ìë™ ì¸ì½”ë”© ì–¸ì–´ ëª¨ë¸ë§ (auto-encoding language modeling) ### ìë™ íšŒê·€ ì–¸ì–´ ëª¨ë¸ë§ ìë™ íšŒêµ¬ ì–¸ì–´ ëª¨ë¸ë§ì€ ë‹¤ì‹œ ë‹¤ìŒ ë‘ ê°€ì§€ ë°©ì‹ìœ¼ë¡œ êµ¬ë¶„í•  ìˆ˜ ìˆë‹¤. ì „ë°© (ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ) ì˜ˆì¸¡ (forward(left-to-right) prediction) í›„ë°© (ì˜¤ë¥¸ìª½ì—ì„œ ì™¼ìª½ìœ¼ë¡œ) ì˜ˆì¸¡ (backward(right-to-left)) prediction) ì´ ë‘ ê°€ì§€ ë°©ë²•ì´ ì–´ë–»ê²Œ ë™ì‘í•˜ëŠ”ì§€ ì˜ˆì œë¡œ ì‚´í´ë³´ì. â€œParis is a beautiful city. I love Parisâ€ ë¼ëŠ” ë¬¸ì¥ì´ ì£¼ì–´ì¡Œì„ ë•Œ ë‹¤ìŒê³¼ ê°™ì´ â€œcityâ€ë¼ëŠ” ë‹¨ì–´ë¥¼ ì œê±°í•˜ê³  ê³µë°±ì„ ì¶”ê°€í•´ë³¸ë‹¤. Paris is a beautiful ___. I love Paris. ì´ì œ ëª¨ë¸ì€ ê³µë°±ì„ ì˜ˆì¸¡í•´ì•¼ í•œë‹¤. ì „ë°© ì˜ˆì¸¡ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ëª¨ë¸ì€ ì˜ˆì¸¡ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì´ ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ê³µë°±ê¹Œì§€ì˜ ëª¨ë“  ë‹¨ì–´ë¥¼ ì½ëŠ”ë‹¤. Paris is a beautiful ___. í›„ë°© ì˜ˆì¸¡ì„ ì‚¬ìš©í•˜ë©´ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ëª¨ë¸ì€ ë‹¤ìŒê³¼ ê°™ì´ ì˜¤ë¥¸ìª½ì—ì„œ ì™¼ìª½ìœ¼ë¡œ ê³µë°±ê¹Œì§€ ëª¨ë“  ë‹¨ì–´ë¥¼ ì½ëŠ”ë‹¤. ___. I love Paris. ìë™ íšŒê·€ ëª¨ë¸ì€ ì›ë˜ ë‹¨ë°©í–¥ì´ë¯€ë¡œ í•œ ë°©í–¥ìœ¼ë¡œë§Œ ë¬¸ì¥ì„ ì½ëŠ”ë‹¤. ë§ˆìŠ¤í¬ ì–¸ì–´ ëª¨ë¸ë§ (MLM)BERTëŠ” ìë™ ì¸ì½”ë”© ì–¸ì–´ ëª¨ë¸ë¡œ, ì˜ˆì¸¡ì„ ìœ„í•´ ë¬¸ì¥ì„ ì–‘ë°©í–¥ìœ¼ë¡œ ì½ëŠ”ë‹¤. ë§ˆìŠ¤í¬ ì–¸ì–´ ëª¨ë¸ë§ì€ ì£¼ì–´ì§„ ì…ë ¥ ë¬¸ì¥ì—ì„œ ì „ì²´ ë‹¨ì–´ì˜ 15%ë¥¼ ë¬´ì‘ìœ„ë¡œ ë§ˆìŠ¤í‚¹í•˜ê³  ë§ˆìŠ¤í¬ëœ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” ê²ƒì´ë‹¤. ë§ˆìŠ¤í¬ëœ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ëª¨ë¸ì€ ì–‘ë°©í–¥ìœ¼ë¡œ ë¬¸ì¥ì„ ì½ê³  ë§ˆìŠ¤í¬ëœ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ë ¤ ì‹œë„í•œë‹¤.ë§ˆìŠ¤í¬ ì–¸ì–´ ëª¨ë¸ë§ì´ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ ì˜ˆì œë¥¼ í†µí•´ ì‚´í´ë³´ì. ì•ì—ì„œ ì‚´í´ë³¸ ë¬¸ì¥ (Paris is a beautiful city, I love Paris)ì„ í† í°í™”í•œë‹¤.tokens = [\"Paris\", \"is\", \"a\", \"beautiful\", \"city\", \"I\", \"love\", \"Paris\"]ì²« ë²ˆì§¸ ë¬¸ì¥ì˜ ì‹œì‘ ë¶€ë¶„ì— [CLS] í† í°ì„ ì¶”ê°€í•˜ê³  ë¬¸ì¥ ëì— [SEP] í† í°ì„ ì¶”ê°€í•œë‹¤.tokens = [\"[CLS]\", \"Paris\", \"is\", \"a\", \"beautiful\", \"city\", \"[SEP]\", \"I\", \"love\", \"Paris\", \"[SEP]\"]ë‹¤ìŒìœ¼ë¡œ, í† í°ì˜ 15%ë¥¼ ë¬´ì‘ìœ„ë¡œ ë§ˆìŠ¤í‚¹í•œë‹¤. ë‹¤ìŒê³¼ ê°™ì´ cityë¼ëŠ” ë‹¨ì–´ë¥¼ ë§ˆìŠ¤í‚¹í•œ ë‹¤ìŒ [MASK] í† í°ìœ¼ë¡œ ë°”ê¾¼ë‹¤.tokens = [\"[CLS]\", \"Paris\", \"is\", \"a\", \"beautiful\", \"[MASK]\", \"[SEP]\", \"I\", \"love\", \"Paris\", \"[SEP]\"]â€œcityâ€ë¼ëŠ” ë‹¨ì–´ë¥¼ [MASK] í† í°ìœ¼ë¡œ ëŒ€ì²´í–ˆë‹¤. ì´ì   ë§ˆìŠ¤í¬ëœ í† í°ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•œ BERTë¥¼ í•™ìŠµì‹œí‚¨ë‹¤.ì—¬ê¸°ì— ì‘ì€ ë¬¸ì œê°€ ìˆë‹¤. ìœ„ì™€ ê°™ì€ ë°©ì‹ìœ¼ë¡œ í† í°ì„ ë§ˆìŠ¤í‚¹í•˜ë©´ ì‚¬ì „í•™ìŠµê³¼ íŒŒì¸íŠœë‹ ì‚¬ì´ì— ë¶ˆì¼ì¹˜ê°€ ìƒê¸°ê²Œ ëœë‹¤. [MASK] í† í°ì„ ì˜ˆì¸¡í•´ BERTë¥¼ ì‚¬ì „í•™ìŠµì‹œí‚¤ê³ , í•™ìŠµ ì‹œí‚¨ í›„ì—ëŠ” ê°ì • ë¶„ì„ê³¼ ê°™ì€ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬ë¥¼ ìœ„í•´ ì‚¬ì „ í•™ìŠµëœ BERTë¥¼ íŒŒì¸ íŠœë‹í•œë‹¤. ê·¸ëŸ°ë° íŒŒì¸ íŠœë‹ì—ëŠ” ì…ë ¥ì— [MASK] í† í°ì´ ì—†ë‹¤. ì´ ë•Œë¬¸ì— BERTê°€ ì‚¬ì „ í•™ìŠµë˜ëŠ” ë°©ì‹ê³¼ íŒŒì¸ íŠœë‹ì— ì‚¬ìš©ë˜ëŠ” ë°©ì‹ ê°„ì— ë¶ˆì¼ì¹˜ê°€ ë°œìƒí•œë‹¤.ì´ ë¬¸ì œë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ 80-10-10% ê·œì¹™ì„ ì‚¬ìš©í•œë‹¤. ë¬¸ì¥ì—ì„œ í† í°ì˜ 15%ë¥¼ ë¬´ì‘ìœ„ë¡œ ë§ˆìŠ¤í‚¹í•œë‹¤ëŠ” ê²ƒì„ í™•ì¸í–ˆë‹¤. ê·¸ëŸ¼ 15% í† í°ì— ëŒ€í•´ ë‹¤ìŒì„ ìˆ˜í–‰í•œë‹¤. 15% ì¤‘ 80%ì˜ í† í°(ì‹¤ì œ ë‹¨ì–´)ë¥¼ [MASK] í† í°ìœ¼ë¡œ êµì²´í•œë‹¤. ì ìš© ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. tokens = [\"[CLS]\", \"Paris\", \"is\", \"a\", \"beautiful\", \"[MASK]\", \"[SEP]\", \"I\", \"love\", \"Paris\", \"[SEP]\"] 15% ì¦ 10%ì˜ í† í°(ì‹¤ì œ ë‹¨ì–´)ì„ ì„ì˜ì˜ í† í°(ì„ì˜ ë‹¨ì–´)ë¡œ êµì²´í•œë‹¤. ì ìš© ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. tokens = [\"[CLS]\", \"Paris\", \"is\", \"a\", \"beautiful\", \"love\", \"[SEP]\", \"I\", \"love\", \"Paris\", \"[SEP]\"] 15% ì¤‘ ë‚˜ë¨¸ì§€ 10%ì˜ í† í°ì€ ì–´ë–¤ ë³€ê²½ë„ í•˜ì§€ ì•ŠëŠ”ë‹¤. ì ìš©ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. tokens = [\"[CLS]\", \"Paris\", \"is\", \"a\", \"beautiful\", \"city\", \"[SEP]\", \"I\", \"love\", \"Paris\", \"[SEP]\"] í† í°í™” ë° ë§ˆìŠ¤í‚¹ í›„ì— ì…ë ¥ í† í°ì„ í† í°, ì„¸ê·¸ë¨¼íŠ¸, ìœ„ì¹˜ ì„ë² ë”© ë ˆì´ì–´ì— ì…ë ¥í•´ ì…ë ¥ ì„ë² ë”©ì„ ì–»ëŠ”ë‹¤.ì´ì œ ì´ ì…ë ¥ ì„ë² ë”©ì„ BERTì— ì œê³µí•œë‹¤.[ê·¸ë¦¼ 2-13]ê³¼ ê°™ì´ BERTëŠ” ì…ë ¥ì„ ë°›ì€ ë‹¤ìŒ ê° í† í°ì˜ í‘œí˜„ ë²¡í„°ë¥¼ ì¶œë ¥ìœ¼ë¡œ ë°˜í™˜í•œë‹¤. $R_{CLS}$ëŠ” [CLS]í† í°ì˜ í‘œí˜„ ë²¡í„°ë¥¼ ì˜ë¯¸í•˜ê³ , $R_{Paris}$ëŠ” Parisí† í°ì˜ í‘œí˜„ ë²¡í„°ë¥¼ ì˜ë¯¸í•œë‹¤. ì´ ì˜ˆì—ì„œëŠ” 12ê°œì˜ ì¸ì½”ë” ë ˆì´ì–´, 12ê°œì˜ ì–´í…ì…˜ í—¤ë“œ, 768ê°œì˜ ì€ë‹‰ ìœ ë‹›ì´ ìˆëŠ” BERT-baseë¥¼ ì‚¬ìš©í•œë‹¤. BERT-base ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ê° í† í°ì˜ í‘œí˜„ ë²¡í„° í¬ê¸°ëŠ” 768ì´ ëœë‹¤. ê·¸ë¦¼ 2-13 BERT[ê·¸ë¦¼ 2-13]ì—ì„œ ê° í† í°ì˜ í‘œí˜„ $R$ì„ ì–»ì—ˆë‹¤. ì´ì œ ì´ëŸ¬í•œ í‘œí˜„ìœ¼ë¡œ ë§ˆìŠ¤í¬ëœ í† í°ì„ ì–´ë–»ê²Œ ì˜ˆì¸¡í•˜ê²Œ ë ê¹Œ?ë§ˆìŠ¤í¬ëœ í† í°ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ BERTì—ì„œ ë°˜í™˜ëœ ë§ˆìŠ¤í¬ëœ í† í° $R_{MASK}$ì˜ í‘œí˜„ì„ ì†Œí”„íŠ¸ë§¥ìŠ¤ í™œì„±í™”ë¥¼ í†µí•´ í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ì— ì…ë ¥í•œë‹¤. í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ëŠ” ë‹¤ìŒê·¸ë¦¼ê³¼ ê°™ì´ $R_{MASK}$ ë‹¨ì–´ê°€ ë§ˆìŠ¤í¬ëœ ë‹¨ì–´ê°€ ë  í™•ë¥ ì„ ë°˜í™˜í•œë‹¤. ì—¬ê¸°ì„œëŠ” ë³µì¡í•¨ì„ ì¤„ì´ê¸° ìœ„í•´ ì…ë ¥ ì„ë² ë”© ë ˆì´ì–´ (í† í°, ì„¸ê·¸ë¨¼íŠ¸, ìœ„ì¹˜)ë¥¼ í‘œì‹œí•˜ì§€ ì•Šì•˜ë‹¤. ê·¸ë¦¼ 2-14 ë§ˆìŠ¤í¬ëœ í† í° ì˜ˆì¸¡[ê·¸ë¦¼ 2-14]ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ â€œcityâ€ë¼ëŠ” ë‹¨ì–´ê°€ ë§ˆìŠ¤í¬ëœ ë‹¨ì–´ì¼ í™•ë¥ ì´ ë†’ë‹¤. ì´ ê²½ìš° ë§ˆìŠ¤í¬ëœ ë‹¨ì–´ëŠ” â€œcityâ€ë¡œ ì˜ˆì¸¡ëœë‹¤.í•™ìŠµ ì´ˆê¸°ì—ëŠ” BERTì˜ í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ ë° ì¸ì½”ë” ê³„ì¸µì˜ ê°€ì¤‘ì¹˜ê°€ ìµœì ì´ ì•„ë‹ˆë¯€ë¡œ ëª¨ë¸ì´ ì˜¬ë°”ë¥¸ í™•ë¥ ì„ ë°˜í™˜í•˜ì§€ ì•ŠëŠ”ë‹¤. ê·¸ëŸ¬ë‚˜ ì—­ì „íŒŒë¥¼ í†µí•œ ì¼ë ¨ì˜ ë°˜ë³µ ê³¼ì •ì„ ê±°ì¹˜ë©° BERT í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ ë° ì¸ì½”ë” ê³„ì¸µì˜ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ê°€ ë°˜ë³µë˜ë©´ì„œ ìµœì ì˜ ê°€ì¤‘ì¹˜ë¥¼ í•™ìŠµí•˜ê²Œ ëœë‹¤.ë§ˆìŠ¤í¬ ì–¸ì–´ ëª¨ë¸ë§ íƒœìŠ¤í¬ëŠ” ë¹ˆì¹¸ì±„ìš°ê¸° íƒœìŠ¤í¬ (cloze task)ë¼ê³ ë„ í•œë‹¤. ì§€ê¸ˆê¹Œì§€ ë§ˆìŠ¤í¬ ì–¸ì–´ ëª¨ë¸ë§ íƒœìŠ¤í¬ê°€ ì‘ë™í•˜ëŠ” ë°©ì‹ê³¼ ë§ˆìŠ¤í¬ ì–¸ì–´ ëª¨ë¸ë§ íƒœìŠ¤í¬ë¥¼ ì‚¬ìš©í•´ BERTë¥¼ í•™ìŠµì‹œí‚¤ëŠ” ë°©ë²•ì„ ë°°ì› ë‹¤. ì´ì œ ì¢€ ë” ì–´ë ¤ìš´ ì „ì²´ ë‹¨ì–´ ë§ˆìŠ¤í‚¹ ë°©ë²•ì„ ì•Œì•„ë³´ì.ì „ì²´ ë‹¨ì–´ ë§ˆìŠ¤í‚¹(WWM)ì „ì²´ ë‹¨ì–´ ë§ˆìŠ¤í‚¹ (Whole Word Masking, WWM)ì´ ì–´ë–»ê²Œ ë™ì‘í•˜ëŠ”ì§€ ì˜ˆì œë¥¼ í†µí•´ ì´í•´í•´ë³´ì. â€œLet us start pretraining the modelâ€ ì´ë¼ëŠ” ë¬¸ì¥ì„ ì˜ˆë¡œ ë“¤ì–´ë³´ì. BERTëŠ” ì›Œë“œí”¼ìŠ¤ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ì›Œë“œí”¼ìŠ¤ í† í¬ë‚˜ì´ì €ë¥¼ í†µí•´ ë¬¸ì¥ì„ í† í°í™”í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ í† í°ì„ ì–»ê²Œ ëœë‹¤.tokens = [\"let\", \"us\", \"start\", \"pre\", \"##train\", \"##ing\", \"the\", \"model\"]ë¬¸ì¥ ì‹œì‘ ë¶€ë¶„ì— [CLS] í† í°ì„ ì¶”ê°€í•˜ê³  ë¬¸ì¥ ëë¶€ë¶„ì— [SEP] í† í°ì„ ì¶”ê°€í•œë‹¤.tokens = [\"[CLS]\", \"let\", \"us\", \"start\", \"pre\", \"##train\", \"##ing\", \"the\", \"model\", \"[SEP]\"]ë§ˆì§€ë§‰ìœ¼ë¡œ ë‹¨ì–´ì˜ 15%ë¥¼ ë¬´ì‘ìœ„ë¡œ ë§ˆìŠ¤í‚¹í•˜ëŠ”ë°, ë§ˆìŠ¤í‚¹ ê²°ê³¼ê°€ ë‹¤ìŒê³¼ ê°™ë‹¤ê³  ê°€ì •í•´ë³´ì.tokens = [\"[CLS]\", \"[MASK]\", \"us\", \"start\", \"pre\", \"[MASK]\", \"##ing\", \"the\", \"model\", \"[SEP]\"]letê³¼ ##trainì´ë¼ëŠ” ë‹¨ì–´ë¥¼ ë§ˆìŠ¤í‚¹í–ˆë‹¤. ##trainì´ë¼ëŠ” ë‹¨ì–´ëŠ” í•˜ìœ„ ë‹¨ì–´ë¡œ ì‚¬ì „ í•™ìŠµì´ë¼ëŠ” ë‹¨ì–´ì˜ ì¼ë¶€ë‹¤. WWM ë°©ë²•ì—ì„œëŠ” í•˜ìœ„ ë‹¨ì–´ê°€ ë§ˆìŠ¤í‚¹ë˜ë©´ í•´ë‹¹ í•˜ìœ„ ë‹¨ì–´ì™€ ê´€ë ¨ëœ ëª¨ë“  ë‹¨ì–´ë¥¼ ë§ˆìŠ¤í‚¹í•œë‹¤. ë”°ë¼ì„œ ì´ì œ í† í° ë¦¬ìŠ¤íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ì•„ì§„ë‹¤.tokens = [\"[CLS]\", \"[MASK]\", \"us\", \"start\", \"[MASK]\", \"[MASK]\", \"[MASK]\", \"the\", \"model\", \"[SEP]\"]##train í•˜ìœ„ ë‹¨ì–´ì™€ ê´€ë ¨ëœ ëª¨ë“  ë‹¨ì–´ë“¤ì´ ë§ˆìŠ¤í‚¹ë˜ì—ˆë‹¤. WWMì˜ ê²½ìš° í•˜ìœ„ ë‹¨ì–´ê°€ ë§ˆìŠ¤í‚¹ë˜ë©´ í•˜ìœ„ ë‹¨ì–´ì™€ ê´€ë ¨ëœ ëª¨ë“  ë‹¨ì–´ë¥¼ ë§ˆìŠ¤í‚¹í•˜ë©´ì„œ ë§ˆìŠ¤í¬ ë¹„ìœ¨(15%)ì„ ìœ ì§€í•˜ë ¤ í•œë‹¤. ë”°ë¼ì„œ í•˜ìœ„ ë‹¨ì–´ì™€ ê´€ë ¨ëœ ëª¨ë“  ë‹¨ì–´ë¥¼ ë§ˆìŠ¤í‚¹í•˜ëŠ” ë™ì•ˆ ë§ˆìŠ¤í‚¹ ë¹„ìœ¨ì´ 15%ë¥¼ ì´ˆê³¼í•˜ë©´ ë‹¤ë¥¸ ë‹¨ì–´ì˜ ë§ˆìŠ¤í‚¹ì„ ë¬´ì‹œí•œë‹¤. ë‹¤ìŒê³¼ ê°™ì´ ë§ˆìŠ¤í‚¹ ë¹„ìœ¨ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ letì˜ ë§ˆìŠ¤í‚¹ì„ ë¬´ì‹œí–ˆë‹¤.tokens = [\"[CLS]\", \"let\", \"us\", \"start\", \"[MASK]\", \"[MASK]\", \"[MASK]\", \"the\", \"model\", \"[SEP]\"]ì´ëŸ¬í•œ ë°©ì‹ìœ¼ë¡œ WWMì„ ê¸°ë°˜ìœ¼ë¡œ í† í°ì„ ë§ˆìŠ¤í‚¹í•œë‹¤. ë§ˆìŠ¤í‚¹í•œ í›„ í† í°ì„ BERTì— ì…ë ¥í•˜ê³  ì•ì„œ ë°°ìš´ ê²ƒì²˜ëŸ¼ ë§ˆìŠ¤í¬ëœ í† í°ì„ ì˜ˆì¸¡í•˜ë„ë¡ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¨ë‹¤.ë‹¤ìŒ ë¬¸ì¥ ì˜ˆì¸¡(NSP)NSPëŠ” BERTí•™ìŠµì— ì‚¬ìš©ë˜ëŠ” ë˜ ë‹¤ë¥¸ í¥ë¯¸ë¡œìš´ íƒœìŠ¤í¬ë¡œ, ì´ì§„ ë¶„ë¥˜ íƒœìŠ¤í¬ì´ë‹¤. NSP íƒœìŠ¤í¬ì—ì„œëŠ” BERTì— ë‘ ë¬¸ì¥ì„ ì…ë ¥í•˜ê³  ë‘ ë²ˆì§¸ ë¬¸ì¥ì´ ì²« ë²ˆì§¸ ë¬¸ì¥ì˜ ë‹¤ìŒ ë¬¸ì¥ì¸ì§€ ì˜ˆì¸¡í•œë‹¤. ì˜ˆì œë¥¼ í†µí•´ NSP íƒœìŠ¤í¬ë¥¼ ì´í•´í•´ë³´ì.ë‹¤ìŒ ë‘ ë¬¸ì¥ì´ ì£¼ì–´ì¡Œë‹¤ê³  ê°€ì •í•´ë³´ì. A: She cooked pasta. B: It was delicious.ì´ ë¬¸ì¥ ìŒì—ì„œ B ë¬¸ì¥ì€ A ë¬¸ì¥ì˜ í›„ì† ë¬¸ì¥ì´ë‹¤. ì¦‰, A ë¬¸ì¥ì—ì„œ ì´ì–´ì§€ëŠ” ë¬¸ì¥ì´ë‹¤. ë”°ë¼ì„œ ì´ ë¬¸ì¥ ìŒì„ isNextë¡œ í‘œì‹œí•´ B ë¬¸ì¥ì´ A ë¬¸ì¥ì˜ ë‹¤ìŒ ë¬¸ì¥ì„ì„ ì•Œ ìˆ˜ ìˆê²Œ í•œë‹¤.ë‹¤ì‹œ ë‹¤ìŒ ë¬¸ì¥ì´ ì£¼ì–´ì¡Œë‹¤ê³  ê°€ì •í•´ë³´ì. A: Turn the radio on. B: She bought a new hat.ì´ ë¬¸ì¥ ìŒì—ì„œ B ë¬¸ì¥ì€ A ë¬¸ì¥ì˜ í›„ì† ë¬¸ì¥ì´ ì•„ë‹ˆë‹¤. ì¦‰, A ë¬¸ì¥ì— ì´ì–´ì§€ëŠ” ë¬¸ì¥ì´ ì•„ë‹ˆë‹¤. ë”°ë¼ì„œ ì´ ë¬¸ì¥ ìŒì„ notNextë¡œ í‘œì‹œí•´ B ë¬¸ì¥ì´ A ë¬¸ì¥ì˜ ë‹¤ìŒ ë¬¸ì¥ì´ ì•„ë‹˜ì„ ì•Œ ìˆ˜ ìˆê²Œ í•œë‹¤.NSP íƒœìŠ¤í¬ì—ì„œ ëª¨ë¸ì˜ ëª©í‘œëŠ” ë¬¸ì¥ ìŒì´ isNext ë²”ì£¼ì— ì†í•˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì´ë‹¤. ë¬¸ì¥ ìŒ (ë¬¸ì¥ A ë° B)ì„ BERTì— ì…ë ¥í•˜ê³  B ë¬¸ì¥ì´ A ë¬¸ì¥ ë‹¤ìŒì— ì˜¤ëŠ”ì§€ ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ í•™ìŠµì‹œí‚¨ë‹¤. ëª¨ë¸ì€ Bë¬¸ì¥ì´ Aë¬¸ì¥ì— ì´ì–´ì§€ë©´ isNextë¥¼ ë°˜í™˜í•˜ê³ , ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ notNextë¥¼ ë°˜í™˜í•œë‹¤. ë”°ë¼ì„œ NSPëŠ” ë³¸ì§ˆì ìœ¼ë¡œ ì´ì§„ ë¶„ë¥˜ íƒœìŠ¤í¬ì´ë‹¤.NSP íƒœìŠ¤í¬ì˜ ëª©ì ì€ ë¬´ì—‡ì¼ê¹Œ? NSP íƒœìŠ¤í¬ë¥¼ ìˆ˜í–‰í•¨ìœ¼ë¡œì¨ ëª¨ë¸ì€ ë‘ ë¬¸ì¥ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆë‹¤. ë‘ ë¬¸ì¥ ê°„ì˜ ê´€ê³„ë¥¼ ì´í•´í•˜ëŠ” ê²ƒì€ ì§ˆë¬¸-ì‘ë‹µ ë° ìœ ì‚¬ë¬¸ì¥íƒì§€ì™€ ê°™ì€ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬ì—ì„œ ìœ ìš©í•˜ë‹¤.ê·¸ëŸ¼, NSP íƒœìŠ¤í¬ë¥¼ ìœ„í•œ ë°ì´í„°ì…‹ì„ ì–´ë–»ê²Œ ì–»ì„ ìˆ˜ ìˆì„ê¹Œ? ì–´ë– í•œ ë§ë­‰ì¹˜ì—ì„œë„ ë°ì´í„°ì…‹ì„ í™•ë³´í•  ìˆ˜ ìˆë‹¤. 2ê°œì˜ ë¬¸ì„œê°€ ìˆë‹¤ê³  ê°€ì •í•´ë³´ì. isNext í´ë˜ìŠ¤ì˜ ê²½ìš° í•œ ë¬¸ì„œì—ì„œ ì—°ì†ëœ ë‘ ë¬¸ì¥ì„ isNextë¡œ í‘œì‹œí•˜ê³  notNext í´ë˜ìŠ¤ì˜ ê²½ìš° í•œ ë¬¸ì„œì—ì„œ í•œ ë¬¸ì¥ì„, ì„ì˜ì˜ ë¬¸ì„œì—ì„œ ë‹¤ë¥¸ ë¬¸ì¥ì„ ê°€ì ¸ì™€ notNextë¡œ í‘œì‹œí•˜ë©´ ëœë‹¤. isNext í´ë˜ìŠ¤ë¥¼ ì „ì²´ì˜ 50% ë¹„ìœ¨ë¡œ ìœ ì§€í•˜ê³  notNext í´ë˜ìŠ¤ì—ì„œ ë‚˜ë¨¸ì§€ 50%ë¥¼ ìœ ì§€í•´ í´ë˜ìŠ¤ê°€ ê· í˜•ì„ ì´ë£° ìˆ˜ ìˆë„ë¡ í•œë‹¤.ì´ì œ NSP íƒœìŠ¤í¬ê°€ ë¬´ì—‡ì¸ì§€ ì•Œì•˜ìœ¼ë‹ˆ, NSP íƒœìŠ¤í¬ë¥¼ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ BERTë¥¼ í•™ìŠµì‹œí‚¤ëŠ” ë°©ë²•ì„ ì‚´í´ë³´ê² ë‹¤. ë°ì´í„°ì…‹ì´ [ê·¸ë¦¼ 2-15]ì™€ ê°™ì´ ë‚˜íƒ€ë‚œë‹¤ê³  ê°€ì •í•´ë³´ì. ê·¸ë¦¼ 2-15 ê°„ë‹¨í•œ ë°ì´í„°ì…‹[ê·¸ë¦¼ 2-15]ì— ì œì‹œëœ ì²« ë²ˆì§¸ ë°ì´í„°ë¥¼ ì‚´í´ë³´ì. ë¨¼ì € ë‹¤ìŒê³¼ ê°™ì´ ë¬¸ì¥ ìŒì„ í† í°í™”í•œë‹¤.tokens = [\"She\", \"cooked\", \"pasta\", \"It\", \"was\", \"delicious\"]ì²« ë²ˆì§¸ ë¬¸ì¥ì˜ ì‹œì‘ ë¶€ë¶„ì— [CLS] í† í°ì„ ì¶”ê°€í•˜ê³  ëª¨ë“  ë¬¸ì¥ì˜ ëì— [SEP] í† í°ì„ ì¶”ê°€í•œë‹¤.tokens = [\"[CLS]\", \"She\", \"cooked\", \"past\", \"[SEP]\", \"it\", \"was\", \"delicious\", \"[SEP]\"]ì´ í† í°ë“¤ì„ í† í°, ì„¸ê·¸ë¨¼íŠ¸, ìœ„ì¹˜ ì„ë² ë”© ë ˆì´ì–´ì— ì…ë ¥í•˜ê³  ì…ë ¥ ì„ë² ë”©ì„ ë°˜í™˜ë°›ëŠ”ë‹¤. ê·¸ëŸ° ë‹¤ìŒ ì…ë ¥ ì„ë² ë”©ì„ BERTì— ë„£ì–´ ê° í† í°ì˜ í‘œí˜„ì„ ì–»ëŠ”ë‹¤. [ê·¸ë¦¼ 2-16]ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ í† í° $R_{CLS}$ëŠ” [CLS]ì˜ í‘œí˜„ì„ ë‚˜íƒ€ë‚´ê³  $R_{she}$ëŠ” She í† í°ì˜ í‘œí˜„ì„ ë‚˜íƒ€ë‚¸ë‹¤. ê·¸ë¦¼ 2-16 BERTì¢€ ì „ì— NSPê°€ ì´ì§„ ë¶„ë¥˜ ì‘ì—…ì´ë¼ê³  ë°°ì› ëŠ”ë°, ì§€ê¸ˆ ìš°ë¦¬ëŠ” ë¬¸ì¥ ìŒì—ì„œ ê° í† í°ì˜ í‘œí˜„ë§Œ ê°€ì§€ê³  ìˆë‹¤. ì´ëŸ¬í•œ í‘œí˜„ì„ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì¥ ìŒì„ ì–´ë–»ê²Œ ë¶„ë¥˜í•  ìˆ˜ ìˆì„ê¹Œ?ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ë ¤ë©´ ê°„ë‹¨íˆ [CLS] í† í° í‘œí˜„ì„ ê°€ì ¸ì™€ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ì— ì…ë ¥í•œë‹¤. ê·¸ëŸ¬ë©´ ë¬¸ì¥ìŒì´ isNextì¸ì§€, notNextì¸ì§€ì— ëŒ€í•œ í™•ë¥ ê°’ì´ ë°˜í™˜ëœë‹¤. ê·¸ë ‡ë‹¤ë©´ ì™œ [CLS] í† í°ë§Œ í¬í•¨ì‹œì¼œì•¼ í• ê¹Œ? ë‹¤ë¥¸ í† í°ì˜ ì„ë² ë”©ì´ ì•„ë‹Œ ì´ìœ ëŠ” ë¬´ì—‡ì¼ê¹Œ?[CLS] í† í°ì€ ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë“  í† í°ì˜ ì§‘ê³„ í‘œí˜„ì„ ë³´ìœ í•˜ê³  ìˆìœ¼ë¯€ë¡œ ë¬¸ì¥ ì „ì²´ì— ëŒ€í•œ í‘œí˜„ì„ ë‹´ê³  ìˆë‹¤. ë”°ë¼ì„œ ë‹¤ë¥¸ ëª¨ë“  í† í°ì˜ í‘œí˜„ì„ ë¬´ì‹œí•˜ê³  [CLS] í† í° í‘œí˜„ $R_{CLS}$ë¥¼ ê°€ì ¸ì™€ í™•ë¥ ì„ ë°˜í™˜í•˜ëŠ” ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ì— ê³µê¸‰í•  ìˆ˜ ìˆë‹¤. ì´ëŸ¬í•œ ë‚´ìš©ì´ [ê·¸ë¦¼ 2-17]ì— í¬í˜„ë˜ì–´ ìˆë‹¤. ì—¬ê¸°ì„œëŠ” ë³µì¡í•¨ì„ ì¤„ì´ê¸° ìœ„í•´ ì…ë ¥ ì„ë² ë”© ë ˆì´ì–´(í† í°, ì„¸ê·¸ë¨¼íŠ¸, ì„ë² ë”© ë ˆì´ì–´)ë¥¼ í‘œì‹œí•˜ì§€ ì•Šì•˜ë‹¤. ê·¸ë¦¼ 2-17 NSP íƒœìŠ¤í¬[ê·¸ë¦¼ 2-17]ì˜ í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ëŠ” ì…ë ¥ ë¬¸ì¥ì´ isNext í´ë˜ìŠ¤ì— ì†í•  í™•ë¥ ì´ ë†’ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤€ë‹¤.í•™ìŠµ ì´ˆê¸°ì—ëŠ” í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ ë° ì¸ì½”ë” ê³„ì¸µì˜ ê°€ì¤‘ì¹˜ê°€ ìµœì ì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì— ëª¨ë¸ì´ ì˜¬ë°”ë¥¸ í™•ë¥ ì„ ë°˜í™˜í•˜ì§€ ëª»í•  ê²ƒì´ë‹¤. ê·¸ëŸ¬ë‚˜ ì—­ì „íŒŒë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì¼ë ¨ì˜ ë°˜ë³µí•™ìŠµì„ í†µí•´ í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ì˜ ê°€ì¤‘ì¹˜ì™€ BERT ì¸ì½”ë” ê³„ì¸µì˜ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ê³  ìµœì ì˜ ê°€ì¤‘ì¹˜ë¥¼ í•™ìŠµí•˜ê²Œ ëœë‹¤.2.4.3 ì‚¬ì „ í•™ìŠµ ì ˆì°¨BERTì˜ ì‚¬ì „ í•™ìŠµì—ëŠ” í† ë¡ í†  ì±… ë§ë­‰ì¹˜ ë° ìœ„í‚¤í”¼ë””ì•„ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•œë‹¤. ì•ì„œ BERTëŠ” MLM ë° NSP íƒœìŠ¤í¬ë¥¼ ì‚¬ìš©í•´ ì‚¬ì „ í•™ìŠµëœë‹¤ëŠ” ê²ƒì„ ë°°ì› ë‹¤. ê·¸ëŸ¼, ì´ ë‘ íƒœìŠ¤í¬ë¥¼ ì‚¬ìš©í•´ BERTë¥¼ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•œ ë°ì´í„°ì…‹ì„ ì–´ë–»ê²Œ ì¤€ë¹„í• ê¹Œ?ë¨¼ì € ë§ë­‰ì¹˜ì—ì„œ ë‘ ë¬¸ì¥ì„ ìƒ˜í”Œë§í•œë‹¤. Aì™€ Bë¬¸ì¥ì„ ìƒ˜í”Œë§í–ˆë‹¤ê³  ê°€ì •í•´ë³´ì. Aì™€ B ë¬¸ì¥ì˜ ì´ í† í° ìˆ˜ì˜ í•©ì€ 512ë³´ë‹¤ ì‘ê±°ë‚˜ ê°™ì•„ì•¼ í•œë‹¤. ë‘ ë¬¸ì¥ì„ ìƒ˜í”Œë§í•  ë•Œ ì „ì²´ì˜ 50%ëŠ” B ë¬¸ì¥ì´ A ë¬¸ì¥ì˜ í›„ì† ë¬¸ì¥ì´ ë˜ë„ë¡ ìƒ˜í”Œë§í•˜ê³ , ë‚˜ë¨¸ì§€ 50%ëŠ” B ë¬¸ì¥ì„ A ë¬¸ì¥ì˜ í›„ì† ë¬¸ì¥ì´ ì•„ë‹Œ ê²ƒìœ¼ë¡œ ìƒ˜í”Œë§í•œë‹¤.ë‹¤ìŒ ë‘ ë¬¸ì¥ì„ ìƒ˜í”Œë§í–ˆë‹¤ê³  ê°€ì •í•˜ì. A ë¬¸ì¥: We enjoyed the game. B ë¬¸ì¥: Turn the radio on.ë¨¼ì € ì›Œë“œí”¼ìŠ¤ í† í¬ë‚˜ì´ì €ë¥¼ í†µí•´ ë¬¸ì¥ì„ í† í°í™”í•˜ê³  ì²« ë²ˆì§¸ ë¬¸ì¥ ì‹œì‘ ë¶€ë¶„ì— [CLS] í† í°ì„ ì¶”ê°€í•œ ë‹¤ìŒ ëª¨ë“  ë¬¸ì¥ì˜ ëì— [SEP] í† í°ì„ ì¶”ê°€í•´, ë‹¤ìŒê³¼ ê°™ì€ í† í° ë¦¬ìŠ¤íŠ¸ë¥¼ ì–»ëŠ”ë‹¤.tokens = [\"[CLS]\", \"we\", \"enjoyed\", \"the\", \"game\", \"[SEP]\", \"turn\", \"the\", \"radio\", \"on\", \"[SEP]\"]ë‹¤ìŒ ê³¼ì •ìœ¼ë¡œ, 80-10-10% ê·œì¹™ì— ë”°ë¼ í† í°ì˜ 15%ë¥¼ ë¬´ì‘ìœ„ë¡œ ë§ˆìŠ¤í‚¹í•œë‹¤. game í† í°ì„ ë§ˆìŠ¤í‚¹í–ˆë‹¤ê³  ê°€ì •í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.tokens = [\"[CLS]\", \"we\", \"enjoyed\", \"the\", \"[MASK]\", \"[SEP]\", \"turn\", \"the\", \"radio\", \"on\", \"[SEP]\"]ì´ì œ í† í°ì„ BERTì— ì…ë ¥í•˜ê³  ë§ˆìŠ¤í¬ëœ í† í°ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ë©° ë™ì‹œì— B ë¬¸ì¥ì´ A ë¬¸ì¥ì˜ í›„ì† ë¬¸ì¥ì¸ì§€ ì—¬ë¶€ë¥¼ ë¶„ë¥˜í•˜ê²Œ í•œë‹¤. ì¦‰, MLMê³¼ NSP ì‘ì—…ì„ ë™ì‹œì— ì‚¬ìš©í•´ BERTë¥¼ í•™ìŠµì‹œí‚¨ë‹¤.BERTëŠ” ì´ 100ë§Œ ìŠ¤í…ì„ í•™ìŠµì‹œí‚¤ê³ , ê° ìŠ¤í…ë‹¹ í¬ê¸° 256 ì…ë ¥ ì‹œí€€ìŠ¤ì— ëŒ€í•´ í•™ìŠµì‹œí‚¨ë‹¤. í•™ìŠµë¥ ì€ $lr=1e-4, \\beta_1=0.9, \\beta_2=0.999$ë¡œ ì„¤ì •í•˜ê³  ì•„ë‹´ ì˜µí‹°ë§ˆì´ì €ë¥¼ ì‚¬ìš©í•˜ë©°, ì›œì—…ì€ 1ë§Œ ìŠ¤í…ìœ¼ë¡œ í•™ìŠµì„ ì§„í–‰í•œë‹¤. ì—¬ê¸°ì„œ ì›œì—… ìŠ¤í…ì€ ë¬´ì—‡ì¼ê¹Œ?í•™ìŠµì´ ì§„í–‰ë˜ë©´, ë†’ì€ í•™ìŠµë¥ ì„ ì„¤ì •í•´ í•™ìŠµ ì´ˆê¸°ì— ëª¨ë¸ì˜ í° ë³€í™”ë¥¼ ìœ ë„í•˜ê³  í•™ìŠµ í›„ë°˜ì—ëŠ” ë‚®ì€ í•™ìŠµë¥ ì„ ì„¤ì •í•´ ëª¨ë¸ì— ì‘ì€ ë³€í™”ë¥¼ ì£¼ì–´ ìµœì í™”í•œë‹¤. í•™ìŠµ ì´ˆê¸°ì—ëŠ” ìˆ˜ë ´ê³¼ ê±°ë¦¬ê°€ ë©€ê¸° ë•Œë¬¸ì— ëª¨ë¸ì— ê³¼ê°í•œ ë³€í™”ë¥¼ ì£¼ì§€ë§Œ ì´í›„ì—ëŠ” ìˆ˜ë ´ì— ê°€ê¹Œì›Œì§€ê¸° ë•Œë¬¸ì— í° ë³€í™”ë³´ë‹¤ ì‘ì€ ë³€í™”ë¥¼ ì£¼ì–´ ëª¨ë¸ì„ ìµœì í™” í•˜ëŠ” ê²ƒì´ë‹¤. ì´ì™€ ê°™ì´ í•™ìŠµ ì´ˆê¸°ì— í•™ìŠµë¥  ê°’ì„ ë†’ê²Œ ì„¤ì •í•œ ë‹¤ìŒ í•™ìŠµì´ ì§„í–‰ë˜ë©´ì„œ í•™ìŠµë¥ ì„ ê°ì†Œì‹œí‚¤ëŠ” ê²ƒì„ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§ì´ë¼ê³  í•œë‹¤.ì›œì—… ìŠ¤í…ì€ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§ì˜ ì¼ë¶€ë‹¤. í•™ìŠµë¥ ì´ $lr=1e-4$ê³  ì›œì—… ìŠ¤í…ì´ ì´ 1ë§Œ ìŠ¤í…ì´ë¼ê³  ê°€ì •í•˜ë©´, ì´ˆê¸° 1ë§Œ ìŠ¤í…ì€ í•™ìŠµë¥ ì´ 0ì—ì„œ $1e-4$ë¡œ ì„ í˜•ì ìœ¼ë¡œ ì¦ê°€í•œë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤. 1ë§Œ ìŠ¤í… í›„ì—ëŠ” ìˆ˜ë ´ì— ê°€ê¹Œì›Œì§ì— ë”°ë¼ í•™ìŠµë¥ ì„ ì„ í˜•ì ìœ¼ë¡œ ê°ì†Œì‹œí‚¤ê²Œ ëœë‹¤.ë˜í•œ ë“œë¡­ì•„ì›ƒí™•ë¥ ì´ 0.1ì¸ ëª¨ë“  ë ˆì´ì–´ì— ë“œë¡­ì•„ì›ƒì„ ì ìš©í•œë‹¤. BERTì—ì„œëŠ” GELUë¼ëŠ” í™œì„±í™” í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ”ë°, ì´ëŠ” ê°€ìš°ì‹œì•ˆ ì˜¤ì°¨ ì„ í˜• ìœ ë‹›(Gaussian Error Linear Unit)ì„ ì˜ë¯¸í•œë‹¤.GELU í•¨ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.\\[GELU(x)=x\\phi(x)\\]$\\phi(x)$ëŠ” í‘œì¤€ ê°€ìš°ì‹œì•ˆ ëˆ„ì  ë¶„í¬(standard Gaussian cummulative distribution)í•¨ìˆ˜ì´ë©°, GELU í•¨ìˆ˜ëŠ” ë‹¤ìŒ ìˆ˜ì‹ì˜ ê·¼ì‚¬ì¹˜ë‹¤.\\[GELU(x)=0.5x(1+\\tanh(\\sqrt{2\\over\\pi}(x+0.044715x^3)))\\][ê·¸ë¦¼ 2-18]ì€ GELU í•¨ìˆ˜ë¥¼ ë„ì‹í™” í•œ ê²ƒì´ë‹¤. ê·¸ë¦¼ 2-18 GELU í™œì„±í™” í•¨ìˆ˜ì´ê²Œ ì „ë¶€ë‹¤. ì´ëŸ¬í•œ ë°©ì‹ìœ¼ë¡œ MLM ë° NSP íƒœìŠ¤í¬ë¥¼ ì‚¬ìš©í•´ BERTë¥¼ ì‚¬ì „ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆë‹¤. ì‚¬ì „ í•™ìŠµëœ BERTëŠ” ë‹¤ì–‘í•œ íƒœìŠ¤í¬ì— ì´ìš©í•  ìˆ˜ ìˆë‹¤." }, { "title": "BERTì˜ êµ¬ì¡°", "url": "/posts/bert-structure/", "categories": "NLP, BERT", "tags": "nlp, bert", "date": "2022-09-09 12:30:00 +0900", "snippet": "BERT ë…¼ë¬¸ ì €ìë“¤ì€ ì•„ë˜ì™€ ê°™ì´ ë‘ ê°€ì§€ êµ¬ì„±ì˜ ëª¨ë¸ì„ ì œì‹œí–ˆë‹¤. BERT-base BERT-largeê°ê°ì„ ìì„¸íˆ ì•Œì•„ë³´ì.2.3.1 BERT-baseBERT-baseëŠ” 12ê°œì˜ ì¸ì½”ë” ë ˆì´ì–´ê°€ ìŠ¤íƒì²˜ëŸ¼ ìŒ“ì¸ í˜•íƒœë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ëª¨ë“  ì¸ì½”ë”ëŠ” 12ê°œì˜ ì–´í…ì…˜ í—¤ë“œë¥¼ ì‚¬ìš©í•˜ë©°, ì¸ì½”ë”ì˜ í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ëŠ” 768ê°œ ì°¨ì›ì˜ ì€ë‹‰ ìœ ë‹›ìœ¼ë¡œ êµ¬ì„±ëœë‹¤. ë”°ë¼ì„œ BERT-baseì—ì„œ ì–»ì€ í‘œí˜„ì˜ í¬ê¸°ëŠ” 768ì´ë‹¤.ì•ìœ¼ë¡œ ë‹¤ìŒ í‘œê¸°ë²•ì„ ì‚¬ìš©í•  ê²ƒì´ë‹¤. ì¸ì½”ë” ë ˆì´ì–´ì˜ ìˆ˜ëŠ” $L$ë¡œ í‘œì‹œí•  ê²ƒì´ë‹¤. ì–´í…ì…˜ í—¤ë“œëŠ” $A$ë¡œ í‘œì‹œí•œë‹¤. ì€ë‹‰ ìœ ë‹›ì€ $H$ë¡œ í‘œì‹œí•œë‹¤.BERT-base ëª¨ë¸ì€ $(L, A, H)=(12, 12, 768)$ ê°€ ë˜ë©°, ì´ ë³€ìˆ˜ì˜ ìˆ˜ëŠ” 1ì–µ 1ì²œë§Œ ê°œë‹¤. [ê·¸ë¦¼ 2-5]ëŠ” BERT-base ëª¨ë¸ì„ ì‹œê°í™” í•œ ê²ƒì´ë‹¤. ê·¸ë¦¼ 2-5 BERT-base2.3.2 BERT-largeBERT-largeëŠ” 24ê°œì˜ ì¸ì½”ë” ë ˆì´ì–´ê°€ ìŠ¤íƒì²˜ëŸ¼ ìŒ“ì¸ í˜•íƒœë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ëª¨ë“  ì¸ì½”ë”ëŠ” 16ê°œì˜ ì–´í…ì…˜ í—¤ë“œë¥¼ ì‚¬ìš©í•˜ë©°, ì¸ì½”ë”ì˜ í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ëŠ” 1024ê°œì˜ ì€ë‹‰ ìœ ë‹›ìœ¼ë¡œ êµ¬ì„±ëœë‹¤. ë”°ë¼ì„œ BERT-largeì—ì„œ ì–»ì€ í‘œí˜„ì˜ í¬ê¸°ëŠ” 1024ê°€ ëœë‹¤.BERT-large ëª¨ë¸ì€ $(L, A, H)=(24, 16, 1024)$ê°€ ë˜ë©°, ì´ ë³€ìˆ˜ì˜ ìˆ˜ëŠ” 3ì–µ 4ì²œë§Œ ê°œë‹¤. [ê·¸ë¦¼ 2-6]ì€ BERT-large ëª¨ë¸ì„ ì‹œê°í™” í•œ ê²ƒì´ë‹¤. ê·¸ë¦¼ 2-6 BERT-large2.3.3 ê·¸ ë°–ì˜ ì—¬ëŸ¬ BERT êµ¬ì¡°ì•ì˜ ë‘ ê°€ì§€ í‘œì¤€ êµ¬ì¡° ì™¸ì—ë„ ë‹¤ë¥¸ ì¡°í•©ìœ¼ë¡œ BERTë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆë‹¤. ë” ì‘ì€ êµ¬ì¡° ì¤‘ ì¼ë¶€ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. BERT-tiny: $(L, A, H)=(2, 2, 128)$ BERT-mini: $(L, A, H)=(4, 4, 256)$ BERT-small: $(L, A, H)=(4, 8, 521)$ BERT-medium: $(L, A, H)=(8, 8, 521)$ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤ê°€ ì œí•œëœ í™˜ê²½ì—ì„œëŠ” ë” ì‘ì€ BERTê°€ ì í•©í•  ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ BERT-base, BERT-largeì™€ ê°™ì€ í‘œì¤€ êµ¬ì¡°ê°€ ë” ì •í™•í•œ ê²°ê³¼ë¥¼ ì œê³µí•˜ê¸° ë•Œë¬¸ì— ê°€ì¥ ë„ë¦¬ ì‚¬ìš©ë˜ê³  ìˆë‹¤." }, { "title": "BERTì˜ ë™ì‘ ë°©ì‹", "url": "/posts/bert-act/", "categories": "NLP, BERT", "tags": "nlp, bert", "date": "2022-09-09 12:20:00 +0900", "snippet": "ì´ë¦„ì—ì„œ ì•Œ ìˆ˜ ìˆë“¯ì´ BERTëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©°, ì¸ì½”ë”-ë””ì½”ë”ê°€ ìˆëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ê³¼ ë‹¬ë¦¬ ì¸ì½”ë”ë§Œ ì‚¬ìš©í•œë‹¤.1ì¥ì—ì„œ ë¬¸ì¥ì„ íŠ¸ëœìŠ¤í¬ë¨¸ ì¸ì½”ë”ì— ì…ë ¥í•˜ê³  ë¬¸ì¥ì˜ ê° ë‹¨ì–´ì— ëŒ€í•œ í‘œí˜„ ë²¡í„°ë¥¼ ì¶œë ¥ìœ¼ë¡œ ë°˜í™˜í•œë‹¤ëŠ” ê²ƒì„ í™•ì¸í–ˆë‹¤. ê·¸ëŸ¼, ì–‘ë°©í–¥ (Bidirectional)ì´ë¼ëŠ” ë‹¨ì–´ëŠ” ë¬´ì—‡ì„ ì˜ë¯¸í• ê¹Œ?íŠ¸ëœìŠ¤í¬ë¨¸ ì¸ì½”ë”ëŠ” ì›ë˜ ì–‘ë°©í–¥ìœ¼ë¡œ ë¬¸ì¥ì„ ì½ì„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ì–‘ë°©í–¥ì´ë‹¤. ë”°ë¼ì„œ BERTëŠ” ê¸°ë³¸ì ìœ¼ë¡œ íŠ¸ëœìŠ¤í¬ë¨¸ì—ì„œ ì–»ì€ ì–‘ë°©í–¥ ì¸ì½”ë” í‘œí˜„ì´ë‹¤.ì˜ˆì œë¥¼ í†µí•´ BERTê°€ ì–´ë–»ê²Œ íŠ¸ëœìŠ¤í¬ë¨¸ì—ì„œ ì–‘ë°©í–¥ ì¸ì½”ë” í‘œí˜„ì„ í•˜ëŠ”ì§€ ì´ì „ ì ˆì—ì„œ ì‚´í´ë³¸ ë¬¸ì¥ìœ¼ë¡œ ì´í•´í•´ë³´ì.â€œHe got bit by Pythonâ€ ì´ë¼ëŠ” ë¬¸ì¥ Aë¥¼ íŠ¸ëœìŠ¤í¬ë¨¸ì— ì…ë ¥ìœ¼ë¡œ ì œê³µí•˜ê³  ë¬¸ì¥ì˜ ê° ë‹¨ì–´ì— ëŒ€í•œ ë¬¸ë§¥ í‘œí˜„ (ì„ë² ë”©)ì„ ì¶œë ¥ìœ¼ë¡œ ê°€ì ¸ì˜¨ë‹¤. ì¸ì½”ë”ì— ë¬¸ì¥ì„ ì…ë ¥í•˜ë©´ ì¸ì½”ë”ëŠ” ë©€í‹° í—¤ë“œ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•´ ë¬¸ì¥ì˜ ê° ë‹¨ì–´ì˜ ë¬¸ë§¥ì„ ì´í•´í•´ ë¬¸ì¥ì— ìˆëŠ” ê° ë‹¨ì–´ì˜ ë¬¸ë§¥ í‘œí˜„ì„ ì¶œë ¥ìœ¼ë¡œ ë°˜í™˜í•œë‹¤.[ê·¸ë¦¼ 2-3]ê³¼ ê°™ì´ ë¬¸ì¥ì„ íŠ¸ëœìŠ¤í¬ë¨¸ ì¸ì½”ë”ì— ì…ë ¥ìœ¼ë¡œ ì œê³µí•˜ê³  ë¬¸ì¥ì˜ ê° ë‹¨ì–´ë¥¼ ì¶œë ¥ìœ¼ë¡œ í‘œì‹œí–ˆë‹¤. ê·¸ë¦¼ê³¼ ê°™ì´ Nê°œì˜ ì¸ì½”ë”ë¥¼ ìŒ“ì„ ìˆ˜ ìˆìœ¼ë‚˜, ë¶ˆí•„ìš”í•œ ë³µì¡í•¨ì„ ì¤„ì´ê¸° ìœ„í•´ í•˜ë‚˜ì˜ ë¸”ë¡ë§Œ í™•ì¥í–ˆë‹¤. [ê·¸ë¦¼ 2-3]ì—ì„œ â€œíŒŒì´ì¬â€ì´ë¼ëŠ” ë‹¨ì–´ì˜ í‘œí˜„ì„ ì¶œë ¥í•˜ê³  ì°¨ë¡€ë¡œ â€œê·¸(the)â€ë¼ëŠ” ë‹¨ì–´ì˜ í‘œí˜„ì„ ì¶œë ¥í•œë‹¤. ê° í† í°ì˜ í‘œí˜„ í¬ê¸°ëŠ” ì¸ì½”ë” ë ˆì´ì–´ì˜ ì¶œë ¥ì˜ ì°¨ì›ì´ë©°, ì¸ì½”ë” ë ˆì´ì–´ì˜ ì°¨ì›ì´ 768ì´ë¼ê³  ê°€ì •í•˜ë©´ ê° í† í°ì˜ í‘œí˜„ í¬ê¸°ëŠ” 768ì´ ëœë‹¤. ê·¸ë¦¼ 2-3 BERTì— ì…ë ¥ëœ A ë¬¸ì¥ì˜ ê° ë‹¨ì–´ í‘œí˜„ ì¶œë ¥ë§ˆì°¬ê°€ì§€ë¡œ , â€œPython is my favorite programming languageâ€ë¼ëŠ” B ë¬¸ì¥ì„ íŠ¸ëœìŠ¤í¬ë¨¸ ì¸ì½”ë”ì— ì…ë ¥í•˜ë©´ ê·¸[ê·¸ë¦¼ 2-4]ì™€ ê°™ì´ ë¬¸ì¥ì˜ ê° ë‹¨ì–´ì— ëŒ€í•œ ë¬¸ë§¥ í‘œí˜„ì„ ì–»ì„ ìˆ˜ ìˆë‹¤. ê·¸ë¦¼ 2-4 BERTì— ì…ë ¥ëœ B ë¬¸ì¥ì˜ ê° ë‹¨ì–´ í‘œí˜„ ì¶œë ¥" }, { "title": "BERTì˜ ê¸°ë³¸ ê°œë…", "url": "/posts/bert-basic/", "categories": "NLP, BERT", "tags": "nlp, bert", "date": "2022-09-09 12:10:00 +0900", "snippet": "BERT (Bidirectional Encoder Representation from Transformer)ëŠ” êµ¬ê¸€ì—ì„œ ë°œí‘œí•œ ìµœì‹  ì„ë² ë”© ëª¨ë¸ì´ë‹¤. ì§ˆë¬¸ì— ëŒ€í•œ ëŒ€ë‹µ, í…ìŠ¤íŠ¸ ìƒì„±, ë¬¸ì¥ ë¶„ë¥˜ ë“±ê³¼ ê°™ì€ íƒœìŠ¤í¬ì—ì„œ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë„ì¶œí•´ ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ì— í¬ê²Œ ê¸°ì—¬í–ˆë‹¤. BERTê°€ ì„±ê³µí•œ ì£¼ëœ ì´ìœ ëŠ” ë¬¸ë§¥ì´ ì—†ëŠ” ì›Œë“œíˆ¬ë²¡í„°ì™€ ê°™ì€ ë‹¤ë¥¸ ì¸ê¸° ìˆëŠ” ì„ë² ë”© ëª¨ë¸ê³¼ ë‹¬ë¦¬ ë¬¸ë§¥ì„ ê³ ë ¤í•œ ì„ë² ë”© ëª¨ë¸ì´ê¸° ë•Œë¬¸ì´ë‹¤.ë¨¼ì € ë‹¤ìŒ ë‘ ë¬¸ì¥ì„ í†µí•´ ë¬¸ë§¥ ê¸°ë°˜ ì„ë² ë”© ëª¨ë¸ê³¼ ë¬¸ë§¥ ë…ë¦½ ì„ë² ë”© ëª¨ë¸ì˜ ì°¨ì´ë¥¼ ì´í•´í•´ ë³´ì. A ë¬¸ì¥: He got bit by Pythob (íŒŒì´ì¬ì´ ê·¸ë¥¼ ë¬¼ì—ˆë‹¤.) B ë¬¸ì¥: Python is my favorite programming language (ë‚´ê°€ ê°€ì¥ ì¢‹ì•„í•˜ëŠ” í”„ë¡œê·¸ë˜ë° ì–¸ì–´ëŠ” íŒŒì´ì¬ì´ë‹¤).ë‘ ë¬¸ì¥ì—ì„œ â€œíŒŒì´ì¬â€ ì´ë¼ëŠ” ë‹¨ì–´ì˜ ì˜ë¯¸ê°€ ì„œë¡œ ë‹¤ë¥´ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. A ë¬¸ì¥ì—ì„œ â€œíŒŒì´ì¬â€ì´ë¼ëŠ” ë‹¨ì–´ëŠ” ë±€ì˜ í•œ ì¢…ë¥˜ë¥¼ ì˜ë¯¸í•˜ê³  B ë¬¸ì¥ì—ì„œ â€œíŒŒì´ì¬â€ì´ë¼ëŠ” ë‹¨ì–´ëŠ” í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¥¼ ì˜ë¯¸í•œë‹¤.ì›Œë“œíˆ¬ë²¡í„°ì™€ ê°™ì€ ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•´ ì•ì˜ ë‘ ë¬¸ì¥ì—ì„œ â€œíŒŒì´ì¬â€ ì´ë¼ëŠ” ë‹¨ì–´ì— ëŒ€í•œ ì„ë² ë”©ì„ ì–»ëŠ” ê²½ìš° ë‘ ë¬¸ì¥ì—ì„œ ë™ì¼í•œ ë‹¨ì–´ê°€ ì“°ì˜€ìœ¼ë¯€ë¡œ ë™ì¼í•˜ê²Œ í‘œí˜„í•˜ê²Œ ëœë‹¤. ì´ëŠ” ì›Œë“œíˆ¬ë²¡í„°ê°€ ë¬¸ë§¥ ë…ë¦½ ëª¨ë¸ì´ê¸° ë•Œë¬¸ì— ë¬¸ë§¥ê³¼ ê´€ê³„ì—†ì´ â€œíŒŒì´ì¬â€ì´ë¼ëŠ” ë‹¨ì–´ì— ëŒ€í•´ í•­ìƒ ë™ì¼í•œ ì„ë² ë”©ì„ ì œê³µí•˜ê¸° ë•Œë¬¸ì´ë‹¤.ë°˜ë©´ BERTëŠ” ë¬¸ë§¥ê¸°ë°˜ëª¨ë¸ì´ë¯€ë¡œ ë¬¸ì¥ì˜ ë¬¸ë§¥ì„ ì´í•´í•œ ë‹¤ìŒ ë¬¸ë§¥ì— ë”°ë¼ ë‹¨ì–´ ì„ë² ë”©ì„ ìƒì„±í•œë‹¤. ë”°ë¼ì„œ ì•ì˜ ë‘ ë¬¸ì¥ì˜ ë¬¸ë§¥ì„ ê¸°ë°˜ìœ¼ë¡œ â€œíŒŒì´ì¬â€ì´ë¼ëŠ” ë‹¨ì–´ì— ëŒ€í•´ ì„œë¡œ ë‹¤ë¥¸ ì„ë² ë”©ì„ ì œê³µí•œë‹¤. ê·¸ëŸ°ë° BERTëŠ” ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ” ê²ƒì¼ê¹Œ? ë¬¸ë§¥ì„ ì–´ë–»ê²Œ ì´í•´í• ê¹Œ? ì´ì— ëŒ€í•´ ë” ìì„¸íˆ ì‚´í´ë³´ì.A ë¬¸ì¥ ( He got bit by Python)ì„ ë³´ì. BERTëŠ” ëª¨ë“  ë‹¨ì–´ì™€ ë¬¸ë§¥ìƒ ì˜ë¯¸ë¥¼ ì´í•´í•˜ê¸° ìœ„í•´ ë¬¸ì¥ì˜ ê° ë‹¨ì–´ë¥¼ ë¬¸ì¥ì˜ ë‹¤ë¥¸ ëª¨ë“  ë‹¨ì–´ì™€ ì—°ê²°ì‹œì¼œ ì´í•´í•œë‹¤. ë”°ë¼ì„œ â€œíŒŒì´ì¬â€ì´ë¼ëŠ” ë‹¨ì–´ì™€ ë¬¸ë§¥ìƒ ì˜ë¯¸ë¥¼ ì´í•´í•˜ê¸° ìœ„í•´ ë¬¸ì¥ì˜ ë‹¤ë¥¸ ëª¨ë“  ë‹¨ì–´ì™€ ê´€ê³„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì´í•´í•˜ë ¤ ì‹œë„í•œë‹¤. ì´ë ‡ê²Œ í•˜ë©´ BERTëŠ” A ë¬¸ì¥ì˜ â€œíŒŒì´ì¬â€ì´ë¼ëŠ” ë‹¨ì–´ì™€ â€œë¬¼ì—ˆë‹¤â€ë¼ëŠ” ë‹¨ì–´ì˜ ê°•í•œ ì—°ê²° ê´€ê³„ë¥¼ íŒŒì•…í•´ â€œíŒŒì´ì¬â€ì´ ë±€ì˜ í•œ ì¢…ë¥˜ë¥¼ ì˜ë¯¸í•œë‹¤ëŠ” ê²ƒì„ íŒŒì•…í•˜ê²Œ ëœë‹¤. ê·¸ë¦¼ 2-1 íŒŒì´ì¬ê³¼ ë‹¤ë¥¸ ëª¨ë“  ë‹¨ì–´ì˜ ê´€ê³„ì´ì œ B ë¬¸ì¥ (Python is my favorite programming language)ì„ ë³´ì. ë§ˆì°¬ê°€ì§€ë¡œ ì—¬ê¸°ì„œ BERTëŠ” ëª¨ë“  ë‹¨ì–´ì˜ ë¬¸ë§¥ìƒ ì˜ë¯¸ë¥¼ ì´í•´í•˜ê¸° ìœ„í•´ ë¬¸ì¥ì˜ ê° ë‹¨ì–´ë¥¼ ë¬¸ì¥ì˜ ëª¨ë“  ë‹¨ì–´ì™€ ì—°ê²°í•œë‹¤. ë”°ë¼ì„œ BERTëŠ” â€œíŒŒì´ì¬â€ì´ë¼ëŠ” ë‹¨ì–´ë¥¼ ê°€ì ¸ì™€ì„œ ì´ ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ì´í•´í•˜ê¸° ìœ„í•´ ë¬¸ì¥ì˜ ëª¨ë“  ë‹¨ì–´ì™€ ì—°ê²°í•œë‹¤. ì´ë ‡ê²Œ í•¨ìœ¼ë¡œì¨ BERTëŠ” Bë¬¸ì¥ì˜ â€œíŒŒì´ì¬â€ì´ë¼ëŠ” ë‹¨ì–´ê°€ â€œí”„ë¡œê·¸ë˜ë°â€ ì´ë¼ëŠ” ë‹¨ì–´ì™€ í•¨ê»˜ ì‚¬ìš©ë˜ê³  ìˆìœ¼ë¯€ë¡œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì™€ ê´€ë ¨ì´ ìˆìŒì„ ì¸ì§€í•˜ê²Œ ëœë‹¤. ê·¸ë¦¼ 2-2 íŒŒì´ì¬ê³¼ ë‹¤ë¥¸ ëª¨ë“  ë‹¨ì–´ì˜ ê´€ê³„ë¬¸ë§¥ ë…ë¦½ ëª¨ë¸ê³¼ ë‹¬ë¦¬ ë¬¸ë§¥ê³¼ ê´€ê³„ ì—†ì´ ì •ì  ì„ë² ë”©ì„ ìƒì„±í•˜ëŠ” ì›Œë“œíˆ¬ë²¡í„°ì™€ ë‹¬ë¦¬ BERTëŠ” ë¬¸ë§¥ì„ ê¸°ë°˜ìœ¼ë¡œ ë™ì  ì„ë² ë”©ì„ ìƒì„±í•œë‹¤." }, { "title": "íŠ¸ëœìŠ¤í¬ë¨¸-ì¸ì½”ë” ë””ì½”ë” ê²°í•©", "url": "/posts/transformer-endecoder/", "categories": "NLP, TRANSFORMER", "tags": "nlp, transformer, encoder, decoder", "date": "2022-09-09 12:00:00 +0900", "snippet": "ì¸ì½”ë”ì™€ ë””ì½”ë”ë¥¼ í¬í•¨í•œ ì™„ì „í•œ ëª¨ì–‘ì˜ íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. ê·¸ë¦¼ 1-63 íŠ¸ëœìŠ¤í¬ë¨¸ ì¸ì½”ë”, ë””ì½”ë”$N \\times$ ëŠ” ì¸ì½”ë”ì™€ ë””ì½”ë”ë¥¼ $N$ê°œ ìŒ“ì„ ìˆ˜ ìˆìŒìœ¼ë¡œ ë‚˜íƒ€ë‚¸ë‹¤. [ê·¸ë¦¼ 1-63]ì—ì„œ ì•Œ ìˆ˜ ìˆë“¯ì´, ì…ë ¥ ë¬¸ì¥ (ì†ŒìŠ¤ ë¬¸ì¥)ì„ ì…ë ¥í•˜ë©´ ì¸ì½”ë”ì—ì„œëŠ” í•´ë‹¹ ë¬¸ì¥ì— ëŒ€í•œ í‘œí˜„ì„ í•™ìŠµì‹œí‚¤ê³ , ê·¸ ê²°ê´ê°’ì„ ë””ì½”ë”ì— ë³´ë‚´ë©´ ë””ì½”ë”ì—ì„œ íƒ€ê¹ƒ ë¬¸ì¥ì„ ìƒì„±í•œë‹¤.1.5 íŠ¸ëœìŠ¤í¬ë¨¸ í•™ìŠµì†ì‹¤ í•¨ìˆ˜ (loss function)ì„ ìµœì†Œí™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ íŠ¸ëœìŠ¤í¬ë¨¸ ë„¤íŠ¸ì›Œí¬ë¥¼ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆë‹¤. ì´ë•Œ ì–´ë–¤ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ì•¼ í• ê¹Œ? ë””ì½”ë”ê°€ vocabì— ëŒ€í•œ í™•ë¥  ë¶„í¬ë¥¼ ì˜ˆì¸¡í•˜ê³  í™•ë¥ ì´ ê°€ì¥ í° ë‹¨ì–´ë¥¼ ì„ íƒí•œë‹¤ëŠ” ê²ƒì„ ë°°ì› ë‹¤. ì¦‰, ì˜¬ë°”ë¥¸ ë¬¸ì¥ì„ ìƒì„±í•˜ë ¤ë©´ ì˜ˆì¸¡ í™•ë¥  ë¶„í¬ì™€ ì‹¤ì œ í™•ë¥  ë¶„í¬ ì‚¬ì´ì˜ ì°¨ì´ë¥¼ ìµœì†Œí™”í•´ì•¼ í•œë‹¤. ê·¸ëŸ¬ë ¤ë©´ ë‘ ë¶„í¬ì˜ ì°¨ì´ë¥¼ ì•Œì•„ì•¼ í•œë‹¤. ì´ë•Œ êµì°¨ ì—”íŠ¸ë¡œí”¼ (cross entropy)ë¥¼ ì‚¬ìš©í•˜ë©´ ë¶„í¬ì˜ ì°¨ì´ë¥¼ ì•Œ ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ì†ì‹¤ í•¨ìˆ˜ë¥¼ êµì°¨ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤ (cross-entropy loss)ë¡œ ì •ì˜í•˜ê³  ì˜ˆì¸¡ í™•ë¥  ë¶„í¬ì™€ ì‹¤ì œ í™•ë¥  ë¶„í¬ë¥¼ ìµœì†Œí™”í•˜ë„ë¡ ëª¨ë¸ì„ í•™ìŠµí•œë‹¤. ì´ë•Œ ì˜µí‹°ë§ˆì´ì € (optimizer)ëŠ” ì•„ë‹´ (Adam)ì„ ì‚¬ìš©í•œë‹¤.ì—¬ê¸°ì„œ í•œ ê°€ì§€ ê³ ë ¤í•  ì ì€ overfittingì„ ë°©ì§€í•˜ë ¤ë©´ ê° ì„œë¸Œë ˆì´ì–´ì˜ ì¶œë ¥ì— ë“œë¡­ì•„ì›ƒì„ ì ìš©í•˜ê³ , ì„ë² ë”© ë° ìœ„ì¹˜ ì¸ì½”ë”©ì˜ í•©ì„ êµ¬í•  ë•Œë„ ë“œë¡­ì•„ì›ƒì„ ì ìš©í•´ì•¼ í•œë‹¤ëŠ” ê²ƒì´ë‹¤.1.6 ë§ˆì¹˜ë©°ì´ë²ˆ ì¥ì—ì„œëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì´ ë¬´ì—‡ì¸ì§€, ì¸ì½”ë”-ë””ì½”ë” ì•„í‚¤í…ì²˜ê°€ ì–´ë–¤ ì›ë¦¬ë¡œ ì‘ë™í•˜ëŠ”ì§€ë¥¼ ë‹¤ë¤˜ë‹¤. íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ì¸ì½”ë” ë¶€ë¶„ì„ ì‚´í´ë³´ë©´ì„œ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ê³¼ í”¼ë“œ í¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ ê°™ì€ ì¸ì½”ë”ì—ì„œ ì‚¬ìš©í•˜ëŠ” ë‹¤ì–‘í•œ ì„œë¸Œë ˆì´ì–´ë¥¼ í™•ì¸í–ˆë‹¤.ì…€í”„ ì–´í…ì…˜ì€ ë‹¨ì–´ë¥¼ ì¢€ ë” ì˜ ì´í•´í•˜ê¸° ìœ„í•´ ì£¼ì–´ì§„ ë¬¸ì¥ì˜ ëª¨ë“  ë‹¨ì–´ì™€ í•´ë‹¹ ë‹¨ì–´ë¥¼ ì—°ê²°í•˜ëŠ” í˜•íƒœë‹¤. ì…€í”„ ì–´í…ì…˜ì„ ê³„ì‚°í•˜ê¸° ìœ„í•´ ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ í–‰ë ¬ì´ë¼ëŠ” ì„¸ ê°€ì§€ í–‰ë ¬ì„ ì‚¬ìš©í–ˆë‹¤. ê·¸ ë‹¤ìŒìœ¼ë¡œ ìœ„ì¹˜ ì¸ì½”ë”©ì„ ê³„ì‚°í•˜ëŠ” ë°©ë²•ê³¼ ìœ„ì¹˜ ì¸ì½”ë”©ì„ ì‚¬ìš©í•´ ë¬¸ì¥ ë‚´ ë‹¨ì–´ì˜ ìˆœì„œë¥¼ ì…ë ¥í•˜ëŠ” ë°©ë²•ë„ ì‚´í´ë´¤ë‹¤. ì¸ì½”ë”ì—ì„œ í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ê°€ ì‘ë™í•˜ëŠ” ë°©ë²•ê³¼ add ë° norm ìš”ì†Œì— ëŒ€í•´ì„œë„ ë°°ì› ë‹¤.ì¸ì½”ë”ì— ëŒ€í•´ ì•Œì•„ë³¸ ë‹¤ìŒ ë””ì½”ë”ì˜ ì‘ë™ ì›ë¦¬ë¥¼ ì‚´í´ë´¤ë‹¤. ë§ˆìŠ¤í¬ëœ ë©€í‹° í—¤ë“œ ì–´í…ì…˜, ì¸ì½”ë”-ë””ì½”ë” ì–´í…ì…˜, í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ ë“± ë””ì½”ë”ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì„œë¸Œë ˆì´ì–´ë¥¼ ì•Œì•„ë´¤ë‹¤. íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ì¸ì½”ë”ì™€ ë””ì½”ë”ê°€ ê²°í•©í•œ í˜•íƒœì—ì„œ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ ì´í•´í•œ ë‹¤ìŒ ë„¤íŠ¸ì›Œí¬ë¥¼ í•™ìŠµì‹œí‚¤ëŠ” ë°©ë²•ë„ ë°°ì› ë‹¤." }, { "title": "íŠ¸ëœìŠ¤í¬ë¨¸-ë””ì½”ë”", "url": "/posts/transformer-decoder/", "categories": "NLP, TRANSFORMER", "tags": "nlp, transformer, decoder", "date": "2022-09-09 11:00:00 +0900", "snippet": "ì˜ì–´ â€œI am goodâ€ì„ ì…ë ¥í•˜ë©´ í”„ë‘ìŠ¤ì–´ â€œJe vais bienâ€ì„ ìƒì„±í•˜ëŠ” ë²ˆì—­ê¸°ë¥¼ ë§Œë“ ë‹¤ê³  ê°€ì •í•˜ì. ë²ˆì—­ê¸°ë¥¼ ë§Œë“¤ë ¤ë©´ ë¨¼ì € ì…ë ¥ ë¬¸ì¥ì¸ â€œI am goodâ€ì„ ì¸ì½”ë”ì— ì…ë ¥í•´ì•¼ í•œë‹¤. ì¸ì½”ë”ëŠ” ì…ë ¥ ë¬¸ì¥ì˜ í‘œí˜„ì„ í•™ìŠµí•œë‹¤. ì•ì—ì„œ ì¸ì½”ë”ê°€ ì…ë ¥ ë¬¸ì¥ì„ í•™ìŠµí•˜ëŠ” ë°©ë²•ì„ ìƒì„¸íˆ ë‹¤ë¤˜ë‹¤. ì´ì œ ì´ ì¸ì½”ë”ì˜ ê²°ê´ê°’ì„ ê°€ì ¸ì™€ì„œ ë””ì½”ë”ì— ì…ë ¥ê°’ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤. ë””ì½”ë”ëŠ” ë‹¤ìŒ ê·¸ë¦¼ê³¼ ê°™ì´ ì¸ì½”ë”ì˜ í‘œí˜„ì„ ì…ë ¥ê°’ìœ¼ë¡œ ì‚¬ìš©í•˜ê³  íƒ€ê¹ƒ ë¬¸ì¥ì¸ â€œJe vais beinâ€ì„ ìƒì„±í•œë‹¤. ê·¸ë¦¼ 1-35 íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ì¸ì½”ë”ì™€ ë””ì½”ë”ì¸ì½”ë” ë¶€ë¶„ì„ ë‹¤ë£° ë•Œ ì¸ì½”ë” $N$ê°œë¥¼ ëˆ„ì í•´ì„œ ìŒ“ì„ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ë°°ì› ë‹¤. ì¸ì½”ë”ì™€ ìœ ì‚¬í•˜ê²Œ ë””ì½”ë” ì—­ì‹œ $N$ê°œë¥¼ ëˆ„ì í•´ì„œ ìŒ“ì„ ìˆ˜ ìˆë‹¤. $N=2$ë¡œ ì˜ˆë¥¼ ë“¤ì–´ë³´ì. [ê·¸ë¦¼ 1-36]ì— í‘œì‹œëœ ê²ƒì²˜ëŸ¼ í•˜ë‚˜ì˜ ë””ì½”ë” ì¶œë ¥ê°’ì€ ê·¸ ìœ„ì— ìˆëŠ” ë””ì½”ë”ì˜ ì…ë ¥ê°’ìœ¼ë¡œ ì „ì†¡ëœë‹¤. ë˜í•œ ì¸ì½”ë”ì˜ ì…ë ¥ ë¬¸ì¥ í‘œí˜„ (ì¸ì½”ë”ì˜ ì¶œë ¥ê°’)ì´ ëª¨ë“  ë””ì½”ë”ì— ì „ì†¡ëœë‹¤. ì¦‰, ë””ì½”ë”ëŠ” ì´ì „ ë””ì½”ë”ì˜ ì…ë ¥ê°’ê³¼ ì¸ì½”ë”ì˜ í‘œí˜„(ì¸ì½”ë”ì˜ ì¶œë ¥ê°’), ì´ë ‡ê²Œ 2ê°œë¥¼ ì…ë ¥ ë°ì´í„°ë¡œ ë°›ëŠ”ë‹¤. ê·¸ë¦¼ 1-37 ì‹œê°„ ìŠ¤í… t=1 ê²½ìš° ë””ì½”ë” ì˜ˆì¸¡ì‹œê°„ ìŠ¤í… t=2 ê²½ìš° í˜„ì¬ê¹Œì§€ì˜ ì…ë ¥ê°’ì— ì´ì „ ë‹¨ê³„ (t-1) ë””ì½”ë”ì—ì„œ ìƒì„±í•œ ë‹¨ì–´ë¥¼ ì¶”ê°€í•´ ë¬¸ì¥ì˜ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ìƒì„±í•œë‹¤. ì¦‰ [ê·¸ë¦¼ 1-38]ì²˜ëŸ¼ ë””ì½”ë”ëŠ” &lt;sos&gt;ì™€ â€œJeâ€ë¥¼ ì…ë ¥ë°›ì•„ íƒ€ê¹ƒ ë¬¸ì¥ì˜ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ìƒì„±í•œë‹¤. ê·¸ë¦¼ 1-38 ì‹œê°„ ìŠ¤í… t=2 ê²½ìš° ë””ì½”ë” ì˜ˆì¸¡ìœ„ì˜ ë°©ë²•ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ëª¨ë“  ë‹¨ê³„ì—ì„œ ë””ì½”ë”ëŠ” ì´ì „ ë‹¨ê³„ì—ì„œ ìƒˆë¡œ ìƒì„±í•œ ë‹¨ì–´ë¥¼ ì¡°í•©í•´ ì…ë ¥ê°’ì„ ìƒì„±í•˜ê³  ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë°©ë²•ì„ ì§„í–‰í•œë‹¤. ë”°ë¼ì„œ $t=4$ì˜ ê²½ìš° &lt;sos&gt;, â€œJeâ€, â€œvaisâ€, â€œbienâ€ì„ ì…ë ¥í•˜ê³  ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•œë‹¤. ê·¸ë¦¼ 1-39 ì‹œê°„ ìŠ¤í… t=4 ê²½ìš° ë””ì½”ë” ì˜ˆì¸¡[ê·¸ë¦¼ 1-40]ì„ í†µí•´ ì•Œ ìˆ˜ìˆë“¯ì´ ë””ì½”ë”ì—ì„œ &lt;eos&gt; í† í°ì„ ìƒì„±í•  ë•Œ íƒ€ê¹ƒ ë¬¸ì¥ì˜ ìƒì„±ì´ ì™„ë£Œëœë‹¤.ì¸ì½”ë”ì˜ ê²½ìš°, ì…ë ¥ ë¬¸ì¥ì„ ì„ë² ë”© í–‰ë ¬ë¡œ ë³€í™˜í•œ í›„ ì—¬ê¸°ì— ìœ„ì¹˜ ì¸ì½”ë”©ì„ ë”í•œ ê°’ì„ ì…ë ¥í•œë‹¤. ë§ˆì°¬ê°€ì§€ë¡œ ë””ì½”ë” ì—­ì‹œ ì…ë ¥ê°’ì„ ë°”ë¡œ ì…ë ¥í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ìœ„ì¹˜ ì¸ì½”ë”©ì„ ì¶”ê°€í•œ ê°’ì„ ë””ì½”ë”ì˜ ì…ë ¥ê°’ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤.ì˜ˆë¥¼ ë“¤ì–´ [ê·¸ë¦¼ 1-41]ì²˜ëŸ¼ ê° ì‹œê°„ ë‹¨ê³„ì˜ ì…ë ¥ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•œë‹¤ê³  í•  ë•Œ ìœ„ì¹˜ ì¸ì½”ë”© ê°’ì„ ì¶”ê°€í•œ ë‹¤ìŒ ë””ì½”ë”ì— ì…ë ¥í•œë‹¤. ê·¸ë¦¼ 1-41 ìœ„ì¹˜ ì¸ì½”ë”©ì´ ì ìš©ëœ ì¸ì½”ë”ì™€ ë””ì½”ë”í•˜ë‚˜ì˜ ë””ì½”ë” ë¸”ë¡ì€ ë‹¤ìŒê³¼ ê°™ì€ ìš”ì†Œë“¤ë¡œ êµ¬ì„±ëœë‹¤. ê·¸ë¦¼ 1-42 ë””ì½”ë” ë¸”ë¡ë””ì½”ë” ë¸”ë¡ì€ ì„œë¸Œë ˆì´ì–´ 3ê°œë¡œ êµ¬ì„±ëœ ì¸ì½”ë” ë¸”ë¡ê³¼ ìœ ì‚¬í•œ êµ¬ì¡°ë‹¤. ë§ˆìŠ¤í¬ëœ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ (masked multi-head attention) ë©€í‹° í—¤ë“œ ì–´í…ì…˜ (multi-head attention) í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ (feedforward network)ë””ì½”ë” ë¸”ë¡ì€ ì¸ì½”ë” ë¸”ë¡ê³¼ ìœ ì‚¬í•˜ê²Œ ì„œë¸Œë ˆì´ì–´ì— ë©€í‹° í—¤ë“œ ì–´í…ì…˜ê³¼ í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ë¥¼ í¬í•¨í•œë‹¤. í•˜ì§€ë§Œ ì¸ì½”ë”ì™€ ë‹¤ë¥´ê²Œ ë‘ ê°€ì§€ í˜•íƒœì˜ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì„ ì‚¬ìš©í•œë‹¤. ê·¸ ì¤‘ í•˜ë‚˜ëŠ” ì–´í…ì…˜ ë¶€ë¶„ì¸ ë§ˆìŠ¤í¬ëœ í˜•íƒœì´ë‹¤.1.3.1 ë§ˆìŠ¤í¬ëœ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì˜ì–´ë¥¼ í”„ë‘ìŠ¤ì–´ë¡œ ë²ˆì—­í•˜ëŠ” íƒœìŠ¤í¬ê°€ ìˆê³ , í•™ìŠµ ë°ì´í„°ê°€ ë‹¤ìŒê³¼ ê°™ì´ ì¤€ë¹„ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•˜ì. ê·¸ë¦¼ 1-43 í•™ìŠµ ë°ì´í„° ì˜ˆì œìœ„ì˜ ë°ì´í„°ë¥¼ í†µí•´ ë²ˆì—­ íƒœìŠ¤í¬ì˜ ì…ë ¥ê³¼ ì¶œë ¥ í˜•íƒœë¥¼ ì´í•´í•  ìˆ˜ ìˆë‹¤. ì•ì—ì„œ ë²ˆì—­ ëª¨ë¸ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•  ë•Œ ë””ì½”ë”ì—ì„œ íƒ€ê¹ƒ ë¬¸ì¥ì„ ì–´ë–»ê²Œ ìƒì„±í•˜ëŠ”ì§€ ì•Œì•„ë´¤ë‹¤.ëª¨ë¸ì„ í•™ìŠµí•  ë•ŒëŠ” ì´ë¯¸ íƒ€ê¹ƒ ë¬¸ì¥ì„ ì•Œê³  ìˆì–´ì„œ ë””ì½”ë”ì— ê¸°ë³¸ìœ¼ë¡œ íƒ€ê¹ƒ ë¬¸ì¥ ì „ì²´ë¥¼ ì…ë ¥í•˜ë©´ ë˜ì§€ë§Œ ìˆ˜ì • ì‘ì—…ì´ ì¡°ê¸ˆ í•„ìš”í•˜ë‹¤. ë””ì½”ë”ì—ì„œ ë¬¸ì¥ì„ ì…ë ¥í•  ë•Œ ì²˜ìŒì—ëŠ” &lt;sos&gt; í† í°ì„ ì…ë ¥í•˜ê³  &lt;eos&gt; í† í°ì´ ìƒì„±ë  ë•Œê¹Œì§€ ì´ì „ ë‹¨ê³„ì—ì„œ ì˜ˆì¸¡í•œ ë‹¨ì–´ë¥¼ ì¶”ê°€í•˜ëŠ” í˜•íƒœë¡œ ì…ë ¥ì„ ë°˜ë³µí•œë‹¤. ë”°ë¼ì„œ íƒ€ê¹ƒ ë¬¸ì¥ì˜ ì‹œì‘ ë¶€ë¶„ì— &lt;sos&gt; í† í°ì„ ì¶”ê°€í•œ ë‹¤ìŒ ë””ì½”ë”ì— ì…ë ¥í•œë‹¤.â€œI am goodâ€ì„ â€œJe vais bienâ€ìœ¼ë¡œ ë²ˆì—­í•œë‹¤ê³  ê°€ì •í•´ë³´ì. íƒ€ê¹ƒ ë¬¸ì¥ ì‹œì‘ ë¶€ë¶„ì— &lt;sos&gt; í† í°ì„ ì¶”ê°€í•œ â€œ&lt;sos&gt; je vais bienâ€ì„ ë””ì½”ë”ì— ì…ë ¥í•˜ë©´ ë””ì½”ë”ì—ì„œ â€œJe vais bien &lt;eos&gt;â€ë¥¼ ì¶œë ¥í•œë‹¤. ê·¸ë¦¼ 1-44 íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ì¸ì½”ë”, ë””ì½”ë”ê·¸ë ‡ë‹¤ë©´ ì„¸ë¶€ì ìœ¼ë¡œ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì‘ë™í•˜ëŠ” ê²ƒì¸ê°€? ì™œ íƒ€ê¹ƒ ë¬¸ì¥ ì „ì²´ë¥¼ ì…ë ¥í•˜ê³  ë””ì½”ë”ì—ì„œëŠ” í•œ ë‹¨ê³„ ì´ë™í•œ í˜•íƒœì˜ ë¬¸ì¥ì„ ì¶œë ¥í•˜ëŠ” ê²ƒì¸ê°€? ì´ ë¶€ë¶„ì„ ì¢€ ë” ìì„¸íˆ ì•Œì•„ë³´ì.ë””ì½”ë”ì— ì…ë ¥ ë¬¸ì¥ì„ ì…ë ¥í•  ë•Œ ì…ë ¥ ë¬¸ì¥ì„ ì„ë² ë”© (ì¶œë ¥ ì„ë² ë”© í–‰ë ¬)ìœ¼ë¡œ ë³€í™˜í•œ í›„ ìœ„ì¹˜ ì¸ì½”ë”©ì„ ì¶”ê°€í•´ ë””ì½”ë”ì— ì…ë ¥í•˜ëŠ” ê²ƒì€ ì•Œê³  ìˆë‹¤. ë””ì½”ë”ì˜ ì…ë ¥ í–‰ë ¬ì„ $X$ë¼ê³  í•˜ì. ê·¸ë¦¼ 1-45 ì…ë ¥ í–‰ë ¬í–‰ë ¬ $X$ë¥¼ ë””ì½”ë”ì— ì…ë ¥í•˜ë©´ ì²« ë²ˆì§¸ ë ˆì´ì–´ëŠ” ë§ˆìŠ¤í¬ëœ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì´ ëœë‹¤. ì¸ì½”ë”ì—ì„œ ì‚¬ìš©í•œ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ê³¼ ê¸°ë³¸ ì›ë¦¬ëŠ” ê°™ì§€ë§Œ ë‹¤ë¥¸ ì ì´ í•œ ê°€ì§€ ìˆë‹¤.ì…€í”„ ì–´í…ì…˜ì„ êµ¬í˜„í•˜ë©´ ì²˜ìŒì— $Q, K, V$í–‰ë ¬ì„ ìƒì„±í•œë‹¤.ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì„ ê³„ì‚°í•˜ë©´ $h$ê°œì˜ $Q, K, V$í–‰ë ¬ì„ ìƒì„±í•œë‹¤. í—¤ë“œ $i$ì˜ ê²½ìš° í–‰ë ¬ $X$ì— ê°ê° ê°€ì¤‘ì¹˜ í–‰ë ¬ $w_i^Q, w_i^K, w_i^V$ë¥¼ ê³±í•´ $Q_i, K_i, V_i$ í–‰ë ¬ì„ ì–»ì„ ìˆ˜ ìˆë‹¤.ì´ì œ ë§ˆìŠ¤í¬ëœ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì„ ì‚´í´ë³´ì. ë””ì½”ë”ì˜ ì…ë ¥ ë¬¸ì¥ì€ â€˜&lt;sos&gt; Je vais beinâ€ì´ë‹¤. ì•ì—ì„œ ì…€í”„ ì–´í…ì…˜ì€ ê° ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ì´í•´í•˜ê¸° ìœ„í•´ ê° ë‹¨ì–´ì™€ ë¬¸ì¥ ë‚´ ì „ì²´ ë‹¨ì–´ë¥¼ ì—°ê²°í–ˆë‹¤. ê·¸ëŸ°ë° ë””ì½”ë”ì—ì„œ ë¬¸ì¥ì„ ìƒì„±í•  ë•Œ ì´ì „ ë‹¨ê³„ì—ì„œ ìƒì„±í•œ ë‹¨ì–´ë§Œ ì…ë ¥ë¬¸ì¥ìœ¼ë¡œ ë„£ëŠ”ë‹¤ëŠ” ì ì´ ì¤‘ìš”í•˜ë‹¤. ì˜ˆë¥¼ ë“¤ì–´ $t=2$ì˜ ê²½ìš° ë””ì½”ë”ì˜ ì…ë ¥ ë‹¨ì–´ëŠ” [&lt;sos&gt;, Je]ë§Œ ë“¤ì–´ê°„ë‹¤.ì¦‰, ì´ëŸ° ë°ì´í„°ì˜ íŠ¹ì„±ì„ ì‚´ë ¤ ëª¨ë¸ í•™ìŠµì„ ì§„í–‰í•´ì•¼ í•œë‹¤. ë”°ë¼ì„œ ì…€í”„ ì–´í…ì…˜ì€ ë‹¨ì–´ì™€ì˜ ì—°ê´€ì„±ì„ â€œJeâ€ë§Œ ê³ ë ¤í•´ì•¼ í•˜ë©°, ëª¨ë¸ì´ ì•„ì§ ì˜ˆì¸¡í•˜ì§€ ì•Šì€ ì˜¤ë¥¸ìª½ì˜ ëª¨ë“  ë‹¨ì–´ë¥¼ ë§ˆìŠ¤í‚¹í•´ í•™ìŠµì„ ì§„í–‰í•œë‹¤. ê·¸ë¦¼ 1-46 ê°’ì— ëŒ€í•œ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬ì´ì™€ ê°™ì€ ë‹¨ì–´ ë§ˆìŠ¤í‚¹ ì‘ì—…ì€ ì…€í”„ ì–´í…ì…˜ì—ì„œ ì…ë ¥ë˜ëŠ” ë‹¨ì–´ì—ë§Œ ì§‘ì¤‘í•´ ë‹¨ì–´ë¥¼ ì •í™•í•˜ê²Œ ìƒì„±í•˜ëŠ” ê¸ì •ì ì¸ íš¨ê³¼ë¥¼ ê°€ì ¸ì˜¨ë‹¤. ê·¸ë ‡ë‹¤ë©´ ë§ˆìŠ¤í‚¹ì„ ì–´ë–»ê²Œ ìˆ˜í˜„í•  ìˆ˜ ìˆì„ê¹Œ? $i$ í—¤ë“œì˜ ì–´í…ì…˜ í–‰ë ¬ $Z_i$ëŠ” ë‹¤ìŒ ì‹ìœ¼ë¡œ êµ¬í•  ìˆ˜ ìˆë‹¤.\\[Z_i=softmax({QK^T\\over\\sqrt{d_k}})V_i\\]ì–´í…ì…˜ í–‰ë ¬ì„ êµ¬í•˜ëŠ” ì²« ë²ˆì§¸ ë‹¨ê³„ëŠ” ì¿¼ë¦¬ì™€ í‚¤ í–‰ë ¬ ì‚¬ì´ì˜ ë‚´ì ì„ ê³„ì‚°í•˜ëŠ” ê²ƒì´ë‹¤. [ê·¸ë¦¼ 1-48]ì€ ì¿¼ë¦¬ì™€ í‚¤ í–‰ë ¬ ì‚¬ì´ì˜ ë‚´ì ê°’ì„ êµ¬í•˜ê³ , $\\sqrt{d_k}$ë¡œ ë‚˜ëˆˆ ì„ì˜ì˜ ê²°ê³¼ë‹¤. ê·¸ë¦¼ 1-48ìœ„ í–‰ë ¬ì— ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì ìš©í•´ ì •ê·œí™” ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤. ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì ìš©í•˜ê¸° ì „ì— í–‰ë ¬ê°’ì— ëŒ€í•œ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬ê°€ í•„ìš”í•˜ë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ìœ„ í–‰ë ¬ì˜ ì²« ë²ˆì§¸ í–‰ì„ ë³´ì. &lt;sos&gt;ì˜ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•œë‹¤ê³  í•  ë•Œ ëª¨ë¸ì—ì„œëŠ” &lt;sos&gt; ì˜¤ë¥¸ìª½ì— ìˆëŠ” ëª¨ë“  ë‹¨ì–´ë¥¼ ì°¸ì¡°í•˜ì§€ ë§ì•„ì•¼í•œë‹¤. &lt;sos&gt; ì˜¤ë¥¸ìª½ì— ìˆëŠ” ëª¨ë“  ë‹¨ì–´ë¥¼ $-\\infty$ë¡œ ë§ˆìŠ¤í‚¹í•œë‹¤. ë‘ ë²ˆì§¸, ì„¸ ë²ˆì§¸ í–‰ë„ ë§ˆì°¬ê°€ì§€ë¡œ ìˆ˜í–‰í•œë‹¤. ì´ì œ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì ìš©í•œ í–‰ë ¬ê³¼ ë°¸ë¥˜ $(V_i)$ í–‰ë ¬ì— ê³±í•´ ìµœì¢…ì ìœ¼ë¡œ ì–´í…ì…˜ í–‰ë ¬ $Z_i$ë¥¼ êµ¬í•œë‹¤. ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì˜ ê²½ìš° $h$ê°œì˜ ì–´í…ì…˜ í–‰ë ¬ì„ êµ¬í•˜ê³  ì´ë“¤ì„ ì„œë¡œ ì—°ê²°í•œ í›„ì— ìƒˆë¡œìš´ ê°€ì¤‘ì¹˜ í–‰ë ¬ $W^0$ì„ ê³±í•´ ìµœì¢…ì ìœ¼ë¡œ ì–´í…ì…˜ í–‰ë ¬ $M$ì„ êµ¬í•œë‹¤.\\[M=concatenate(Z_1, Z_2, Z_3, \\cdots, Z_h)W_0\\]1.3.2 ë©€í‹° í—¤ë“œ ì–´í…ì…˜[ê·¸ë¦¼ 1-52]ëŠ” ì¸ì½”ë”ì™€ ë””ì½”ë”ë¥¼ ê²°í•©í•œ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì˜ ëª¨ìŠµì´ë‹¤. ì´ë•Œ ë””ì½”ë”ì˜ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì€ ì…ë ¥ ë°ì´í„° 2ê°œë¥¼ ë°›ëŠ”ë‹¤. í•˜ë‚˜ëŠ” ì´ì „ ì„œë¸Œë ˆì´ì–´ì˜ ì¶œë ¥ê°’ì´ê³ , ë‹¤ë¥¸ í•˜ë‚˜ëŠ” ì¸ì½”ë”ì˜ í‘œí˜„ì´ë‹¤. ê·¸ë¦¼ 1-52 ì¸ì½”ë”ì™€ ë””ì½”ë” ìƒí˜¸ ì‘ìš©ì¸ì½”ë”ì˜ í‘œí˜„ ê°’ì„ $R$, ì´ì „ ì„œë¸Œë ˆì´ì–´ì¸ ë§ˆìŠ¤í¬ëœ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì˜ ê²°ê³¼ë¡œ ë‚˜ì˜¨ ì–´í…ì…˜ í–‰ë ¬ì„ $M$ì´ë¼ê³  í•œë‹¤. ì—¬ê¸°ì„œ ì¸ì½”ë”ì˜ ê²°ê³¼ì™€ ë””ì½”ë”ì˜ ê²°ê³¼ ì‚¬ì´ì— ìƒí˜¸ ì‘ìš©ì´ ì¼ì–´ë‚œë‹¤. ì´ë¥¼ ì¸ì½”ë”-ë””ì½”ë” ì–´í…ì…˜ ë ˆì´ì–´ (encoder-decoder attention layer)ë¼ê³  í•œë‹¤.ì´ì œ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ ë ˆì´ì–´ê°€ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ ì•Œì•„ë³´ì. ì²« ë²ˆì§¸ ë‹¨ê³„ì—ì„œëŠ” ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ í–‰ë ¬ì„ ìƒì„±í•œë‹¤. ì•ì—ì„œ í–‰ë ¬ì— ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ ê³±í•´ì„œ ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ í–‰ë ¬ì„ ë§Œë“¤ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ë°°ì› ë‹¤. í•˜ì§€ë§Œ ì´ë²ˆì—ëŠ” ì…ë ¥ê°’ì´ 2ê°œ (ì¸ì½”ë” í‘œí˜„ $R$, ì´ì „ ì„œë¸Œë ˆì´ì–´ì˜ ê²°ê³¼ì¸ $M$)ë‹¤. ì´ëŸ° ê²½ìš°ì—ëŠ” ì–´ë–»ê²Œ í•´ì•¼ í• ê¹Œ?ì´ì „ ì„œë¸Œë ˆì´ì–´ì˜ ì¶œë ¥ê°’ì¸ ì–´í…ì…˜ í–‰ë ¬ $M$ì„ ì‚¬ìš©í•´ ì¿¼ë¦¬ í–‰ë ¬ $Q$ë¥¼ ìƒì„±í•˜ê³ , ì¸ì½”ë” í‘œí˜„ ê°’ì¸ $R$ì„ í™œìš©í•´ $K, V$í–‰ë ¬ì„ ìƒì„±í•œë‹¤. í˜„ì¬ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì„ ì‚¬ìš©í•˜ê³  ìˆìœ¼ë¯€ë¡œ í—¤ë“œ $i$ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ìŒ ì ˆì°¨ë¥¼ ë”°ë¥¸ë‹¤. ì–´í…ì…˜ í–‰ë ¬ $M$ì— ê°€ì¤‘ì¹˜ í–‰ë ¬ $W_i^Q$ë¥¼ ê³±í•´ ì¿¼ë¦¬ í–‰ë ¬ $Q_i$ë¥¼ ìƒì„±í•œë‹¤. ì¸ì½”ë” í‘œí˜„ê°’ $R$ì— ê°€ì¤‘ì¹˜ í–‰ë ¬ $W_i^K, W_i^V$ë¥¼ ê°ê° ê³±í•´ í‚¤, ë°¸ë¥˜ í–‰ë ¬ $K_i, V_i$ë¥¼ ìƒì„±í•œë‹¤. ê·¸ë¦¼ 1-53 ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ í–‰ë ¬ ìƒì„±ì™œ ì¿¼ë¦¬ í–‰ë ¬ì€ $M$ì„ í†µí•´ ìƒì„±í•˜ê³  í‚¤, ë°¸ë¥˜ í–‰ë ¬ì€ $R$ì„ í†µí•´ ìƒì„±í•˜ëŠ” ê²ƒì¼ê¹Œ? ì¼ë°˜ì ìœ¼ë¡œ ì¿¼ë¦¬ í–‰ë ¬ì€ íƒ€ê¹ƒ ë¬¸ì¥ì˜ í‘œí˜„ì„ í¬í•¨í•˜ë¯€ë¡œ íƒ€ê¹ƒ ë¬¸ì¥ì— ëŒ€í•œ ê°’ì¸ $M$ì˜ ê°’ì„ ì°¸ì¡°í•œë‹¤. í‚¤ì™€ ë°¸ë¥˜ í–‰ë ¬ì€ ì…ë ¥ ë¬¸ì¥ì˜ í‘œí˜„ì„ ê°€ì ¸ì„œ $R$ì˜ ê°’ì„ ì°¸ì¡°í•œë‹¤. ì´ë•Œ ì¥ì ì€ ë¬´ì—‡ì¼ê¹Œ? ì…€í”„ ì–´í…ì…˜ì„ ë‹¨ê³„ì ìœ¼ë¡œ ê³„ì‚°í•˜ë©´ì„œ ì¢€ ë” ìì„¸íˆ ì•Œì•„ë³´ì.ì…€í”„ ì–´í…ì…˜ì˜ ì²« ë²ˆì§¸ ë‹¨ê³„ëŠ” ì¿¼ë¦¬, í‚¤ í–‰ë ¬ ê°„ì˜ ë‚´ì ì„ ê³„ì‚°í•˜ëŠ” ê²ƒì´ë‹¤. ì•ì—ì„œ ì„¤ëª…í–ˆë“¯ì´ ì¿¼ë¦¬ í–‰ë ¬ì€ $M$ì˜ ê°’ì„, í‚¤ í–‰ë ¬ì€ $R$ì˜ ê°’ì„ ì°¸ì¡°í–ˆë‹¤. ì¿¼ë¦¬ , í‚¤ í–‰ë ¬ê°’ì€ ë‹¤ìŒ ê·¸ë¦¼ê³¼ ê°™ë‹¤. ìœ„ í–‰ë ¬ $Q_i\\cdot K_i^T$ë¥¼ í†µí•´ ë‹¤ìŒ ì‚¬ì‹¤ì„ ì´í•´í•  ìˆ˜ ìˆë‹¤. í–‰ë ¬ì˜ ì²« ë²ˆì§¸ í–‰ì—ì„œ ì¿¼ë¦¬ ë²¡í„° $q_1(&lt;sos&gt;)$ì™€ ëª¨ë“  í‚¤ ë²¡í„° $k_1(I), k_2(am), k_3(good)$ ì‚¬ì´ì˜ ë‚´ì ì„ ê³„ì‚°í•œë‹¤. ì²« í–‰ì€ íƒ€ê¹ƒ ë‹¨ì–´ $&lt;sos&gt;$ê°€ ì…ë ¥ ë¬¸ì¥ì˜ ëª¨ë“  ë‹¨ì–´ (I, am, good)ì™€ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€ë¥¼ ê³„ì‚°í•˜ëŠ” ê²ƒìœ¼ë¡œ í•´ì„í•  ìˆ˜ ìˆë‹¤.ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì˜ ë‹¤ìŒ ë‹¨ê³„ëŠ” $Q_i\\cdot K_i^T$ë¥¼ $\\sqrt{d_k}$ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì´ë‹¤. ì´í›„ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì ìš©í•˜ë©´ ìŠ¤ì½”ì–´ í–‰ë ¬ì„ ì–»ì„ ìˆ˜ ìˆë‹¤.\\[Z_i=softmax({Q_iK_i^T\\over \\sqrt{d_k}})V_i\\]ì–´í…ì…˜ í–‰ë ¬ì€ ë‹¤ìŒ ê·¸ë¦¼ì²˜ëŸ¼ í‘œí˜„í•  ìˆ˜ ìˆë‹¤. íƒ€ê¹ƒ ë¬¸ì¥ì˜ ì–´í…ì…˜ í–‰ë ¬ $Z_i$ì˜ ê²½ìš° ê° ìŠ¤ì½”ì–´ì— ëŒ€í•œ ê°€ì¤‘ì¹˜ë¥¼ ë°˜ì˜í•œ ë²¡í„°ê°’ì˜ í•©ìœ¼ë¡œ ê³„ì‚°ëœë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ë‹¨ì–´ â€œJeâ€, $Z_2$ì˜ ì…€í”„ ë²¡í„°ê°’ì„ ê³„ì‚°í•œë‹¤ê³  ê°€ì •í•˜ì.\\[Z_2=0.98 \\cdot V_1(I)+0.02 \\cdot V_2(am)+0.0\\cdot V_3(good)\\]ì´ì™€ ìœ ì‚¬í•˜ê²Œ $h$ê°œì˜ í—¤ë“œì— ëŒ€í•´ ì–´í…ì…˜ í–‰ë ¬ì„ êµ¬í•œ í›„ ì´ë¥¼ ì—°ê²°í•˜ê³ , ê°€ì¤‘ì¹˜ í–‰ë ¬ $W_0$ì„ ê³±í•˜ë©´ ìµœì¢… ì–´í…ì…˜ í–‰ë ¬ì„ êµ¬í•  ìˆ˜ ìˆë‹¤.\\[multi head \\ attention = concatenate(Z_1, Z_2, \\cdots, Z_h)W_0\\]1.3.3 í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ë‹¤ìŒ ê·¸ë¦¼ ì²˜ëŸ¼ ë””ì½”ë”ì˜ ë‹¤ìŒ ì„œë¸Œë ˆì´ì–´ëŠ” feedforward networkì´ë‹¤. ë””ì½”ë”ì˜ í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ëŠ” ì•ì—ì„œ ë°°ìš´ ì¸ì½”ë”ì˜ í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ì™€ ë™ì¼í•œ êµ¬ì¡°ë‹¤. ì´ì œ addì™€ normì— ëŒ€í•´ ì•Œì•„ë³´ì.1.3.4 addì™€ norm ìš”ì†Œì¸ì½”ë”ì—ì„œ ë°°ìš´ ê²ƒì²˜ëŸ¼ addì™€ norm êµ¬ì„± ìš”ì†ŒëŠ” [ê·¸ë¦¼ 1-60]ì²˜ëŸ¼ ì„œë¸Œë ˆì´ì–´ì˜ ì…ë ¥ê³¼ ì¶œë ¥ì„ ì„œë¡œ ì—°ê²°í•œë‹¤. ê·¸ë¦¼ 1-60 addì™€ norm ìš”ì†Œê°€ ìˆëŠ” ë””ì½”ë” ë¸”ë¡1.3.5 ì„ í˜•ê³¼ ì†Œí”„íŠ¸ë§¥ìŠ¤ ë ˆì´ì–´ë””ì½”ë”ê°€ íƒ€ê¹ƒ ë¬¸ì¥ì— ëŒ€í•œ í‘œí˜„ì„ í•™ìŠµì‹œí‚¤ë©´ [ê·¸ë¦¼ 1-61] ì²˜ëŸ¼ ìµœìƒìœ„ ë””ì½”ë”ì—ì„œ ì–»ì€ ì¶œë ¥ê°’ì„ ì„ í˜• ë° ì†Œí”„íŠ¸ë§¥ìŠ¤ ë ˆì´ì–´ì— ì „ë‹¬í•œë‹¤. ê·¸ë¦¼ 1-61 ì„ í˜• ë° ì†Œí”„íŠ¸ë§¥ìŠ¤ ë ˆì´ì–´ì„ í˜• ë ˆì´ì–´ì˜ ê²½ìš° ê·¸ í¬ê¸°ê°€ ì–´íœ˜(vocabulary) (ì´í•˜ vocab) í¬ê¸°ì™€ ê°™ì€ logit í˜•íƒœì´ë‹¤. vocabì´ ë‹¤ìŒê³¼ ê°™ì´ 3ê°œì˜ ìš”ì†Œë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•˜ì.\\[vocabulary=[bien, Je, vais]\\]ì„ í˜• ë ˆì´ì–´ê°€ ë°˜í™˜í•˜ëŠ” ë¡œì§“ì€ í¬ê¸°ê°€ 3ì¸ ë²¡í„° í˜•íƒœê°€ ëœë‹¤. ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ ë¡œì§“ê°’ì„ í™•ë¥ ê°’ìœ¼ë¡œ ë³€í™˜í•œ ë‹¤ìŒ, ë””ì½”ë”ì—ì„œ ê°€ì¥ ë†’ì€ í™•ë¥ ê°’ì„ ê°–ëŠ” ì¸ë±ìŠ¤ì˜ ë‹¨ì–´ë¡œ ì¶œë ¥í•œë‹¤. ë‹¤ìŒ ì˜ˆì œë¥¼ í†µí•´ ë” ìì„¸íˆ ì•Œì•„ë³´ì.ë””ì½”ë”ì˜ ì…ë ¥ ë‹¨ì–´ê°€ $&lt;sos&gt;$ì™€ $Je$ ë¼ê³  í•  ë•Œ ë””ì½”ë”ëŠ” ì…ë ¥ ë‹¨ì–´ë¥¼ ë³´ê³  ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•œë‹¤. ì´ë¥¼ ìœ„í•´ ë””ì½”ë”ì—ì„œëŠ” ìµœìƒìœ„ ì¶œë ¥ê°’ì„ ê°€ì ¸ì™€ì„œ ì„ í˜• ë ˆì´ì–´ì— ì…ë ¥í•œë‹¤. ì´ ì„ í˜• ë ˆì´ì–´ì—ì„œ vocab í¬ê¸°ì™€ ë™ì¼í•œ í¬ê¸°ì˜ ë¡œì§“ ë²¡í„°ë¥¼ ìƒì„±í•œë‹¤. ì´ ë¡œì§“ê°’ì´ ë‹¤ìŒê³¼ ê°™ë‹¤ê³  ê°€ì •í•˜ì.\\[logit=[45,40,49]\\]ì´ ë¡œì§“ê°’ì— ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì ìš©í•˜ê³  í™•ë¥ ê°’ $prob$ì„ ì–»ëŠ”ë‹¤.\\[prob=[0.0179, 0.000, 0.981]\\]ì•ì˜ í–‰ë ¬ì—ì„œ ì¸ë±ìŠ¤ê°€ 2ì¸ ê²½ìš° í™•ë¥ ê°’ì€ $0.981$ë¡œ ê°€ì¥ ë†’ë‹¤. ë”°ë¼ì„œ vocabì—£ì„œ ì¸ë±ìŠ¤ê°€ 2ì¸ $vais$ê°€ íƒ€ê¹ƒ ë¬¸ì¥ì˜ ë‹¤ìŒ ë‹¨ì–´ë¡œ ì˜ˆì¸¡ëœë‹¤. ì´ëŸ° ë°©ì‹ìœ¼ë¡œ ë””ì½”ë”ëŠ” íƒ€ê¹ƒ ë¬¸ì¥ì˜ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•œë‹¤.1.3.6 ë””ì½”ë” ëª¨ë“  êµ¬ì„± ìš”ì†Œ ì—°ê²°í•˜ê¸°ë‹¤ìŒ ê·¸ë¦¼ì€ ë””ì½”ë”ê°€ 2ê°œ ìŒ“ì¸ í˜•íƒœë‹¤. ê°„ê²°í•˜ê²Œ í‘œí˜„í•˜ê¸° ìœ„í•´ ë””ì½”ë”ì˜ ì²« ë²ˆì§¸ ë¶€ë¶„ë§Œ í™•ì¥í•´ì„œ í‘œí˜„í–ˆë‹¤. ê·¸ë¦¼ 1-62 ë””ì½”ë” 2ê°œê°€ ìŒ“ì¸ í˜•íƒœ[ê·¸ë¦¼ 1-62]ì—ì„œ ë‹¤ìŒ ì‚¬ì‹¤ì„ ì•Œ ìˆ˜ ìˆë‹¤. ë¨¼ì € ë””ì½”ë”ì— ëŒ€í•œ ì…ë ¥ ë¬¸ì¥ì„ ì„ë² ë”© í–‰ë ¬ë¡œ ë³€í™˜í•œ ë‹¤ìŒ ìœ„ì¹˜ ì¸ì½”ë”© ì •ë³´ë¥¼ ì¶”ê°€í•˜ê³  ë””ì½”ë”(ë””ì½”ë” 1)ì— ì…ë ¥í•œë‹¤. ë””ì½”ë”ëŠ” ì…ë ¥ì„ ê°€ì ¸ì™€ì„œ ë§ˆìŠ¤í¬ëœ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ ë ˆì´ì–´ì— ë³´ë‚´ê³ , ì¶œë ¥ìœ¼ë¡œ ì–´í…ì…˜ í–‰ë ¬ $M$ì„ ë°˜í™˜í•œë‹¤. ì–´í…ì…˜ í–‰ë ¬ $M$, ì¸ì½”ë”© í‘œí˜„ $R$ì„ ì…ë ¥ë°›ì•„ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ ë ˆì´ì–´ (ì¸ì½”ë”-ë””ì½”ë” ì–´í…ì…˜ ë ˆì´ì–´)ì— ê°’ì„ ì…ë ¥í•˜ê³ , ì¶œë ¥ìœ¼ë¡œ ìƒˆë¡œìš´ ì–´í…ì…˜ í–‰ë ¬ì„ ìƒì„±í•œë‹¤. ì¸ì½”ë”-ë””ì½”ë” ì–´í…ì…˜ ë ˆì´ì–´ì—ì„œ ì¶œë ¥í•œ ì–´í…ì…˜ í–‰ë ¬ì„ ë‹¤ìŒ ì„œë¸Œë ˆì´ì–´ì¸ í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ì— ì…ë ¥í•œë‹¤. í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ì—ì„œëŠ” ì´ ì…ë ¥ê°’ì„ ë°›ì•„ì„œ ë””ì½”ë”ì˜ í‘œí˜„ìœ¼ë¡œ ê°’ì„ ì¶œë ¥í•œë‹¤. ë””ì½”ë” 1ì˜ ì¶œë ¥ê°’ì„ ë””ì½”ë” 2ì˜ ì…ë ¥ê°’ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤. ë””ì½”ë”2ëŠ” ë””ì½”ë” 1ì—ì„œ ìˆ˜í–‰í•œ í”„ë¡œì„¸ìŠ¤ì™€ ë™ì¼í•œ í˜•íƒœë¥¼ ì§„í–‰í•˜ê³ , íƒ€ê¹ƒ ë¬¸ì¥ì— ëŒ€í•œ ë””ì½”ë” í‘œí˜„ì„ ë°˜í™˜í•œë‹¤.ë””ì½”ë”ì˜ ê²½ìš° $N$ê°œì˜ ë””ì½”ë”ë¥¼ ìŒ“ì„ ìˆ˜ ìˆë‹¤. ì´ë•Œ ìµœì¢… ë””ì½”ë” (ìµœìƒìœ„ ë””ì½”ë”)ì—ì„œ ì–»ì€ ì¶œë ¥ (ë””ì½”ë” í‘œí˜„)ì€ íƒ€ê¹ƒ ë¬¸ì¥ì˜ í‘œí˜„ì´ ëœë‹¤. ë‹¤ìŒìœ¼ë¡œ íƒ€ê¹ƒ ë¬¸ì¥ì˜ ë””ì½”ë” í‘œí˜„ì„ ì„ í˜• ë° ì†Œí”„íŠ¸ë§¥ìŠ¤ ë ˆì´ì–´ì— ì…ë ¥í•˜ê³  ìµœì¢…ìœ¼ë¡œ ì˜ˆì¸¡ëœ ë‹¨ì–´ë¥¼ ì–»ëŠ”ë‹¤." }, { "title": "íŠ¸ëœìŠ¤í¬ë¨¸-ì¸ì½”ë”", "url": "/posts/transformer-encoder/", "categories": "NLP, TRANSFORMER", "tags": "nlp, transformer, encoder", "date": "2022-09-09 10:30:00 +0900", "snippet": "íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ìì—°ì–´ ì²˜ë¦¬ì—ì„œ ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë”¥ëŸ¬ë‹ ì•„í‚¤í…ì²˜ ì¤‘ í•˜ë‚˜ë‹¤. íŠ¸ëœìŠ¤í¬ë¨¸ê°€ ì¶”í˜„í•œ ë’¤ë¡œ, ë‹¤ì–‘í•œ íƒœìŠ¤í¬ì— í™œìš©ë˜ì—ˆë˜ ìˆœí™˜ì‹ ê²½ë§(RNN)ê³¼ ì¥ë‹¨ê¸° ë©”ëª¨ë¦¬(LSTM)ëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ë¡œ ëŒ€ì²´ëœë‹¤. BERT, GPT, T5 ë“±ê³¼ ê°™ì€ ë‹¤ì–‘í•œ ìì—°ì–´ ì²˜ë¦¬(NLP)ëª¨ë¸ì— íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ê°€ ì ìš©ëë‹¤.ì´ë²ˆ ì¥ì—ì„œëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ê¸°ë³¸ì ì¸ ì˜ë¯¸ë¶€í„° ì´í•´í•´ë³¼ ê²ƒì´ë‹¤. ê·¸ ë‹¤ìŒìœ¼ë¡œ ì–¸ì–´ ë²ˆì—­ íƒœìŠ¤í¬ë¥¼ í†µí•´ ì¸ì½”ë”-ë””ì½”ë” í˜•íƒœë¡œ ì–´ë–»ê²Œ ì‚¬ìš©ë˜ëŠ”ì§€ ë°°ìš´ë‹¤. ì´í›„ì—ëŠ” ê° ì¸ì½”ë”ì˜ êµ¬ì„±ìš”ì†Œê°€ ì–´ë–»ê²Œ ë™ì‘í•˜ëŠ”ì§€ ìì„¸íˆ ì§šì–´ë³¼ ì˜ˆì •ì´ë‹¤. ì¸ì½”ë”ì— ëŒ€í•œ ì „ë°˜ì ì¸ ë‚´ìš©ì„ ë‹¤ë£¬ ë‹¤ìŒ ë””ì½”ë”ë¥¼ ì‚´í´ë³´ê³  ë””ì½”ë”ì˜ ê° êµ¬ì„±ìš”ì†Œê°€ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ ì•Œì•„ë³¸ë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ì¸ì½”ë”ì™€ ë””ì½”ë”ë¥¼ ê²°í•©í•´ íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ì „ì²´ ì‘ë™ íë¦„ì„ í™•ì¸í•˜ì.1.1 íŠ¸ëœìŠ¤í¬ë¨¸ ì†Œê°œRNNê³¼ LSTM ë„¤íŠ¸ì›Œí¬ëŠ” ë‹¤ìŒ ë‹¨ì–´ ì˜ˆì¸¡, ê¸°ê³„ ë²ˆì—­, í…ìŠ¤íŠ¸ ìƒì„± ë“±ì˜ ìˆœì°¨ì  íƒœìŠ¤í¬ì—ì„œ ë„ë¦¬ ì‚¬ìš©ëœë‹¤. í•˜ì§€ë§Œ ì´ ë„¤íŠ¸ì›Œí¬ëŠ” ì¥ê¸° ì˜ì¡´ì„± ë¬¸ì œê°€ ìˆë‹¤. ì´ëŸ° RNNì˜ í•œê³„ì ì„ ê·¹ë³µí•˜ë ¤ê³  â€œAttention Is All You Needâ€ë…¼ë¬¸ì—ì„œ â€œíŠ¸ëœìŠ¤í¬ë¨¸â€ë¼ëŠ” ì•„í‚¤í…ì²˜ë¥¼ ì œì•ˆí•œë‹¤. íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” í˜„ì¬ ìì—°ì–´ ê³¼ì œì—ì„œ ìµœì‹  ê¸°ìˆ ë¡œ ì‚¬ìš©ëœë‹¤. íŠ¸ëœìŠ¤í¬ë¨¸ê°€ ì¶œí˜„í•¨ìœ¼ë¡œì¨ ìì—°ì–´ ì²˜ë¦¬ ë¶„ì•¼ëŠ” íšê¸°ì ìœ¼ë¡œ ë°œì „í–ˆìœ¼ë©° BERT, GPT-3, T5 ë“±ê³¼ ê°™ì€ í˜ëª…ì ì¸ ì•„í‚¤í…ì²˜ê°€ ë°œì „í•˜ëŠ” ê¸°ë°˜ì´ ë§ˆë ¨ë˜ì—ˆë‹¤.íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” RNNì—ì„œ ì‚¬ìš©í•œ ìˆœí™˜ë°©ì‹ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ìˆœìˆ˜í•˜ê²Œ ì–´í…ì…˜ë§Œ ì‚¬ìš©í•œ ëª¨ë¸ì´ë‹¤. íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” self attentionì´ë¼ëŠ” íŠ¹ìˆ˜í•œ í˜•íƒœì˜ ì–´í…ì…˜ì„ ì‚¬ìš©í•œë‹¤. ë‹¤ìŒ ì ˆì—ì„œ ì…€í”„ì–´í…ì…˜ì´ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ ìì„¸íˆ ë‹¤ë£¬ë‹¤.ê¸°ê³„ë²ˆì—­ ê³¼ì œë¥¼ í†µí•´ íŠ¸ëœìŠ¤í¬ë¨¸ê°€ ì–´ë–¤ ì›ë¦¬ë¡œ ì‘ë™í•˜ëŠ”ì§€ ì‚´í´ë³´ì. íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ì¸ì½”ë”-ë””ì½”ë”ë¡œ êµ¬ì„±ëœ ëª¨ë¸ì´ë‹¤. ë¨¼ì € ì¸ì½”ë”ì— ì…ë ¥ ë¬¸ì¥ (ì›ë¬¸)ì„ ì…ë ¥í•˜ë©´ ì¸ì½”ë”ëŠ” ì…ë ¥ ë¬¸ì¥ì˜ í‘œí˜„ ë°©ë²•ì„ í•™ìŠµì‹œí‚¤ê³  ê·¸ ê²°ê³¼ë¥¼ ë””ì½”ë”ë¡œ ë³´ë‚¸ë‹¤. ë””ì½”ë”ëŠ” ì¸ì½”ë”ì—ì„œ í•™ìŠµí•œ í‘œí˜„ ê²°ê³¼ë¥¼ ì…ë ¥ë°›ì•„ ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ë¬¸ì¥ì„ ìƒì„± í•œë‹¤. ê·¸ë¦¼ 1-1 íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ì¸ì½”ë”-ë””ì½”ë” êµ¬ì¡°ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ” ê²ƒì¼ê¹Œ? íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ì¸ì½”ë”-ë””ì½”ë”ëŠ” ì˜ì–´ ë¬¸ì¥ (ì…ë ¥ ë¬¸ì¥)ì„ ì–´ë–»ê²Œ í”„ë‘ìŠ¤ì–´ ë¬¸ì¥(íƒ€ê¹ƒ ë¬¸ì¥)ìœ¼ë¡œ ë³€í˜•í•˜ëŠ” ê²ƒì¼ê¹Œ? ì¸ì½”ë”ì™€ ë””ì½”ë”ëŠ” ì–´ë–¤ ì›ë¦¬ë¡œ ì‘ë™í• ê¹Œ? ì¸ì½”ë”ì™€ ë””ì½”ë”ë¥¼ ìì„¸íˆ ì•Œì•„ë³´ì.1.2 íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ì¸ì½”ë” ì´í•´í•˜ê¸°íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” Nê°œì˜ ì¸ì½”ë”ê°€ ìŒ“ì¸í˜•íƒœë‹¤. ì¸ì½”ë”ì˜ ê²°ê´ê°’ì€ ê·¸ ë‹¤ìŒ ì¸ì½”ë”ì˜ ì…ë ¥ê°’ìœ¼ë¡œ ë“¤ì–´ê°„ë‹¤. [ê·¸ë¦¼ 1-2]ëŠ” ì¸ì½”ë”ê°€ Nê°œë¡œ ìŒ“ì¸ í˜•íƒœë¥¼ ë³´ì—¬ì¤€ë‹¤. ê° ì¸ì½”ë”ì˜ ê²°ê´ê°’ì€ ê·¸ ìœ„ì— ìˆëŠ” ì¸ì½”ë”ì˜ ì…ë ¥ê°’ìœ¼ë¡œ ë“¤ì–´ê°„ë‹¤. ê°€ì¥ ë§ˆì§€ë§‰ì— ìˆëŠ” ì¸ì½”ë”ì˜ ê²°ê´ê°’ì´ ì…ë ¥ê°’ì˜ ìµœì¢… í‘œí˜„ ê²°ê³¼ê°€ ëœë‹¤. ìµœì´ˆ ì¸ì½”ë”ì— ëŒ€í•œ ì…ë ¥ê°’ìœ¼ë¡œ ì…ë ¥ ë¬¸ì¥ì„ ë„£ê²Œ ë˜ê³ , ìµœì¢… ì¸ì½”ë”ì˜ ê²°ê´ê°’ìœ¼ë¡œ ì…ë ¥ ë¬¸ì¥ì— ë”°ë¥´ëŠ” í‘œí˜„ ê²°ê³¼ë¥¼ ì–»ëŠ”ë‹¤. ê·¸ë¦¼ 1-2 Nê°œë¡œ ëˆ„ì ëœ ì¸ì½”ë”íŠ¸ëœìŠ¤í¬ë¨¸ ê´€ë ¨ ë…¼ë¬¸ì¸ â€œAttention Is All You Needâ€ë¥¼ ë³´ë©´ $N=6$ìœ¼ë¡œ ë˜ì–´ìˆë‹¤. ì´ëŠ” ì¸ì½”ë” 6ê°œë¥¼ ëˆ„ì í•´ì„œ ìŒ“ì•„ ì˜¬ë¦° í˜•íƒœë¥¼ í‘œí˜„í•œ ê²ƒì´ë‹¤. í•˜ì§€ë§Œ $N$ì„ ë‹¤ì–‘í•œ ê°’ìœ¼ë¡œ ì§€ì •í•´ ì¸ì½”ë”ì˜ í˜•íƒœë¥¼ ë°”ê¿€ ìˆ˜ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ $N=2$ì¸ ê²½ìš°ëŠ” ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„í•œë‹¤. ê·¸ë¦¼ 1-3 N=2 ì¸ì½”ë”ì¸ì½”ë”ëŠ” ì–´ë–¤ ì›ë¦¬ë¡œ ì‘ë™í• ê¹Œ? ì…ë ¥ ë¬¸ì¥ìœ¼ë¡œ ì–´ë–¤ ê²°ê´ê°’ì„ ìƒì„±í•˜ëŠ”ê°€? ì´ë¥¼ ì´í•´í•˜ë ¤ë©´ ìš°ì„  ì¸ì½”ë”ì˜ ê° êµ¬ì„±ìš”ì†Œë¥¼ ì´í•´í•´ì•¼ í•œë‹¤. ì¸ì½”ë”ì˜ ì„¸ë¶€ êµ¬ì„± ìš”ì†Œë¥¼ í‘œí˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. ê·¸ë¦¼ 1-4 ì¸ì½”ë”ì˜ êµ¬ì„± ìš”ì†Œì¸ì½”ë”ì˜ êµ¬ì„± ìš”ì†Œë¥¼ ë³´ë©´ ëª¨ë“  ì¸ì½”ë” ë¸”ë¡ì€ í˜•íƒœê°€ ë™ì¼í•˜ë‹¤. ë˜í•œ ì¸ì½”ë” ë¸”ë¡ì€ ë‘ ê°€ì§€ ìš”ì†Œë¡œ êµ¬ì„±ëœë‹¤. ë©€í‹° í—¤ë“œ ì–´í…ì…˜ (multi-head attention) í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ (feedforward network)ë‘ ê°€ì§€ ìš”ì†Œê°€ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ ìì„¸íˆ ì•Œì•„ë³´ì. ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì„ ì´í•´í•˜ë ¤ë©´ ë¨¼ì € ì…€í”„ ì–´í…ì…˜ì´ ì–´ë–¤ ì›ë¦¬ë¡œ ì‘ë™í•˜ëŠ”ì§€ ì´í•´í•´ì•¼ í•œë‹¤. ì…€í”„ ì–´í…ì…˜ì˜ ì‘ë™ ì›ë¦¬ì— ëŒ€í•´ ì‚´í´ë³´ë„ë¡ í•˜ì.1.2.1 ì…€í”„ ì–´í…ì…˜ì˜ ì‘ë™ ì›ë¦¬ì˜ˆì œë¥¼ í™œìš©í•´ ì…€í”„ ì–´í…ì…˜ì˜ ì‘ë™ ì›ë¦¬ë¥¼ ì´í•´í•´ë³´ì. ë‹¤ìŒê³¼ ê°™ì€ ë¬¸ì¥ì´ ìˆë‹¤ê³  ê°€ì •í•œë‹¤. A dog ate the food because it was hungry.ì´ ë¬¸ì¥ì—ì„œ â€˜itâ€™ì€ â€˜dogâ€™ë‚˜ â€˜foodâ€™ë¥¼ ì˜ë¯¸í•  ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ ë¬¸ì¥ì„ ìì„¸íˆ ì‚´í´ë³´ë©´ â€˜itâ€™ì€ â€˜foodâ€™ê°€ ì•„ë‹Œ â€˜dogâ€™ë¥¼ ì˜ë¯¸í•œë‹¤ëŠ” ê²ƒì„ ì‰½ê²Œ ì•Œ ìˆ˜ ìˆë‹¤. ìœ„ì™€ ê°™ì€ ë¬¸ì¥ì´ ì£¼ì–´ì§ˆ ê²½ìš° ëª¨ë¸ì€ â€˜itâ€™ì´ â€˜foodâ€™ê°€ ì•„ë‹Œ â€˜dogâ€™ë¼ëŠ” ê²ƒì„ ì–´ë–»ê²Œ ì•Œ ìˆ˜ ìˆì„ê¹Œ? ì´ë•Œ ì…€í”„ ì–´í…ì…˜ì´ í•„ìš”í•˜ë‹¤.ì´ ë¬¸ì¥ì´ ì…ë ¥ë˜ì—ˆì„ ë•Œ, ëª¨ë¸ì€ ê°€ì¥ ë¨¼ì € ë‹¨ì–´ â€˜Aâ€™ì˜ í‘œí˜„ì„, ê·¸ ë‹¤ìŒìœ¼ë¡œ ë‹¨ì–´ â€˜dogâ€™ì˜ í‘œí˜„ì„ ê³„ì‚°í•œ ë‹¤ìŒ â€˜ateâ€™ë¼ëŠ” ë‹¨ì–´ì˜ í‘œí˜„ì„ ê³„ì‚°í•œë‹¤. ê°ê°ì˜ ë‹¨ì–´ë¥¼ ê³„ì‚°í•˜ëŠ” ë™ì•ˆ ê° ë‹¨ì–´ì˜ í‘œí˜„ë“¤ì€ ë¬¸ì¥ ì•ˆì— ìˆëŠ” ë‹¤ë¥¸ ëª¨ë“  ë‹¨ì–´ì˜ í‘œí˜„ê³¼ ì—°ê²°í•´ ë‹¨ì–´ê°€ ë¬¸ì¥ ë‚´ì—ì„œ ê°–ëŠ” ì˜ë¯¸ë¥¼ ì´í•´í•œë‹¤.ì˜ˆë¥¼ ë“¤ì–´ â€˜itâ€™ì´ë¼ëŠ” ë‹¨ì–´ì˜ í‘œí˜„ì„ ê³„ì‚°í•˜ëŠ” ë™ì•ˆ ëª¨ë¸ì—ì„œëŠ” â€˜itâ€™ì´ë¼ëŠ” ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ì´í•´í•˜ê¸° ìœ„í•´ ë¬¸ì¥ ì•ˆì— ìˆëŠ” ëª¨ë“  ë‹¨ì–´ì™€ â€˜itâ€™ì´ë¼ëŠ” ë‹¨ì–´ë¥¼ ì—°ê²°í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤.[ê·¸ë¦¼ 1-5]ëŠ” â€˜itâ€™ì´ë¼ëŠ” ë‹¨ì–´ì˜ í‘œí˜„ì„ ê³„ì‚°í•˜ê¸° ìœ„í•´ â€˜itâ€™ì„ ë¬¸ì¥ì˜ ëª¨ë“  ë‹¨ì–´ì™€ ì—°ê²°í•˜ëŠ” ì‘ì—…ì„ ë³´ì—¬ì¤€ë‹¤. ì´ì™€ ê°™ì€ ì—°ê²° ì‘ì—…ìœ¼ë¡œ ëª¨ë¸ì€ â€˜itâ€™ì´ â€˜foodâ€™ê°€ ì•„ë‹Œ â€˜dogâ€™ì™€ ê´€ë ¨ì´ ìˆë‹¤ëŠ” ê²ƒì„ í•™ìŠµí•œë‹¤. â€˜dogâ€™ë¥¼ ì‡ëŠ” ì„ ì´ ë‹¤ë¥¸ ë‹¨ì–´ë³´ë‹¤ ë‘ê»ê²Œ í‘œì‹œë˜ì—ˆë‹¤. ì´ëŠ” ì£¼ì–´ì§„ ë¬¸ì¥ ë‚´ì—ì„œ â€˜itâ€™ì´ë¼ëŠ” ë‹¨ì–´ê°€ â€˜foodâ€™ê°€ ì•„ë‹Œ â€˜dogâ€™ì™€ ê´€ë ¨ì´ ìˆë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤€ë‹¤. ê·¸ë¦¼ 1-5 ì…€í”„ ì–´íƒ ì…˜ ì˜ˆì œì…€í”„ ì–´í…ì…˜ì€ ë‚´ë¶€ì ìœ¼ë¡œ ì–´ë–¤ ì›ë¦¬ë¡œ ì‘ë™í• ê¹Œ? ì´ì œ ì…€í”„ ì–´í…ì…˜ ë‚´ë¶€ ì‘ë™ ì›ë¦¬ë¥¼ ìì„¸íˆ ì•Œì•„ë³´ì.ì…ë ¥ ë¬¸ì¥ì´ â€˜I am goodâ€™ì´ë¼ê³  ê°€ì •í•´ë³´ì. ì´ ë¬¸ì¥ì„ ê¸°ì¤€ìœ¼ë¡œ ê° ë‹¨ì–´ì˜ ì„ë² ë”©ì„ ì¶”ì¶œí•œë‹¤. ì—¬ê¸°ì„œ ì„ë² ë”©ì´ë€ ê°ê°ì˜ ë‹¨ì–´ë¥¼ í‘œí˜„í•˜ëŠ” ë²¡í„°ê°’ì„ ì˜ë¯¸í•˜ë©°, ì„ë² ë”©ê°’ì€ ëª¨ë¸ í•™ìŠµ ê³¼ì •ì—ì„œ ê°™ì´ í•™ìŠµëœë‹¤.$x_1$ ì„ â€˜Iâ€™, $x_2$ë¥¼ â€˜amâ€™, $x_3$ë¥¼ â€˜goodâ€™ì— ëŒ€í•œ ì„ë² ë”©ê°’ì´ë¼ê³  í•˜ì. ê°ê°ì˜ ê°’ì„ í‘œí˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. ë‹¨ì–´ â€˜Iâ€™ì— ëŒ€í•œ ì„ë² ë”©: $x_1=[1.76, \\ 2.22, \\ \\cdots, \\ 6.66]$ ë‹¨ì–´ â€˜amâ€™ì— ëŒ€í•œ ì„ë² ë”©: $x_2=[7.77, \\ 0.631, \\ \\cdots, \\ 5.35]$ ë‹¨ì–´ â€˜goodâ€™ì— ëŒ€í•œ ì„ë² ë”©: $x_3=[11.44, \\ 10.10, \\ \\cdots, \\ 3.33]$ì´ì œ ì…ë ¥ ë¬¸ì¥ â€œI am goodâ€ì„ [ê·¸ë¦¼ 1-6]ê³¼ ê°™ì´ ì…ë ¥ í–‰ë ¬ $X$(ì„ë² ë”© í–‰ë ¬ ë˜ëŠ” ì…ë ¥ ì„ë² ë”©)ë¡œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤.ì´ ì…ë ¥ í–‰ë ¬ $X$(ì„ë² ë”© í–‰ë ¬ ë˜ëŠ” ì…ë ¥ ì„ë² ë”©)ë¡œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤. ê·¸ë¦¼ 1-6 ì…ë ¥ í–‰ë ¬í–‰ë ¬ $X$ì—ì„œ ì²« ë²ˆì§¸ í–‰ì€ â€˜Iâ€™ì˜ ì„ë² ë”©, ë‘ ë²ˆì§¸ í–‰ì€ â€˜amâ€™ì˜ ì„ë² ë”©, ì„¸ ë²ˆì§¸ í–‰ì€ â€˜goodâ€™ì˜ ì„ë² ë”©ì„ ì˜ë¯¸í•œë‹¤. ì´ë•Œ í–‰ë ¬ $X$ì˜ ì°¨ì›ì€ [ë¬¸ì¥ ê¸¸ì´ x ì„ë² ë”© ì°¨ì›]ì˜ í˜•íƒœê°€ ëœë‹¤. ìœ„ ë¬¸ì¥ì—ì„œ ë‹¨ì–´ì˜ ìˆ˜(ë¬¸ì¥ì˜ ê¸¸ì´)ëŠ” 3ì´ê³  ì„ë² ë”© ì°¨ì›ì€ 512ë¼ê³  ê°€ì •í•˜ë©´ ì…ë ¥ í–‰ë ¬ (ì…ë ¥ ì„ë² ë”©)ì˜ ì°¨ì›ì€ [3 x 512]ê°€ ëœë‹¤.ì´ì œ ì…ë ¥ í–‰ë ¬ $X$ë¡œ ë¶€í„° ì¿¼ë¦¬ $Q$ í–‰ë ¬, í‚¤ $K$ í–‰ë ¬, ë°¸ë¥˜ $V$ í–‰ë ¬ì„ ìƒì„±í•œë‹¤. ì´ í–‰ë ¬ì€ ë¬´ì—‡ì´ê³ , ì™œ í•„ìš”í• ê¹Œ? ì´ ì„¸ê°€ì§€ í–‰ë ¬ì€ ì…€í”„ ì–´í…ì…˜ì—ì„œ ì‚¬ìš©ëœë‹¤. ì´ í–‰ë ¬ë“¤ì„ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ëŠ”ì§€ ì‚´í´ë³´ì.ìš°ì„  ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ í–‰ë ¬ì„ ì–´ë–»ê²Œ ë§Œë“œëŠ”ì§€ ì•Œì•„ë³´ì. í–‰ë ¬ì„ ìƒì„±í•˜ê¸° ìœ„í•´ì„œëŠ” $W^Q, W^K, W^V$ë¼ëŠ” 3ê°œì˜ ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ ìƒì„±í•œ ë‹¤ìŒ ì´ ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ ì…ë ¥í–‰ë ¥ $X$ì— ê³±í•´ $Q, K,V$ë¥¼ ìƒì„±í•œë‹¤.ì´ë•Œ ê°€ì¤‘ì¹˜ í–‰ë ¬ $W^Q, W^K, W^V$ëŠ” ì²˜ìŒì— ì„ì˜ì˜ ê°’ì„ ê°€ì§€ë©°, í•™ìŠµ ê³¼ì •ì—ì„œ ìµœì ê°’ì„ ì–»ëŠ”ë‹¤. í•™ìŠµì„ í†µí•´ ìµœì ì˜ ê°€ì¤‘ì¹˜ í–‰ë ¬ê°’ì´ ìƒì„±ë˜ë©´ ë”ìš± ì •í™•í•œ ì¿¼ë¦¬ê°’, í‚¤ê°’, ë°¸ë¥˜ê°’ì„ ì–»ê²Œ ëœë‹¤.[ê·¸ë¦¼1-7]ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ ì…ë ¥ í–‰ë ¬ê°’ì—ì„œ ê°€ì¤‘ì¹˜ í–‰ë ¬ $W^Q, W^K, W^V$ë¥¼ ê³±í•˜ë©´ ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ê°’ì„ ì–»ì„ ìˆ˜ ìˆë‹¤. ê·¸ë¦¼ 1-7 ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ í–‰ë ¬ ìƒì„±[ê·¸ë¦¼ 1-7]ì„ í†µí•´ ë‹¤ìŒê³¼ ê°™ì€ ë‚´ìš©ì„ ì•Œ ìˆ˜ ìˆë‹¤. ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ì˜ ì²« ë²ˆì§¸ í–‰ì¸ $q_1,k_1, v_1$ì€ ë‹¨ì–´ â€˜Iâ€™ì— ëŒ€í•œ ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ ë²¡í„°ë¥¼ ì˜ë¯¸í•œë‹¤. ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ì˜ ì²« ë²ˆì§¸ í–‰ì¸ $q_2,k_2, v_2$ì€ ë‹¨ì–´ â€˜amâ€™ì— ëŒ€í•œ ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ ë²¡í„°ë¥¼ ì˜ë¯¸í•œë‹¤. ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ì˜ ì²« ë²ˆì§¸ í–‰ì¸ $q_3,k_3, v_3$ì€ ë‹¨ì–´ â€˜goodâ€™ì— ëŒ€í•œ ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ ë²¡í„°ë¥¼ ì˜ë¯¸í•œë‹¤.ì´ë•Œ ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ ë²¡í„°ì˜ ì°¨ì›ì´ 64ë¼ê³  ê°€ì •í•˜ë©´ ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ í–‰ë ¬ì˜ ì°¨ì›ì€ [ë¬¸ì¥ ê¸¸ì´ x 64] ê°€ ëœë‹¤. ì˜ˆì œ ë¬¸ì¥ì˜ ì„¸ ê°€ì§€ ë‹¨ì–´ì— ëŒ€í•œ ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ í–‰ë ¬ì˜ ì°¨ì›ì€ [3 x 64]ê°€ ëœë‹¤.ê·¸ëŸ°ë° ì™œ ì´ëŸ° í˜•íƒœë¡œ ê³„ì‚°í•´ì•¼ í• ê¹Œ? ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ í–‰ë ¬ì€ ì–´ë–»ê²Œ ì‚¬ìš©ë˜ëŠ”ê°€? ì´ì™€ ê°™ì€ ë°©ë²•ì˜ ì¥ì ì€ ë¬´ì—‡ì¸ê°€? ìì„¸íˆ ì•Œì•„ë³´ë„ë¡ í•˜ì.ì…€í”„ ì–´í…ì…˜ì˜ ì‘ë™ ì›ë¦¬ ì´í•´í•˜ê¸°ì•ì—ì„œ $Q, K, V$ í–‰ë ¬ ê³„ì‚° ë°©ë²•ê³¼ í•´ë‹¹ í–‰ë ¬ì„ ì…ë ¥ í–‰ë ¬ë¡œ ì–»ì„ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ë°°ì› ë‹¤. ì´ì œ ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ í–‰ë ¬ì„ ì…€í”„ ì–´í…ì…˜ì— ì–´ë–»ê²Œ ì‚¬ìš©í•˜ëŠ”ì§€ ë³´ì.ì•ì„œ ë‹¨ì–´ì˜ í‘œí˜„ì„ ê³„ì‚°í•˜ê¸° ìœ„í•´ ì…€í”„ ì–´í…ì…˜ì€ ê° ë‹¨ì–´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì£¼ì–´ì§„ ë¬¸ì¥ì— ìˆëŠ” ëª¨ë“  ë‹¨ì–´ì™€ ì—°ê²°í•˜ëŠ” ê³¼ì •ì„ ìˆ˜í–‰í•˜ë‹¤ëŠ” ì‚¬ì‹¤ì„ ë°°ì› ë‹¤. â€˜I am goodâ€™ì´ë¼ëŠ” ë¬¸ì¥ì„ ì˜ˆë¡œ ë“¤ì–´ ë³´ì. ë‹¨ì–´ â€˜Iâ€™ì˜ í‘œí˜„ì„ ê³„ì‚°í•˜ë ¤ë©´, [ê·¸ë¦¼ 1-8]ì²˜ëŸ¼ ë‹¨ì–´ â€˜Iâ€™ì™€ ì „ì²´ ë¬¸ì¥ì— ìˆëŠ” ë‹¨ì–´ì™€ ì—°ê²°í•˜ëŠ” ê³¼ì •ì„ ìˆ˜í–‰í•œë‹¤. ê·¸ë¦¼ 1-8 ì…€í”„ ì–´í…ì…˜ ì˜ˆì œìœ„ì™€ ê°™ì€ ë°©ë²•ì„ ì ìš©í•˜ëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì¼ê¹Œ? íŠ¹ì • ë‹¨ì–´ì™€ ë¬¸ì¥ ë‚´ì— ìˆëŠ” ëª¨ë“  ë‹¨ì–´ê°€ ì–´ë–¤ ì—°ê´€ì´ ìˆëŠ”ì§€ë¥¼ ì´í•´í•˜ë©´ ì¢€ ë” ì¢‹ì€ í‘œí˜„ì„ í•™ìŠµì‹œí‚¤ëŠ”ë° ë„ì›€ì´ ëœë‹¤. ì´ì œ ì…€í”„ ì–´í…ì…˜ì´ ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ ê°’ì„ ì‚¬ìš©í•´ íŠ¹ì • ë‹¨ì–´ì™€ ë¬¸ì¥ ë‚´ì— ìˆëŠ” ëª¨ë“  ë‹¨ì–´ë¥¼ ì—°ê²°í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³¸ë‹¤. ì…€í”„ ì–´í…ì…˜ì€ ì´ 4ë‹¨ê³„ë¡œ ì´ë£¨ì–´ì ¸ ìˆë‹¤. ê° ë‹¨ê³„ë¥¼ í•˜ë‚˜ì”© ì§šì–´ë³´ì.1ë‹¨ê³„ì…€í”„ ì–´í…ì…˜ì˜ ì²« ë²ˆì§¸ ë‹¨ê³„ëŠ” $Q$ í–‰ë ¬ê³¼ $K^T$í–‰ë ¬ì˜ ë‚´ì  ì—°ì‚°ì„ ìˆ˜í–‰í•œë‹¤. ê·¸ë¦¼ 1-9 ì¿¼ë¦¬, í‚¤ í–‰ë ¬ì¿¼ë¦¬ í–‰ë ¬ $Q$ì™€ í‚¤ í–‰ë ¬ $K^T$ì˜ ë‚´ì  ì—°ì‚° ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. ê·¸ë¦¼ 1-10 ì¿¼ë¦¬, í‚¤ í–‰ë ¬ ë‚´ì  ì—°ì‚° ê²°ê³¼ì´ë•Œ ì¿¼ë¦¬ì™€ í‚¤ í–‰ë ¬ ì‚¬ì´ ë‚´ì ì„ ê³„ì‚°í•˜ëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì¼ê¹Œ? ì—°ì‚° ê²°ê³¼ëŠ” ì •í™•íˆ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ëŠ”ê°€? $Q\\cdot K^T$ì˜ ê²°ê³¼ì— ëŒ€í•´ ì•Œì•„ë³´ì.[ê·¸ë¦¼ 1-11]ì—ì„œ $Q\\cdot K^T$ì˜ ì²« ë²ˆì§¸ í–‰ì„ ë³´ì. ì²« ë²ˆì§¸ í–‰ì€ ì¿¼ë¦¬ ë²¡í„° $q_1(I)$ê³¼ í‚¤ ë²¡í„° $k_1(I), k_2(am), k_3(good)$ì˜ ë‚´ì ì„ ê³„ì‚°í•œë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ë‘ ë²¡í„° ì‚¬ì´ì˜ ë‚´ì ì„ ê³„ì‚°í•˜ë©´ ë‘ ë²¡í„°ê°€ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€ë¥¼ ì•Œ ìˆ˜ ìˆë‹¤.ì¦‰, ì¿¼ë¦¬ ë²¡í„° $(q_1)$ê³¼ í‚¤ ë²¡í„° $(k_1, k_2, k_3)$ ì‚¬ì´ì˜ ë‚´ì ì„ ê³„ì‚°í•˜ëŠ” ê²ƒì€ ì¿¼ë¦¬ ë²¡í„° $q_1(I)$ì™€ í‚¤ ë²¡í„° $k_1(I), k_2(am), k_3(good)$ ì‚¬ì´ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•œ ê²ƒì´ë‹¤. $Q\\cdot K^T$ í–‰ë ¬ì˜ ì²« ë²ˆì§¸ í–‰ì„ ë³´ë©´ ë‹¨ì–´ â€˜Iâ€™ëŠ” ë‹¨ì–´ â€˜amâ€™ê³¼ â€˜goodâ€™ë³´ë‹¤ ìì‹  (I)ê³¼ ì—°ê´€ì„±ì´ ë” ë†’ì€ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. $q_1\\cdot k_1$ì˜ ë‚´ì ê°’ì´ $q_1\\cdot k_2, q_1\\cdot k_3$ ë³´ë‹¤ ë†’ê¸° ë•Œë¬¸ì´ë‹¤. ê·¸ë¦¼ 1-11 ì¿¼ë¦¬ë²¡í„°ì™€ í‚¤ ë²¡í„°ì˜ ë‚´ì  ê³„ì‚° ê²°ê³¼2ë‹¨ê³„ë‹¤ìŒ ë‹¨ê³„ëŠ” $Q\\cdot K^T$ í–‰ë ¬ì˜ í‚¤ ë²¡í„° ì°¨ì›ì˜ ì œê³±ê·¼ ê°’ìœ¼ë¡œ ë‚˜ëˆˆ ê²ƒì´ë‹¤. ì´ì™€ ê°™ì€ ë°©ë²•ì„ ì ìš©í•˜ë©´ ì•ˆì •ì ì¸ ê²½ì‚¿ê°’(gradient)ì„ ì–»ì„ ìˆ˜ ìˆë‹¤.$d_k$ë¥¼ í‚¤ ë²¡í„°ì˜ ì°¨ì›(dimension)ì´ë¼ê³  í•˜ì. ê·¸ëŸ¬ë©´ $Q\\cdot K^T$ë¥¼ $\\sqrt{d_k}$ë¡œ ë‚˜ëˆ„ë©´ ëœë‹¤. ìœ„ì˜ ì˜ˆì œì—ì„œ í‚¤ ë²¡í„°ì˜ ì°¨ì›ì€ 64ì´ë‹¤. 64ì˜ ì œê³±ê·¼ì¸ 8ë¡œ $Q\\cdot K^T$ë¥¼ ë‚˜ëˆˆë‹¤. ê·¸ë¦¼ 1-14 d_kì˜ ì œê³±ê·¼ìœ¼ë¡œ ë‚˜ëˆ„ê¸°3ë‹¨ê³„ì´ì „ ë‹¨ê³„ì—ì„œ ê³„ì‚°í•œ ìœ ì‚¬ë„ ê°’ì€ ë¹„ì •ê·œí™”ëœ í˜•íƒœ(unnormalized form)ë‹¤. ë”°ë¼ì„œ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ ì •ê·œí™” ì‘ì—…ì„ ì§„í–‰í•œë‹¤. ì†Œí”„íŠ¸ ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì ìš©í•˜ë©´ ì „ì²´ ê°’ì˜ í•©ì€ 1ì´ë˜ë©´ ê°ê° 0ê³¼ 1ì‚¬ì´ì˜ ê°’ì„ ê°–ëŠ”ë‹¤. 2ë‹¨ê³„ì˜ ê²°ê³¼ì— ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì ìš©í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ëŠ”ë‹¤. ê·¸ë¦¼ 1-15 ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ ì ìš© ê²°ê³¼ì´ëŸ¬í•œ í–‰ë ¬ì„ ìŠ¤ì½”ì–´ í–‰ë ¬ì´ë¼ê³  í•œë‹¤. ìœ„ ì ìˆ˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¬¸ì¥ ë‚´ì— ìˆëŠ” ê° ë‹¨ì–´ê°€ ë¬¸ì¥ì— ìˆëŠ” ë‹¨ì–´ì™€ ì–¼ë§ˆë‚˜ ì—°ê´€ë˜ì–´ ìˆëŠ”ì§€ ì•Œ ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ìŠ¤ì½”ì–´ í–‰ë ¬ì˜ ì²« í–‰ì„ ë³´ë©´ ë‹¨ì–´ â€˜Iâ€™ëŠ” ìê¸° ìì‹ ê³¼ 90%, ë‹¨ì–´ â€˜amâ€™ê³¼ëŠ” 10%, ë‹¨ì–´ â€˜goodâ€™ê³¼ëŠ” 3% ê´€ë ¨ë˜ì–´ ìˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.4ë‹¨ê³„ì§€ê¸ˆê¹Œì§€ ì¿¼ë¦¬, í‚¤ í–‰ë ¬ì— ëŒ€í•´ ë‚´ì ì„ ê³„ì‚°í•˜ê³ , ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ ë‚´ì ê°’ì— ëŒ€í•œ ì •ê·œí™” ì‘ì—…ì„ ì§„í–‰í–ˆë‹¤. ê·¸ ë‹¤ìŒ ê³¼ì •ì€ ì–´í…ì…˜ í–‰ë ¬ $Z$ë¥¼ ê³„ì‚°í•˜ëŠ” ê²ƒì´ë‹¤.ì–´í…ì…˜ í–‰ë ¬ì€ ë¬¸ì¥ì˜ ê° ë‹¨ì–´ì˜ ë²¡í„°ê°’ì„ ê°–ëŠ”ë‹¤. ì•ì—ì„œ ê³„ì‚°í•œ ìŠ¤ì½”ì–´ í–‰ë ¬ì¸ $softmax({QK^T\\over \\sqrt{d_k}})$ì— ë°¸ë¥˜ í–‰ë ¬ $V$ë¥¼ ê³±í•˜ë©´ ì–´í…ì…˜ í–‰ë ¬ $Z$ë¥¼ êµ¬í•  ìˆ˜ ìˆë‹¤. ë‹¤ìŒì€ ì–´í…ì…˜ í–‰ë ¬ì„ ê³„ì‚°í•œ ê²°ê³¼ì´ë‹¤. ì–´í…ì…˜ í–‰ë ¬ $Z$ëŠ” ê° ì ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê°€ì¤‘ì¹˜ê°€ ë¶€ì—¬ëœ ë²¡í„°ì˜ í•©ìœ¼ë¡œ ê³„ì‚°í•œë‹¤. ê³„ì‚° ê²°ê³¼ë¥¼ í•œ ì¤„ ì”© ì‚´í´ë³´ì. ì²« ë§ˆì§€ë§‰ìœ¼ë¡œ\\[z_1=0.9 \\cdot v_1(I)+0.07\\cdot v_2(am)+0.03\\cdot v_3(good)\\]ìœ„ ì‹ì²˜ëŸ¼ ë‹¨ì–´ â€˜Iâ€™ì˜ ì…€í”„ì–´í…ì…˜ $z_1$ì€ ê° ë°¸ë¥˜ ë²¡í„°ê°’ì˜ ê°€ì¤‘ì¹˜ í•©ìœ¼ë¡œ ê³„ì‚°ëœë‹¤. ì¦‰ $z_1$ì˜ ê°’ì€ ë°¸ë¥˜ ë²¡í„° $v_1(I)$ì˜ 90% ê°’ê³¼ ë°¸ë¥˜ ë²¡í„° $v_2(am)$ì˜ 7% ê°’ê³¼ ë°¸ë¥˜ ë°±í„° $v_3(good)$ì˜ 3%ê°’ì˜ í•©ìœ¼ë¡œ êµ¬í•œë‹¤.ì´ëŸ° ê³„ì‚°ë°©ë²•ì˜ ì¥ì ì€ ë¬´ì—‡ì¼ê¹Œ? â€œA dog ate the food because it was hungryâ€ë¥¼ ì˜ˆë¡œ ë“¤ì–´ ë‹µí•´ë³´ì. ì—¬ê¸°ì„œ ë‹¨ì–´ â€˜itâ€™ì€ â€˜dogâ€™ë¥¼ ì˜ë¯¸í•œë‹¤. ì´ë•Œ ë‹¨ì–´ â€˜itâ€™ì— ëŒ€í•´ ìœ„ì˜ ë°©ë²•ìœ¼ë¡œ ì…€í”„ ì–´í…ì…˜ì„ ê³„ì‚°í•´ ë‹¤ìŒê³¼ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ì—ˆë‹¤ê³  ê°€ì •í•´ë³´ì.\\[z_n=0.0\\cdot v_1(A)+1.0\\cdot v_2(dog)+\\cdots +0.0\\cdot v_9(hungry)\\]ë‹¨ì–´ â€˜itâ€™ì˜ ì…€í”„ ë²¡í„°ê°’ì€ ë°¸ë¥˜ ë²¡í„° $v_2(dog)$ê°€ 100% ë°˜ì˜ëœ ê²°ê³¼ë¡œ ë³¼ ìˆ˜ ìˆë‹¤. ì´ëŠ” ëª¨ë¸ì—ì„œ â€˜itâ€™ì´ â€˜foodâ€™ê°€ ì•„ë‹Œ â€˜dogâ€™ì™€ ê´€ë ¨ì´ ìˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ì…€í”„ ì–´í…ì…˜ ë°©ë²•ì„ ì ìš©í•˜ë©´ ë‹¨ì–´ê°€ ë¬¸ì¥ ë‚´ì— ìˆëŠ” ë‹¤ë¥¸ ë‹¨ì–´ì™€ ì–¼ë§ˆë‚˜ ì—°ê´€ì„±ì´ ìˆëŠ”ì§€ë¥¼ ì•Œ ìˆ˜ ìˆë‹¤.ì–´í…ì…˜ í–‰ë ¬ì€ ë¬¸ì¥ ë‚´ì— ìˆëŠ” ë‹¨ì–´ì˜ ì…€í”„ ë°±í„° ê°’ìœ¼ë¡œ êµ¬ì„±ëœ ê²ƒì„ ì•Œ ìˆ˜ ìˆìœ¼ë©° ë‹¤ìŒ ì‹ìœ¼ë¡œ ê·¸ ê°’ì„ êµ¬í•  ìˆ˜ ìˆë‹¤.\\[Z=softmax({QK^T\\over \\sqrt{d_k}})V\\]ì§€ê¸ˆê¹Œì§€ ì‚´í´ë³¸ ì…€í”„ ì–´í…ì…˜ì˜ ë‹¨ê³„ë¥¼ ìš”ì•½í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. ì¿¼ë¦¬ í–‰ë ¬ê³¼ í‚¤ í–‰ë ¬ ê°„ì˜ ë‚´ì ì„ ê³„ì‚°í•˜ê³ ($Q\\cdot K^T)$ ìœ ì‚¬ë„ ê°’ì„ ì‚°ì¶œí•œë‹¤. $Q\\cdot K^T$ë¥¼ í‚¤ í–‰ë ¬ ì°¨ì›ì˜ ì œê³±ê·¼$(\\sqrt{d_k})$ë¡œ ë‚˜ëˆˆë‹¤. ìŠ¤ì½”ì–´ í–‰ë ¬ì— ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì ìš©í•´ ì •ê·œí™” ì‘ì—…ì„ ì§„í–‰í•œë‹¤. $(softmax({QK^T\\over \\sqrt{d_k}})).$ ë§ˆì§€ë§‰ìœ¼ë¡œ ìŠ¤ì½”ì–´ í–‰ë ¬ì— ë°¸ë¥˜ í–‰ë ¬ì„ ê³±í•´ ì–´í…ì…˜ í–‰ë ¬ $Z$ë¥¼ ì‚°ì¶œí•œë‹¤.ê·¸ë¦¼ìœ¼ë¡œ í‘œí˜„í•˜ìë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. ê·¸ë¦¼ 1-22 ì…€í”„ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì…€í”„ ì–´í…ì…˜ì€ ì¿¼ë¦¬ì™€ í‚¤ ë²¡í„°ì˜ ë‚´ì ì„ ê³„ì‚°í•œ ë‹¤ìŒ $\\sqrt{d_k}$ë¡œ ë‚˜ëˆ„ê¸° ë•Œë¬¸ì— scale dot product ì–´í…ì…˜ì´ë¼ê³ ë„ ë¶€ë¥¸ë‹¤.1.2.2 ë©€í‹° í—¤ë“œ ì–´í…ì…˜ ì›ë¦¬ì–´í…ì…˜ì„ ì‚¬ìš©í•  ë•Œ í—¤ë“œ í•œ ê°œë§Œ ì‚¬ìš©í•œ í˜•íƒœê°€ ì•„ë‹Œ í—¤ë“œ ì—¬ëŸ¬ ê°œë¥¼ ì‚¬ìš©í•œ ì–´í…ì…˜ êµ¬ì¡°ë„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. ì•ì—ì„œ ì–´í…ì…˜ í–‰ë ¬ $Z$ í–‰ë ¬ì„ ê³„ì‚°í•˜ëŠ” ë°©ë²•ì„ ë°°ì› ë‹¤. ë‹¨ì¼ ì–´í…ì…˜ í–‰ë ¬ $Z$ì´ ì•„ë‹Œ ë‹¤ì¤‘ ì–´í…ì…˜ í–‰ë ¬ì„ ê³„ì‚°í•´ë³´ì. ì´ëŸ° ê³„ì‚°ë²•ì€ ì–´ë–¤ ì´ì ì´ ìˆì„ê¹Œ?â€œAll is wellâ€ì´ë¼ëŠ” ë¬¸ì¥ìœ¼ë¡œ ì˜ˆë¥¼ ë“¤ì–´ ë³´ì. ë‹¨ì–´ â€œwellâ€ì˜ ì…€í”„ ì–´í…ì…˜ì„ ê³„ì‚°í•œë‹¤ê³  í•˜ì. ê³„ì‚° ê²°ê³¼ ë‹¤ìŒê³¼ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ì—ˆë‹¤ê³  ê°€ì •í•˜ì.\\[Z_{well}=0.6\\cdot v_1(All) + 0.0\\cdot v_2(is) + 0.4\\cdot v_3(well)\\]ìœ„ ì‹ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ ë‹¨ì–´ â€œwellâ€ì˜ ì…€í”„ ë°±í„°ê°’ì€ ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•œ ê° ë‹¨ì–´ì˜ ë²¡í„°ê°’ì˜ í•©ì„ì„ ì•Œ ìˆ˜ìˆë‹¤. ìœ„ì˜ ë‚´ìš©ì„ ì¢€ ë” ìì„¸íˆ ë“¤ì—¬ë‹¤ë³´ë©´ ë‹¨ì–´ â€œwellâ€™ì˜ ë²¡í„°ê°’ì€ ë‹¨ì–´ â€œAllâ€ì´ ê°€ì¥ ìš°ì„¸í•˜ê²Œ ì‘ìš©í•˜ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.í•˜ì§€ë§Œ ë¬¸ì¥ ë‚´ì—ì„œ ë‹¨ì–´ì˜ ì˜ë¯¸ê°€ ëª¨í˜¸í•œ ê²½ìš° ì—­ì‹œ ë°œìƒí•  ìˆ˜ ìˆë‹¤. ë‹¤ìŒ ë¬¸ì¥ì„ ì˜ˆë¥¼ ë“¤ì–´ ë³´ì. A dog ate the food becuase it was hungry.ì´ ì˜ˆì œì—ì„œ ë‹¨ì–´ â€˜itâ€™ì˜ ì…€í”„ ì–´í…ì…˜ì„ ê³„ì‚°í•´ì„œ ë‹¤ìŒê³¼ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ì—ˆë‹¤ê³  ê°€ì •í•˜ì.\\[z_{it}=0.0\\cdot v_1(A)+1.0\\cdot v_2(dog)+\\cdots + 0.0\\cdot v_9(hungry)\\]ì´ ë•Œ ë‹¨ì–´ â€˜itâ€™ì˜ ì˜ë¯¸ëŠ” â€˜dogâ€™ ë˜ëŠ” â€˜foodâ€™ê°€ ë  ìˆ˜ ìˆëŠ”ë° ìœ„ì˜ ê²°ê³¼ëŠ” ë‹¨ì–´ì˜ ì˜ë¯¸ê°€ ì˜ ì—°ê²°ëœ ê²½ìš°ë‹¤.ë”°ë¼ì„œ ë¬¸ì¥ ë‚´ì—ì„œ ëª¨í˜¸í•œ ì˜ë¯¸ë¥¼ ê°€ì§„ ë‹¨ì–´ê°€ ìˆì„ ê²½ìš°ì— ì•ì˜ ì˜ˆì™€ ê°™ì´ ì ì ˆí•œ ì˜ë¯¸ë¥¼ ê°€ì§„ ë‹¨ì–´ì˜ ë²¡í„°ê°’ì´ ì˜ í• ë‹¹ë˜ì—ˆì„ ê²½ìš°ì—ëŠ” ë¬¸ì¥ì˜ ì˜ë¯¸ë¥¼ ì´í•´í•˜ëŠ” ë° ì¢Šì€ ì˜í–¥ì„ ì¤„ ìˆ˜ìˆë‹¤. í•˜ì§€ë§Œ ê·¸ ë°˜ëŒ€ì˜ ê²½ìš°, ì¦‰, ì˜ë¯¸ê°€ ë§ì§€ ì•ŠëŠ” ë‹¨ì–´ì˜ ë²¡í„°ê°’ì´ ë†’ì„ ê²½ìš°ì—ëŠ” ë¬¸ì¥ì­ ì˜ë¯¸ê°€ ì˜ ëª» í•´ì„ë  ìˆ˜ ìˆë‹¤. ê·¸ë˜ì„œ ì–´í…ì…˜ ê²°ê³¼ì˜ ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ì„œ ë‹¨ì¼ í—¤ë“œ ì–´í…ì…˜ í–‰ë ¬ì´ ì•„ë‹Œ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì„ ì‚¬ìš©í•œ í›„ ê·¸ ê²°ê´ê°’ì„ ë”í•˜ëŠ” í˜•íƒœë¡œ ì§„í–‰í•œë‹¤. ì´ì™€ ê°™ì€ ë°©ë²•ì„ ì‚¬ìš©í•˜ëŠ”ë°ëŠ” ë‹¨ì¼ í—¤ë“œ ì–´í…ì…˜ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒë³´ë‹¤ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì„ ì‚¬ìš©í•˜ë©´ ì¢€ ë” ëª…í™•í•˜ê²Œ ë¬¸ì¥ì˜ ì˜ë¯¸ë¥¼ ì´í•´í•  ìˆ˜ ìˆë‹¤ëŠ” ê°€ì •ì´ ê¹”ë ¤ìˆë‹¤. ì´ì œ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì— ëŒ€í•´ ì¢€ ë” ìì„¸íˆ ì•Œì•„ë³´ì.$h$ê°œì˜ ì–´í…ì…˜ í–‰ë ¬ì„ êµ¬í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤. 8ê°œì˜ ì–´í…ì…˜ í–‰ë ¬ì„ êµ¬í•œë‹¤ê³  í•˜ë©´ í•´ë‹¹ í–‰ë ¬ì„ ê³„ì‚°í•œ í›„ì— ê·¸ ê²°ê³¼ë¥¼ ì—°ê²°í•œ í›„ ìƒˆë¡œìš´ ê°€ì¤‘ì¹˜ í–‰ë ¬ $W^O$ë¥¼ ê³±í•˜ë©´ ìµœì¢…ì ìœ¼ë¡œ ìš°ë¦¬ê°€ ì›í•˜ëŠ” í–‰ë ¬ê³±ì„ êµ¬í•  ìˆ˜ ìˆë‹¤.\\[mha = concatenate(Z_1, Z_2, \\cdots, Z_8)\\cdot W_0\\]1.2.3 ìœ„ì¹˜ ì¸ì½”ë”©ìœ¼ë¡œ ìœ„ì¹˜ ì •ë³´ í•™ìŠµâ€œI am goodâ€ì´ë¼ëŠ” ì…ë ¥ ë¬¸ì¥ì´ ìˆë‹¤ê³  ê°€ì •í•˜ì. RNNì—ì„œëŠ” ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë„¤íŠ¸ì›Œí¬ì— ë¬¸ì¥ì„ ì…ë ¥í•œë‹¤. ì²˜ìŒì— â€œIâ€ë¼ëŠ” ë‹¨ì–´ê°€ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬ëœ ë‹¤ìŒì— â€œamâ€ì´ë¼ëŠ” ë‹¨ì–´ê°€ ì „ë‹¬ëœë‹¤. ë„¤íŠ¸ì›Œí¬ëŠ” ë¬¸ì¥ì„ ì™„ì „íˆ ì´í•´í•˜ê¸° ìœ„í•´ ë¬¸ì¥ì„ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ì„œ ì…ë ¥í•œë‹¤. í•˜ì§€ë§Œ íŠ¸ëœìŠ¤í¬ë¨¸ ë„¤íŠ¸ì›Œí¬ì—ì„œëŠ” ìœ„ì™€ ê°™ì€ ìˆœí™˜êµ¬ì¡°ë¥¼ ë”°ë¥´ì§€ ì•ŠëŠ”ë‹¤. ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë¬¸ì¥ì„ ì…ë ¥í•˜ëŠ” ëŒ€ì‹ ì— ë¬¸ì¥ ì•ˆì— ìˆëŠ” ëª¨ë“  ë‹¨ì–´ë¥¼ ë³‘ë ¬ í˜•íƒœë¡œ ì…ë ¥í•œë‹¤. ë³‘ë ¬ë¡œ ë‹¨ì–´ë¥¼ ì…ë ¥í•˜ëŠ” ê²ƒì€ í•™ìŠµ ì‹œê°„ì„ ì¤„ì´ê³  RNNì˜ ì¥ê¸° ì˜ì¡´ì„± ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° ë„ì›€ì´ ëœë‹¤.í•˜ì§€ë§Œ íŠ¸ëœìŠ¤í¬ë¨¸ì—ì„œ ë‹¨ì–´ë¥¼ ë³‘ë ¬ë¡œ ì…ë ¥í•˜ë©´ í•œ ê°€ì§€ ë¬¸ì œê°€ ë°œìƒí•œë‹¤. ê·¸ê²ƒì€ ë°”ë¡œ ë‹¨ì–´ì˜ ìˆœì„œ ì •ë³´ê°€ ìœ ì§€ë˜ì§€ ì•Šì€ ìƒíƒœì—ì„œ ë¬¸ì¥ì˜ ì˜ë¯¸ë¥¼ ì–´ë–»ê²Œ ì´í•´í•  ìˆ˜ ìˆëŠëƒëŠ” ì ì´ë‹¤.ë¬¸ì¥ì˜ ì˜ë¯¸ë¥¼ ì´í•´í•˜ê¸° ìœ„í•´ì„œëŠ” ë‹¨ì–´ì˜ ìˆœì„œ (ë¬¸ì¥ì˜ ë‹¨ì–´ì˜ ìœ„ì¹˜ ì •ë³´)ê°€ ë§¤ìš° ì¤‘ìš”í•˜ë‹¤. ë¬¸ì¥ì˜ ì˜ë¯¸ë¥¼ ëª…í™•íˆ ì´í•´í•˜ë ¤ë©´ ë‹¨ì–´ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ë°˜ë“œì‹œ ì´í•´í•´ì•¼ í•œë‹¤.â€œI am goodâ€ì´ë¼ëŠ” ë¬¸ì¥ìœ¼ë¡œ ëŒì•„ê°€ì„œ, ì²˜ìŒì— ë¬¸ì¥ ì•ˆì˜ ê° ë‹¨ì–´ì— ëŒ€í•´ ì„ë² ë”©ê°’ì„ ì–»ëŠ”ë‹¤. ì´ë•Œ ì„ë² ë”©ì˜ ì°¨ì›ì„ $d_{model}$ì´ë¼ê³  í•œë‹¤. ì—¬ê¸°ì„œ ì„ë² ë”© ì°¨ì›ì˜ ê°’ì„ 4ë¼ê³  í•œë‹¤ë©´ ë¬¸ì¥ì— ëŒ€í•œ ì…ë ¥ í–‰ì˜ ì°¨ì›ì€ [ë¬¸ì¥ ê¸¸ì´ x ì„ë² ë”© ì°¨ì›] = [3 x 4]ê°€ ëœë‹¤.â€œI am goodâ€ ì´ë¼ëŠ” ë¬¸ì¥ì„ ì…ë ¥í–‰ë ¬(ì„ë² ë”© í–‰ë ¬)ë¡œ í‘œí˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. ê·¸ë¦¼ 1-25 ì…ë ¥ í–‰ë ¬ì…ë ¥ í–‰ë ¬ì„ íŠ¸ëœìŠ¤í¬ë¨¸ì— ë°”ë¡œ ì…ë ¥í•˜ë©´ ë‹¨ì–´ì˜ ìˆœì„œ ì •ë³´ë¥¼ ì´í•´í•  ìˆ˜ ì—†ë‹¤. ì…ë ¥ í–‰ë ¬ì„ íŠ¸ëœìŠ¤í¬ë¨¸ì— ì§ì ‘ ì „ë‹¬í•˜ëŠ” ëŒ€ì‹  ë„¤íŠ¸ì›Œí¬ì—ì„œ ë¬¸ì¥ì˜ ì˜ë¯¸ë¥¼ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë‹¨ì–´ì˜ ìˆœì„œë¥¼ í‘œí˜„í•˜ëŠ” ì •ë³´ë¥¼ ì¶”ê°€ë¡œ ì œê³µí•´ì•¼ í•œë‹¤. ì´ë¥¼ ìœ„í•´ ìœ„ì¹˜ ì¸ì½”ë”©ì´ë¼ëŠ” ìƒˆë¡œìš´ ë°©ë²•ì„ í™œìš©í•œë‹¤. ìœ„ì¹˜ ì¸ì½”ë”©ì´ë¼ëŠ” ì´ë¦„ì—ì„œ ì•Œ ìˆ˜ ìˆë“¯ì´ ë¬¸ì¥ì—ì„œ ë‹¨ì–´ì˜ ìœ„ì¹˜ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì¸ì½”ë”©ì´ë‹¤.ìœ„ì¹˜ ì¸ì½”ë”© í–‰ë ¬ $P$ì˜ ì°¨ì›ì€ ì…ë ¥í–‰ë ¬ $X$ì˜ ì°¨ì›ê³¼ ë™ì¼í•˜ë‹¤. ì´ì œ ì…ë ¥ í–‰ë ¬ì„ íŠ¸ëœìŠ¤í¬ë¨¸ì— ì§ì ‘ ì…ë ¥í•˜ê¸° ì „ì— ìœ„ì¹˜ ì¸ì½”ë”©ì„ í¬í•¨í•œë‹¤. ì¦‰ ì…ë ¥ í–‰ë ¬ $X$ì— ìœ„ì¹˜ ì¸ì½”ë”© $P$ë¥¼ ë”í•œ í›„ ë„¤íŠ¸ì›Œí¬ì— ì…ë ¥í•˜ëŠ” ê²ƒì´ë‹¤. ì´ì œ ì…ë ¥ í–‰ë ¬ì€ ë‹¨ì–´ì˜ ì„ë² ë”© ë¿ ì•„ë‹ˆë¼ ë¬¸ì¥ì˜ ë‹¨ì–´ ìœ„ì¹˜ ì •ë³´ë„ í¬í•¨í•œë‹¤. ê·¸ë¦¼ 1-26 ì…ë ¥ í–‰ë ¬ì— ìœ„ì¹˜ ì¸ì½”ë”© í–‰ë ¬ê°’ ì¶”ê°€ê·¸ë ‡ë‹¤ë©´ ìœ„ì¹˜ ì¸ì½”ë”©ì€ ì–´ë–»ê²Œ ê³„ì‚°ë˜ëŠ” ê²ƒì¼ê¹Œ? â€œAttention Is All You Needâ€ ë…¼ë¬¸ì˜ ì €ìëŠ” ìœ„ì¹˜ ì¸ì½”ë”©ì„ ê³„ì‚°í•˜ëŠ”ë° ì‚¬ì¸íŒŒ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í–ˆë‹¤.\\[P(pos, 2i)=\\sin({pos\\over 1000^{2i/d_{model}}}) \\\\ P(pos, 2i+1)=\\cos({pos\\over 1000^{2i/d_{model}}})\\]ìœ„ì˜ ì‹ì—ì„œ $pos$ëŠ” ë¬¸ì¥ì—ì„œì˜ ë‹¨ì–´ì˜ ìœ„ì¹˜ë¥¼ ì˜ë¯¸í•˜ê³ , $i$ëŠ” í•´ë‹¹ ìœ„ì¹˜ì˜ ì„ë² ë”©ì„ ì˜ë¯¸í•œë‹¤. ì˜ˆì œë¥¼ í†µí•´ í•´ë‹¹ ì‹ì˜ ì˜ë¯¸ë¥¼ ì´í•´í•´ë³´ì. ìœ„ì˜ ì‹ì„ ì‚¬ìš©í•´ ìœ„ì¹˜ ì¸ì½”ë” í–‰ë ¬ì„ í‘œí˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.\\[P=\\begin{bmatrix} \\sin({pos\\over10000^0}) \\ \\cos({pos\\over10000^0}) \\ \\sin({pos\\over10000^{2/4}}) \\ \\cos({pos\\over10000^{2/4}}) \\\\ \\\\ \\sin({pos\\over10000^0}) \\ \\cos({pos\\over10000^0}) \\ \\sin({pos\\over10000^{2/4}}) \\ \\cos({pos\\over10000^{2/4}}) \\\\ \\\\ \\sin({pos\\over10000^0}) \\ \\cos({pos\\over10000^0}) \\ \\sin({pos\\over10000^{2/4}}) \\ \\cos({pos\\over10000^{2/4}}) \\end{bmatrix}\\]ìœ„ì¹˜ ì¸ì½”ë”© $P$ë¥¼ ê³„ì‚°í•œ í›„ ì„ë² ë”© í–‰ë ¬ $X$ì— ìš”ì†Œë³„ í•© (element-wise addition)ì„ ìˆ˜í–‰í•œ í›„ ì¸ì½”ë”ì˜ ì…ë ¥ í–‰ë ¬ë¡œ ì…ë ¥í•œë‹¤.ì¸ì½”ë”ì˜ ì•„í‚¤í…ì²˜ë¥¼ ë‹¤ì‹œ ì‚´í´ë³´ì. [ê·¸ë¦¼ 1-31]ì˜ ë‹¨ì¼ ì¸ì½”ë” ë¸”ë¡ì„ ë³´ë©´ ì¸ì½”ë”ì— ì…ë ¥ ë°ì´í„°ëŠ” ì…ë ¥ ì„ë² ë”©ì„ êµ¬í•œ ë‹¤ìŒ ìœ„ì¹˜ ì¸ì½”ë”©ì„ í•©í•œ í›„ ì¸ì½”ë”ì— ì…ë ¥í•˜ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ê·¸ë¦¼ 1-31 ë‹¨ì¼ ì¸ì½”ë” ë¸”ë¡1.2.4 í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ì¸ì½”ë” ë¸”ë¡ ë‚´ ì„œë¸Œë ˆì´ì–´ì—ì„œ í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ëŠ” ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„í•  ìˆ˜ ìˆë‹¤. ê·¸ë¦¼ 1-32 ì¸ì½”ë” ë¸”ë¡í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ëŠ” 2ê°œì˜ ì „ê²°í•©ì¸µ(dense layer)ê³¼ ReLU í™œì„±í™” í•¨ìˆ˜ë¡œ êµ¬ì„±ëœë‹¤. í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ì˜ ë³€ìˆ˜(parameter)ëŠ” ë¬¸ì¥ì˜ ë‹¤ë¥¸ ìœ„ì¹˜ì—ì„œëŠ” ë™ì¼í•˜ê³  ì¸ì½”ë” ë¸”ë¡ì—ì„œëŠ” ë‹¤ë¥´ê²Œ ë‚˜íƒ€ë‚œë‹¤.1.2.5 addì™€ norm ìš”ì†Œì¸ì½”ë”ì—ì„œ ì¤‘ìš”í•œ ìš”ì†Œ ì¤‘ í•˜ë‚˜ëŠ” ë°”ë¡œ addì™€ normê´€ë ¨ ë¶€ë¶„ì´ë‹¤. ì´ ë¶€ë¶„ì€ ì„œë¸Œë ˆì´ì–´ì˜ ì…ë ¥ê³¼ ì¶œë ¥ ë¶€ë¶„ì— ì—°ê²°ë˜ì–´ ìˆë‹¤. ì´ëŠ” [ê·¸ë¦¼ 1-33]ì—ì„œ ì ì„ ìœ¼ë¡œ í‘œì‹œëœ ë¶€ë¶„ì´ë‹¤. ì´ ë¶€ë¶„ì„ ìì„¸íˆ ë³´ë©´ ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì„±ëë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ìˆë‹¤. ì„œë¸Œë ˆì´ì–´ì—ì„œ ë©€í‹° í—¤ë“œ ì–´í…ì…˜ì˜ ì…ë ¥ê°’ê³¼ ì¶œë ¥ê°’ì„ ì„œë¡œ ì—°ê²°í•œë‹¤. ì„œë¸Œë ˆì´ì–´ì—ì„œ í”¼ë“œí¬ì›Œë“œì˜ ì…ë ¥ê°’ê³¼ ì¶œë ¥ê°’ì„ ì„œë¡œ ì—°ê²°í•œë‹¤. ê·¸ë¦¼ 1-33 addì™€ normì´ ì¶”ê°€ëœ ì¸ì½”ë” ë¸”ë¡add ì™€ norm ìš”ì†ŒëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë ˆì´ì–´ ì •ê·œí™” (layer normalization)ê³¼ ì”ì°¨ ì—°ê²°(residual connection)ì´ë‹¤. ë ˆì´ì–´ ì •ê·œí™”ëŠ” ê° ë ˆì´ì–´ ê°’ì´ í¬ê²Œ ë³€í™”í•˜ëŠ” ê²ƒì„ ë°©ì§€í•´ ëª¨ë¸ì„ ë” ë¹ ë¥´ê²Œ í•™ìŠµí•  ìˆ˜ ìˆê²Œ í•œë‹¤.1.2.6 ëª¨ë“  ì¸ì½”ë” êµ¬ì„± ìš”ì†Œ í†µí•©[ê·¸ë¦¼ 1-34]ëŠ” ì¸ì½”ë” 2ê°œê°€ ëˆ„ì ëœ ìƒíƒœë¥¼ ë³´ì—¬ì¤€ë‹¤. ê°„ê²°í•˜ê²Œ í‘œí˜„í•˜ê¸° ìœ„í•´ ì¸ì½”ë” 1ë§Œ ìì„¸í•˜ê²Œ í‘œí˜„í–ˆë‹¤. ê·¸ë¦¼ 1-34 ì¸ì½”ë” 1ì„ í™•ì¥í•œ ì¸ì½”ë” ëˆ„ì ìœ„ì˜ ì˜ˆì œì²˜ëŸ¼ ì¸ì½”ë”ë¥¼ $N$ê°œ ëˆ„ì í•´ì„œ ìƒì„±í•œë‹¤. ìµœìƒìœ„ ì¸ì½”ë”ì˜ ì¶œë ¥ê°’(ì¸ì½”ë” í‘œí˜„)ì€ ì£¼ì–´ì§„ ì¸ì½”ë”ì— ëŒ€í•œ í‘œí˜„ê°’ì´ ëœë‹¤. ìµœì¢… ì¸ì½”ë”ì—ì„œ ì–»ì€ ì¸ì½”ë” í‘œí˜„ì„ $R$ì´ë¼ê³  í•˜ì.$R$ì€ ë””ì½”ë”ì˜ ì…ë ¥ê°’ìœ¼ë¡œ ë“¤ì–´ê°„ë‹¤. ë””ì½”ë”ëŠ” ì¸ì½”ë” í‘œí˜„ì„ ì…ë ¥ê°’ìœ¼ë¡œ ì‚¬ìš©í•˜ê³  íƒ€ê¹ƒ ë¬¸ì¥ì„ ìƒì„±í•œë‹¤." }, { "title": "ì ëŒ€ì  ê³µê²©ì— ì €í•­í•˜ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ í–¥í•˜ì—¬ (Towards Deep Learning Models Resistant to Adversarial Attacks - Aleksnader Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, Adrian Vladu)", "url": "/posts/pgd/", "categories": "ADVERSARIAL TRAINING, PGD", "tags": "adversarial example", "date": "2022-07-30 22:00:00 +0900", "snippet": "ì˜ì—­ 99%, ì§€ì  íƒœí´ í™˜ì˜ì›ë¬¸: Towards Deep Learning Models Resistant to Adversarial Attacks0 ì´ˆë¡ìµœê·¼ ì—°êµ¬ë“¤ì—ì„œ ì‹¬ì¸µ ì‹ ê²½ë§ì´ adversarial example(ì›ë³¸ ë°ì´í„°ì™€ ê±°ì˜ êµ¬ë³„í•  ìˆ˜ ì—†ì§€ë§Œ networkê°€ ì˜¤ë¶„ë¥˜í•˜ëŠ” ì…ë ¥)ì— ì·¨ì•½í•˜ë‹¤ëŠ” ê²ƒê³¼. adversarial attackì˜ ì¡´ì¬ê°€ ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ë‚´ì¬ì ì¸ ì•½ì ì¼ ìˆ˜ ë„ ìˆë‹¤ëŠ” ê²ƒì´ ë°í˜€ì¡Œë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, robust optimizationì˜ ê´€ì ì—ì„œ ì‹ ê²½ë§ì˜ adversarial robustnessë¥¼ ì‚´í´ë³¼ ê²ƒì´ë‹¤. ì´ëŸ¬í•œ ì ‘ê·¼ì€ í•´ë‹¹ ì£¼ì œì˜ ì´ì „ ì—°êµ¬ë“¤ë³´ë‹¤ ê´‘ë²”ìœ„í•˜ê³  í†µì¼ëœ ê´€ì ì„ ì œê³µí•œë‹¤. ë˜í•œ ì´ëŸ¬í•œ ì›ì¹™ì ì¸ ì„±ì§ˆì€ ì‹ ê²½ë§ì— ëŒ€í•œ í›ˆë ¨ê³¼ ê³µê²©ì„ ìœ„í•œ ì‹ ë¢°í•  ìˆ˜ ìˆê³ , ì–´ë–¤ ì˜ë¯¸ì—ì„œëŠ”, ë³´í¸ì ì¸ ë°©ë²•ì„ ì œì‹œí•  ìˆ˜ ìˆê²Œ í•œë‹¤, íŠ¹íˆ, ëª¨ë“  ì ìœ¼ë¡œë¶€í„° ë³´í˜¸í•  ìˆ˜ ìˆëŠ” concrete security guaranteeë¥¼ ëª…ì‹œí•œë‹¤. ì´ëŸ¬í•œ ë°©ë²•ì€ ê´‘ë²”ìœ„í•œ ì ëŒ€ì  ê³µê²©ì— í¬ê²Œ í–¥ìƒëœ ë‚´ì„±ì„ ê°€ì§„ network í›ˆë ¨ì„ í•  ìˆ˜ ìˆê²Œ í•˜ì˜€ë‹¤. ë˜í•œ ìì—°ìŠ¤ëŸ½ê³  ê´‘ë²”ìœ„í•œ security guaranteeë¡œì¨ first-order adversaryì— ëŒ€í•œ ë³´ì•ˆ ê°œë…ì„ ì œì•ˆí•œë‹¤. ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ adversariesì˜ ì˜ ì •ì˜ëœ í´ë˜ìŠ¤ê°€ ì™„ë²½í•œ ë‚´ì„±ì„ ê°€ì§„ ë”¥ëŸ¬ë‹ ëª¨ë¸ë¡œ í–¥í•˜ëŠ” ë””ë”¤ëŒì„ì„ ë¯¿ëŠ”ë‹¤.1 ê°œìš”ìµœê·¼ ì»´í“¨í„° ë¹„ì „ì´ë‚˜ ìì—°ì–´ ì²˜ë¦¬ì—ì„œì˜ íšê¸°ì ì¸ ë°œì „ì€ í›ˆë ¨ëœ ë¶„ë¥˜ê¸°ë¥¼ ë³´ì•ˆ ì¤‘ì‹œ ì²´ê³„ì˜ ì¤‘ì‹¬ìœ¼ë¡œ ëŒì–´ë“¤ì´ê³  ìˆë‹¤. ììœ¨ì£¼í–‰ ìë™ì°¨, ì–¼êµ´ì¸ì‹ ê·¸ë¦¬ê³  ë©€ì›¨ì–´ ê°ì§€ëŠ” ëŒ€í‘œì ì¸ ì˜ˆì‹œì— í•´ë‹¹í•œë‹¤. ì´ëŸ¬í•œ ë°œì „ì€ ë¨¸ì‹ ëŸ¬ë‹ì˜ ë³´ì•ˆì ì¸ ì¸¡ë©´ì„ ë§¤ìš° ì¤‘ìš”í•˜ê²Œ ë§Œë“¤ê³  ìˆë‹¤. íŠ¹íˆ, ì ëŒ€ì ìœ¼ë¡œ ì„ íƒëœ ì…ë ¥ì— ëŒ€í•œ ì €í•­ì´ ì¤‘ìš”í•œ ì„¤ê³„ ëª©í‘œê°€ ë˜ê³  ìˆë‹¤. ì˜ í›ˆë ¨ëœ ëª¨ë¸ì€ ì¼ë°˜ì ì¸ ì…ë ¥ì˜ ë¶„ë¥˜ì— ìˆì–´ì„œ ë§¤ìš° íš¨ê³¼ì ì´ì§€ë§Œ, ìµœê·¼ ì—°êµ¬ëŠ” ì•…ì˜ì ìœ¼ë¡œ ì…ë ¥ì„ ì¡°ì‘í•˜ì—¬ ëª¨ë¸ì´ ì˜ëª»ëœ ì¶œë ¥ì„ ë§Œë“¤ë„ë¡í•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•˜ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤€ë‹¤.ì´ëŸ¬í•œ í˜„ìƒì€ ì‹¬ì¸µì‹ ê²½ë§ì˜ ë§¥ë½ì—ì„œ ê´€ì‹¬ì„ ë°›ì•˜ì—ˆê³ , í˜„ì¬ëŠ” ì´ ì£¼ì œì— ëŒ€í•œ ì—°êµ¬ê°€ ê¸‰ì†ë„ë¡œ ì´ë£¨ì–´ ì§€ê³  ìˆë‹¤. ì»´í“¨í„° ë¹„ì „ì€ íŠ¹íˆ ì£¼ëª©í•  ë§Œí•œ ë„ì „ì„ ì œê³µí•œë‹¤: ì…ë ¥ ì´ë¯¸ì§€ì— ë¯¸ì„¸í•œ ë³€ê²½ë§Œì„ ì£¼ì–´ë„ SOA ì‹ ê²½ë§ì„ ë†’ì€ ì‹ ë¢°ë„ë¡œ ì†ì¼ ìˆ˜ ìˆë‹¤. ì´ë•Œ ëª¨ë¸ì€ ì¼ë°˜ì ì¸ ì…ë ¥ì€ ì œëŒ€ë¡œ ë¶„ë¥˜í•˜ë©°, ë³€ê²½ëœ ì°¨ì´ì— ëŒ€í•´ì„œ ì¸ê°„ì€ ì¸ì§€í•  ìˆ˜ ì—†ë‹¤. ë³´ì•ˆì ì¸ ë¶€ë¶„ì„ ë–¼ê³  ìƒê°í•˜ë”ë¼ë„, ì´ëŸ¬í•œ í˜„ìƒì€ í˜„ì¬ì˜ ëª¨ë¸ì´ ê²¬ê³ í•œ ë°©ì‹ìœ¼ë¡œ ê¸°ì € ê°œë…ì„ í•™ìŠµí•˜ëŠ”ê²Œ ì•„ë‹ˆë¼ëŠ” ê²ƒì„ ì…ì¦í•œë‹¤. ì´ëŸ¬í•œ ëª¨ë“  ë°œê²¬ì€ í•˜ë‚˜ì˜ ê·¼ë³¸ì ì¸ ì§ˆë¬¸ì„ ë– ì˜¤ë¥´ê²Œ í•œë‹¤:ì–´ë–»ê²Œ í•˜ë©´ ì ëŒ€ì  ì…ë ¥ì— robustí•œ ì‹¬ì¸µ ì‹ ê²½ë§ì„ í›ˆë ¨í•  ìˆ˜ ìˆëŠ”ê°€?í˜„ì¬ ì ëŒ€ì ì¸ í™˜ê²½ì—ì„œì˜ ê³µê²©ê³¼ ë°©ì–´ì— ëŒ€í•œ ë‹¤ì–‘í•œ ë©”ì»¤ë‹ˆì¦˜ì„ ì œì‹œí•œ ìƒë‹¹í•œ ì–‘ì˜ ì—°êµ¬ê°€ ì¡´ì¬í•œë‹¤. defensive distillation, feature squeezing ê·¸ë¦¬ê³  ì¼ë¶€ ë‹¤ë¥¸ ì ëŒ€ì  ì˜ˆì œ ê°ì§€ì— ëŒ€í•œ ì ‘ê·¼ì´ ì´ì— í¬í•¨ëœë‹¤. ì´ ì—°êµ¬ë“¤ì€ ì´ê³³ì˜ ê°€ëŠ¥ì„±ì˜ ì˜ì—­ì„ íƒêµ¬í•˜ëŠ” ì¤‘ìš”í•œ ì²« ë°œìêµ­ì´ ë˜ì—ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê·¸ë“¤ì€ ê·¸ë“¤ì´ ì œê³µí•œ ë³´ì¥ì— ëŒ€í•œ ì–‘ì§ˆì˜ ì´í•´ë¥¼ ì œê³µí•˜ì§€ ì•ŠëŠ”ë‹¤. ìš°ë¦¬ëŠ” ì£¼ì–´ì§„ ê³µê²©ì´ ë§¥ë½ì•ˆì—ì„œ â€œê°€ì¥ ì ëŒ€ì ì¸â€ ì˜ˆì¸ì§€, í˜¹ì€ íŠ¹ì •í•œ ë°©ì–´ ë©”ì»¤ë‹ˆì¦˜ì´ ì–´ë–¤ ì¢…ë¥˜ì˜ ì ëŒ€ì  ê³µê²©ì„ ì˜ˆë°©í•˜ëŠ”ì§€ ê²°ì½” í™•ì‹ í•  ìˆ˜ ì—†ë‹¤. ì´ëŠ” adversarial robustnessë¥¼ ì¡°ì‚¬í•˜ê±°ë‚˜ ê°€ëŠ¥í•œ ë³´ì•ˆì— ëŒ€í•œ íš¨ê³¼ë¥¼ ì™„ì „íˆ í‰ê°€í•˜ëŠ” ê²ƒì„ ì–´ë µê²Œ í•œë‹¤.ë³¸ ë¬¸ì„œì—ì„œëŠ” robustness optimizationì˜ ê´€ì ì—ì„œ ì‹ ê²½ë§ì˜ adversarial roboustnessë¥¼ ì¡°ì‚¬í•  ê²ƒì´ë‹¤. ì›ì¹™ì ì¸ ë°©ì‹ìœ¼ë¡œ, ì ëŒ€ì  ê³µê²©ì— ëŒ€í•œ ë³´ì•ˆì˜ ê°œë…ì„ ì¡ê¸° ìœ„í•´ ë§ ì•ˆì¥ì (min-max) ê³µì‹ì„ ì‚¬ìš©í•œë‹¤. ì´ ê³µì‹ì€ ë‹¬ì„±í•˜ê³ ì í•˜ëŠ” security guaranteeì˜ ìœ í˜•, ì¦‰ íŠ¹ì •í•œ ì˜ ì•Œë ¤ì§„ ê³µê²©ë§Œ ë°©ì–´í•˜ëŠ” ê²ƒê³¼ ë‹¬ë¦¬, ê´‘ë²”ìœ„í•œ ê³µê²©ì— ì €í•­í•˜ëŠ” ê²ƒì— ëŒ€í•´ì„œ ì •í™•íˆ íŒŒì•…í•  ìˆ˜ ìˆê²Œ í•´ì¤€ë‹¤. ë˜í•œ ê³µì‹í™”ì„ í†µí•´ ê³µê²©ê³¼ ë°©ì–´ë¥¼ ëª¨ë‘ ê³µí†µëœ ì´ë¡ ì  í† ëŒ€ì— ë³´ë‚¼ ìˆ˜ ìˆìœ¼ë©°, ì ëŒ€ì  ì˜ˆì œì— ëŒ€í•œ ì´ì „ì˜ ì—°êµ¬ë“¤ì˜ ëŒ€ë¶€ë¶„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ìº¡ìŠí™”í•  ìˆ˜ ìˆê²Œ í•œë‹¤. íŠ¹íˆ, ì ëŒ€ì  í›ˆë ¨ì€ ì´ ë§ì•ˆì¥ì  ë¬¸ì œë¥¼ ìµœì í™” í•˜ëŠ” ê²ƒì— ì§ì ‘ì ìœ¼ë¡œ ì—°ê´€ë˜ì–´ ìˆë‹¤. ì´ì™€ ìœ ì‚¬í•˜ê²Œ, ì‹ ê²½ë§ì„ ê³µê²©í•˜ëŠ” ì´ì „ì˜ ë°©ë²•ë“¤ì€ ê¸°ì €ê°€ ë˜ëŠ” ì œí•œëœ ìµœì í™” ë¬¸ì œë¥¼ í‘¸ëŠ” íŠ¹ì •í•œ ì•Œê³ ë¦¬ì¦˜ê³¼ ì—°ê´€ë˜ì–´ ìˆë‹¤.ì´ëŸ¬í•œ ê´€ì ì—ì„œ ìš°ë¦¬ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì„±ê³¼ë¥¼ ëƒˆë‹¤. ìš°ë¦¬ëŠ” ì´ ë§ì•ˆì¥ì  ì‹ê³¼ ê´€ë ¨ëœ optimization landscape(ìµœì í™” ê³µê°„ì˜ ëª¨ì–‘)ì˜ ì„¸ì‹¬í•œ ì‹¤í—˜ì ì¸ ì—°êµ¬ë¥¼ ì‹œí–‰í•œ í›„, non-convexityì™€ non-concavityì—ë„ ë¶ˆêµ¬í•˜ê³ , ë‚´ì œëœ ìµœì í™” ë¬¸ì œê°€ ë‹¤ë£¨ê¸° ì‰½ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í•˜ì˜€ë‹¤. íŠ¹íˆ, ìš°ë¦¬ëŠ” first-order methodê°€ í™•ì‹¤íˆ ì´ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆë‹¤ëŠ” ê°•ë ¥í•œ ì¦ê±°ë¥¼ ì œì‹œí•œë‹¤. projected gradient descent(PGD)ë¥¼ ë³´í¸ì ì¸ â€œfirst-order adversaryâ€ë¡œì¨ ê°•í•˜ê²Œ ì œì‹œí•˜ëŠ” ì‹¤í•´ì„í•™(real analysis)ì—ì„œì˜ ì•„ì´ë””ì–´ì™€ í•¨ê»˜ ì´ëŸ¬í•œ í†µì°°ì„ ë³´ì¶©í•  ê²ƒì´ë‹¤. first-order adversaryë€, networkì— ëŒ€í•œ local first order ì •ë³´ë¥¼ ì´ìš©í•œ ê°€ì¥ ê°•í•œ ê³µê²©ì´ë‹¤. network êµ¬ì¡°ê°€ adversarial robustnessì— ë¯¸ì¹˜ëŠ” ì˜í–¥ê³¼ model capacityê°€ ì´ê²ƒì— ì¤‘ìš”í•œ ì—­í• ì„ í•œë‹¤ëŠ” ê²ƒì„ ì•Œì•„ëƒˆë‹¤. ê°•í•œ adversarial attackì— ì•ˆì •ì ìœ¼ë¡œ ê²¬ëŒë‚´ê¸° ìœ„í•´, newtorkì—ê²ŒëŠ” ì¼ë°˜ì ì¸ ì…ë ¥ë§Œì„ ì˜¬ë°”ë¥´ê²Œ ë¶„ë¥˜í•˜ëŠ” ë° í•„ìš”í•œ ê²ƒë³´ë‹¤ ë” í° capacityê°€ ìš”êµ¬ëœë‹¤. ì´ëŠ” ë§ì•ˆì¥ì  ë¬¸ì œì˜ robust decision boundaryê°€, ì¼ë°˜ì ì¸ ì…ë ¥ì„ ë¶„ë¥˜í•˜ëŠ” decision bondaryì— ë¹„í•´ì„œ ìƒë‹¹íˆ ë³µì¡í•´ ì§ˆ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤€ë‹¤. ìœ„ì˜ í†µì°°ì„ ë°”íƒ•ìœ¼ë¡œ, ê´‘ë²”ìœ„í•œ ì ëŒ€ì  ê³µê²©ì— robustí•œ MNISTì™€ CIFARì—ì„œ networkë¥¼ í›ˆë ¨ì‹œì¼°ë‹¤. ìš°ë¦¬ì˜ ì ‘ê·¼ì€ ì•ì„œ ì–¸ê¸‰í•œ ë§ì•ˆì¥ì  ê³µì‹ ìµœì í™”ì— ê¸°ë°˜í–ˆìœ¼ë©°, ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” first-order adversaryë¡œ PGDë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤. ìš°ë¦¬ì˜ ìµœê³ ì˜ MNIST ëª¨ë¸ì€ í…ŒìŠ¤íŠ¸ êµ°ì˜ ê°€ì¥ ê°•í•œ adversaryë“¤ë¡œë¶€í„° 89% ì´ìƒì˜ ì •í™•ë„ë¥¼ ë‹¬ì„±í–ˆë‹¤. ì‹¬ì§€ì–´ ìš°ë¦¬ì˜ MNIST networkëŠ” iterative adversaryì˜ white box attack ì—ì„œë„ robustí•˜ì˜€ë‹¤. ê°™ì€ adversaryì—ì„œ ìš°ë¦¬ì˜ CIFAR10 ëª¨ë¸ì€ 46%ì˜ ì •í™•ë„ë¥¼ ë‹¬ì„±í–ˆë‹¤. ë”ìš±ì´, ì•½í•œ black box/transfer ê³µê²©ì—ì„œ, ìš°ë¦¬ì˜ MNISTì™€ CIFAR10 networkëŠ” ê°ê° 95%ì´ìƒ, 64%ì´ìƒì˜ ì •í™•ë„ë¥¼ ë‹¬ì„±í–ˆë‹¤(ë” ìì„¸í•œ ê°œìš”ëŠ” [í‘œ1]ê³¼ [í‘œ2]ì—ì„œ ë³¼ ìˆ˜ ìˆë‹¤). ìš°ë¦¬ê°€ ì•„ëŠ” í•œ, ì´ëŸ¬í•œ ê´‘ë²”ìœ„í•œ ì¢…ë¥˜ì˜ ê³µê²©ì—ì„œ ì´ ì •ë„ ìˆ˜ì¤€ì˜ robustnessë¥¼ ë‹¬ì„±í•œ ê²ƒì€ ìš°ë¦¬ê°€ ìµœì´ˆì´ë‹¤.ì¢…í•©í•˜ìë©´, ì´ëŸ¬í•œ ë°œê²¬ë“¤ì€ ì•ˆì „í•œ ì‹ ê²½ë§ì´ ë„ë‹¬ ë²”ìœ„ ì•ˆì— ìˆìŒì„ ì œì‹œí•œë‹¤. ì´ ì£¼ì¥ì„ ë”ìš± ë’·ë°›ì¹¨ í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” challenge í˜•íƒœë¡œ ìš°ë¦¬ì˜ MNISTì™€ CIFAR10 networkì„ ê³µê²©í•˜ëŠ” ì»¤ë®¤ë‹ˆí‹°ì— ì´ˆëŒ€í•œë‹¤. ì´ê²ƒì€ ìš°ë¦¬ì˜ ëª¨ë¸ì˜ robustnessë¥¼ ì •í™•í•˜ê²Œ í‰ê°€ì‹œì¼œì¤„ ê²ƒì´ë©°, ê·¸ ê³¼ì •ì—ì„œ ìƒˆë¡œìš´ ê³µê²© ë°©ë²•ìœ¼ë¡œ ì´ì–´ì§ˆ ê°€ëŠ¥ì„±ì´ ìˆë‹¤. ë„ì „ ê³¼ì œì— ëŒ€í•œ ì„¤ëª…ê³¼ ì „ì²´ ì½”ë“œëŠ” https://github.com/MadryLab/mnist_challenge ê³¼ https://github.com/MadryLab/cifar10_challenge ì—ì„œ ë³¼ ìˆ˜ ìˆë‹¤.2 ì ëŒ€ì  Robustnessì— ëŒ€í•œ ìµœì í™” ê´€ì ìš°ë¦¬ì˜ ë…¼ì˜ì˜ ëŒ€ë¶€ë¶„ì€ ì ëŒ€ì  robustnessë¥¼ ì£¼ë¡œ í•  ê²ƒì´ë‹¤. ì´ëŸ¬í•œ ê´€ì ì€ ìš°ë¦¬ê°€ ì—°êµ¬í•˜ê³ ì í•˜ëŠ” í˜„ìƒë¿ë§Œ ì•„ë‹ˆë¼ ì—°êµ¬ ê²°ê³¼ ë˜í•œ ì •í™•í•˜ê²Œ í¬ì°©í•  ìˆ˜ ìˆê²Œ í•œë‹¤. ëì—ì„œ ê¸°ë³¸ì´ ë˜ëŠ” ë°ì´í„° ë¶„í¬ $\\mathcal{D}$ì˜ $x\\in\\mathbb{R}^d$ì— ëŒ€ì‘í•˜ëŠ” $y\\in[k]$ ì˜ˆì œ ìŒì—ì„œì˜ í‘œì¤€ ë¶„ë¥˜ ì‘ì—…ì„ ê³ ë ¤í•  ê²ƒì´ë‹¤. ë˜í•œ ì‹ ê²½ë§ì—ì„œì˜ cross-entropy lossì™€ ê°™ì€ ì ì ˆí•œ ì†ì‹¤ í•¨ìˆ˜ $L(\\theta, x, y)$ê°€ ì£¼ì–´ì¡Œë‹¤ê³  ê°€ì •í•œë‹¤. ëŠ˜ ê·¸ë ‡ë“¯, $\\theta \\in \\mathbb{R}^p$ëŠ” ëª¨ë¸ íŒŒë¼ë¯¸í„°ì˜ ì§‘í•©ì´ë‹¤. ì´ì œ ìš°ë¦¬ì˜ ëª©í‘œëŠ” risk(=loss value) $\\mathbb{E}_{(x, y)\\sim \\mathcal{D}}[L(x, y, \\theta)]$ë¥¼ ìµœì†Œí™”í•˜ëŠ” ëª¨ë¸ íŒŒë¼ë¯¸í„° $\\theta$ë¥¼ ì°¾ëŠ” ê²ƒì´ë‹¤.Empirical risk minimization (ERM, ê²½í—˜ì  ìœ„í—˜ë„ ìµœì†Œí™”)ì€ population riskê°€ ì‘ì€ ë¶„ë¥˜ê¸°ë¥¼ ì°¾ëŠ” ê²ƒì— í¬ê²Œ ì„±ê³µì ì´ì—ˆë‹¤. ë¶ˆí–‰í•˜ê²Œë„, ERMì€ ì¢…ì¢… ì ëŒ€ì ìœ¼ë¡œ ìƒì„±ëœ ì˜ˆì œë“¤ì— robustí•œ ëª¨ë¸ì„ ì‚°ì¶œí•˜ì§€ ì•ŠëŠ”ë‹¤. í´ë˜ìŠ¤ $c_1$ì— ì†í•œ ì…ë ¥ $x$ì™€, $x$ì™€ ë§¤ìš° ìœ ì‚¬í•˜ì§€ë§Œ í´ë˜ìŠ¤ë¥¼ $c_2\\not=c_1$ìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ” ì…ë ¥ $x^{adv}$ë¥¼ ì°¾ëŠ” íš¨ìœ¨ì ì´ê³  ê³µì‹ì ì¸ ì•Œê³ ë¦¬ì¦˜(ì´í•˜ â€adversariesâ€)ì´ ì¡´ì¬í•œë‹¤.ì ëŒ€ì  ê³µê²©ì— ì‹ ë¢°ì ì¸ ëª¨ë¸ í›ˆë ¨ì„ ìœ„í•˜ì—¬, ERM íŒ¨ëŸ¬ë‹¤ì„ì„ ì ì ˆí•˜ê²Œ ë³´ê°•í•˜ëŠ” ê²ƒì´ í•„ìš”í•˜ë‹¤. ìš°ë¦¬ëŠ” íŠ¹ì •í•œ ê³µê²©ì— ëŒ€í•œ robustnessë¥¼ ì§ì ‘ì ìœ¼ë¡œ í–¥ìƒì‹œí‚¤ëŠ” ë°©ë²•ë“¤ì„ ì¬ì •ë¦½í•˜ëŠ” ëŒ€ì‹ , adversarially modelì´ ë§Œì¡±í•´ì•¼ í•˜ëŠ” concrete guaranteeë¥¼ ìµœì´ˆë¡œ ì œì‹œí•œë‹¤. ê·¸ëŸ° ë‹¤ìŒ, í•´ë‹¹ guaranteeë¥¼ ë‹¬ì„±í•˜ëŠ” ìª½ìœ¼ë¡œ ëª¨ë¸ì„ ì ì‘ì‹œí‚¨ë‹¤.ì´ëŸ¬í•œ guaranteeë¥¼ í–¥í•œ ì²« ë°œê±¸ìŒì€, ëª¨ë¸ì´ ì €í•­í•´ì•¼ í•˜ëŠ” ê³µê²©ì˜ ì •í™•í•œ ì •ì˜ì¸ attack modelì„ íŠ¹ì •í•˜ëŠ” ê²ƒì´ë‹¤. ê° ë°ì´í„° í¬ì¸íŠ¸ $x$ì— ëŒ€í•œ í—ˆìš©ëœ êµë€ë“¤ì˜ ì§‘í•©$\\mathcal{S}\\subseteq \\mathbb{R}^d$ì„ ì†Œê°œí•œë‹¤. $\\mathcal{S}$ëŠ” adversaryì˜ ì¡°ì‘ë ¥(manuipulative power)ë¥¼ ê³µì‹í™”í•œë‹¤. ì´ë¯¸ì§€ ë¶„ë¥˜ì—ì„œ $\\mathcal{S}$ë¥¼ ì„ íƒí•˜ì—¬ ì´ë¯¸ì§€ë“¤ ì‚¬ì´ì˜ ì§€ê°ì ì¸ ìœ ì‚¬ì„±(perceptual similarity)ì„ í¬ì°©í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´, $x$ë¥¼ ì¤‘ì ìœ¼ë¡œ í•˜ëŠ” $\\ell_\\infty$-ballì´ ì ëŒ€ì  êµë€ì— ëŒ€í•œ ê¸°ë³¸ì ì¸ ê°œë…ìœ¼ë¡œ ìµœê·¼ ì—°êµ¬ë˜ì–´ ì™”ë‹¤. ìš°ë¦¬ëŠ” ë³¸ ë…¼ë¬¸ì—ì„œ $\\ell_\\infty$-bounded ê³µê²©ì— ëŒ€í•œ robustnessì— ì´ˆì ì„ ë§ì¶”ì§€ë§Œ, ì§€ê°ì  ìœ ì‚¬ì„±ì— ëŒ€í•œ ë³´ë‹¤ í¬ê´„ì ì¸ ê°œë…ì€ í–¥í›„ ì—°êµ¬ì˜ ì¤‘ìš”í•œ ë°©í–¥ì´ë¼ëŠ” ê²ƒì„ ì–¸ê¸‰í•œë‹¤.ë‹¤ìŒìœ¼ë¡œ, ìœ„ì˜ adversaryë¥¼ í¬í•¨í•˜ë„ë¡ population risk $\\mathbb{E}_\\mathcal{D}[L]$ì— ëŒ€í•œ ì •ì˜ë¥¼ ë³€ê²½í•œë‹¤. ë¶„í¬ $\\mathcal{D}$ì—ì„œ loss $L$ë¡œ ìƒ˜í”Œë“¤ì„ ì§ì ‘ ì£¼ëŠ” ëŒ€ì‹ , ë¨¼ì € adversaryê°€ ì…ë ¥ì„ êµë€ì‹œí‚¤ë„ë¡ í•œë‹¤. ì´ëŠ” ìš°ë¦¬ ì—°êµ¬ì˜ ì¤‘ì‹¬ ëª©ì ì¸ ë‹¤ìŒì˜ ë§ì•ˆì¥ì  ë¬¸ì œë¥¼ ë– ì˜¤ë¥´ê²Œ í•œë‹¤.\\[\\min_\\theta \\rho(\\theta), \\quad\\text{where}\\quad \\rho(\\theta)=\\mathbb{E}_{(x,y)\\sim\\mathcal{D}} \\big[ \\max_{\\delta\\in\\mathcal{S}}L(\\theta, x+\\delta, y)\\big] \\tag{2.1}\\]ì´ëŸ¬í•œ ìœ í˜•ì˜ ì‹(ê·¸ë¦¬ê³  ìœ í•œí•œ ìƒ˜í”Œë“¤ì— ëŒ€í•œ ê°ê°ì˜ ëŒ€ì‘ë¬¼)ì€ Wald[30]ìœ¼ë¡œ ê±°ìŠ¬ëŸ¬ ì˜¬ë¼ê°€ëŠ” robust optimizationì—ì„œ ìœ êµ¬í•œ ì—­ì‚¬ë¥¼ ê°€ì§€ê³  ìˆë‹¤. ìœ„ ì‹ì€ ìš°ë¦¬ ì—°êµ¬ì˜ ë§¥ë½ì—ì„œ íŠ¹íˆ ìœ ìš©í•˜ë‹¤.ì²«ì§¸ë¡œ, ì´ ì‹ì€ adversarial robustnessì— ëŒ€í•œ ì´ì „ì˜ ì—°êµ¬ë“¤ì„ ì•„ìš°ë¥´ëŠ” í†µí•©ëœ ê´€ì ì„ ì œê³µí•œë‹¤. ìš°ë¦¬ ê´€ì ì˜ ì¤„ê¸°ëŠ” ë§ì•ˆì¥ì  ë¬¸ì œë¥¼ ì†ì— ìˆëŠ” ê²ƒì„ ìµœëŒ€í™”(inner maximization)í•˜ê³  ê²‰ì— ìˆëŠ” ê²ƒì„ ìµœì†Œí™”(outer minimization)í•˜ëŠ” ê²ƒìœ¼ë¡œ ë¶€í„° ë¹„ë¡¯ëœë‹¤. ì´ ë‘˜ ëª¨ë‘ ìš°ë¦¬ ë§¥ë½ì— ëŒ€í•œ ìì—°ìŠ¤ëŸ¬ìš´ í•´ì„ì„ ê°€ì§€ê³  ìˆë‹¤. ë‚´ë¶€ ìµœëŒ€í™” ë¬¸ì œëŠ” ì£¼ì–´ì§„ ë°ì´í„° í¬ì¸íŠ¸ $x$ì— ëŒ€í•´, ë†’ì€ ì†ì‹¤ì„ ê°–ëŠ” ì ëŒ€ì  ë²„ì „ì„ ì°¾ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤. ì´ëŠ” ì •í™•íˆ ì£¼ì–´ì§„ ì‹ ê²½ë§ì„ ê³µê²©í•˜ëŠ” ë¬¸ì œì´ë‹¤. ë°˜ë©´, ì™¸ë¶€ ìµœì†Œí™” ë¬¸ì œì˜ ëª©ì ì€ model parameterë¥¼ ì°¾ì•„ì„œ, ë‚´ë¶€ ê³µê²© ë¬¸ì œê°€ ì œê³µí•œ â€œì ëŒ€ì  ì†ì‹¤â€ì„ ìµœì†Œí™” í•˜ëŠ” ê²ƒì´ë‹¤. ì´ëŠ” ì •í™•íˆ ì ëŒ€ì  í›ˆë ¨ ê¸°ìˆ ì„ ì‚¬ìš©í•´ robustí•œ ë¶„ë¥˜ê¸°ë¥¼ í›ˆë ¨í•˜ëŠ” ë¬¸ì œì´ë‹¤.ë‘˜ì§¸ë¡œ, ë§ì•ˆì¥ì  ë¬¸ì œëŠ” ì´ìƒì ì¸ robust ë¶„ë¥˜ê¸°ê°€ ë‹¬ì„±í•´ì•¼ í•˜ëŠ” ëª…í™•í•œ ëª©ì ì„ robustnessì˜ ìˆ˜ì¹˜ì ì¸ ì²™ë„ë¡œ ì œì‹œí•œë‹¤. íŠ¹íˆ, parameters $\\theta$ê°€ (ê±°ì˜) í¬ë¯¸í•œ riskë¥¼ ì‚°ì¶œí–ˆì„ ë•Œ, í•´ë‹¹ ëª¨ë¸ì€ ìš°ë¦¬ì˜ attack modelì´ í•œ ê³µê²©ì— ëŒ€í•´ ì™„ë²½í•˜ê²Œ robustí•œ ê²ƒì´ë‹¤.ë³¸ ë…¼ë¬¸ì€ ì‹¬ì¸µ ì‹ ê²½ë§ì˜ ë§¥ë½ì—ì„œ ë§ì•ˆì¥ì  ë¬¸ì œì˜ êµ¬ì¡°ë¥¼ ì—°êµ¬í•œë‹¤. ì´ëŸ¬í•œ ì—°êµ¬ëŠ” ê´‘ë²”ìœ„í•œ ì ëŒ€ì  ê³µê²©ì— ëŒ€í•œ ë†’ì€ ë‚´ì„±ì„ ê°€ì§„ ëª¨ë¸ì„ ìƒì„±í•˜ëŠ” í›ˆë ¨ í…Œí¬ë‹‰ì„ ë°œê²¬í•  ìˆ˜ ìˆê²Œ í•œë‹¤. ìš°ë¦¬ì˜ ì„±ê³¼ì— ë“¤ì–´ê°€ê¸° ì•ì„œ, ì ëŒ€ì  ì˜ˆì œì— ëŒ€í•œ ì´ì „ì˜ ì—°êµ¬ë“¤ì„ ê°„ë‹¨íˆ ë¦¬ë·°í•˜ê³ , ì´ê²ƒì´ ì–´ë–»ê²Œ ìœ„ ì‹ì— ë§ì¶°ì§€ëŠ” ì§€ ìì„¸í•˜ê²Œ ì„¤ëª…í•œë‹¤.2.1 ê³µê²©ê³¼ ë°©ì–´ì— ëŒ€í•œ í†µí•©ì ì¸ ê´€ì ì ëŒ€ì  ì˜ˆì œì— ëŒ€í•œ ì´ì „ì˜ ì—°êµ¬ë“¤ì€ ë‹¤ìŒ ë‘ ì£¼ìš”í•œ ì§ˆë¬¸ì— ì§‘ì¤‘ëœë‹¤. ì–´ë–»ê²Œ í•˜ë©´ ê°•ë ¥í•œ ì ëŒ€ì  ì˜ˆì œ(ì‘ì€ êµë€ë§Œì„ ìš”êµ¬í•˜ë©´ì„œ ë†’ì€ ì‹ ë¢°ë„ë¡œ ëª¨ë¸ì„ ì†ì¼ ìˆ˜ ìˆëŠ”)ë¥¼ ìƒì„±í•  ìˆ˜ ìˆëŠ”ê°€? ì–´ë–»ê²Œ í•˜ë©´ ì ëŒ€ì  ì˜ˆì œê°€ ì—†ê²Œë”, ìµœì†Œí•œ ì ëŒ€ì  ì˜ˆì œë¥¼ ì‰½ê²Œ ì°¾ì„ ìˆ˜ ì—†ê²Œë” ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¬ ìˆ˜ ìˆëŠ”ê°€?ë§ì•ˆì¥ì  ë¬¸ì œ(2.1)ì—ì„œ ìš°ë¦¬ì˜ ê´€ì ì€ ìœ„ ë‘˜ ë¬¸ì œ ëª¨ë‘ì—ì„œ í•´ë‹µì„ ì£¼ì—ˆë‹¤. ê³µê²© ì¸¡ë©´ì—ì„œ, ì´ì „ì˜ ì—°êµ¬ëŠ” FGSM[11]ê³¼ ì´ê²ƒì˜ ë‹¤ì–‘í•œ ë³€í˜•[18]ê³¼ ê°™ì€ ë°©ë²•ë“¤ì„ ì œì‹œí–ˆë‹¤. FGSMì€ $\\ell_\\infty$-bounded adversary ê³µê²©ì´ë©° ë‹¤ìŒê³¼ ê°™ì´ ì ëŒ€ì  ì˜ˆì œë¥¼ ê³„ì‚°í•œë‹¤.\\[x+\\epsilon \\ \\text{sgn}(\\nabla_xL(\\theta,x, y)).\\]ì´ ê³µê²©ì„ ë§ì•ˆì¥ì  ê³µì‹ì˜ ë‚´ë¶€ë¥¼ ìµœëŒ€í™”í•˜ëŠ” ê°„ë‹¨í•œ one-step ë°©ì‹ì˜ ê³µê²©ìœ¼ë¡œ í•´ì„í•  ê²ƒì´ë‹¤. ë” ê°•ë ¥í•œ adversaryëŠ” multi-step ë³€í˜•ì¸ë°, ì´ëŠ” ê·¼ë³¸ì ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ìŒì˜ ì†ì‹¤ í•¨ìˆ˜ì—ì„œì˜ ì‚¬ì˜ëœ ê²½ì‚¬ í•˜ê°•(projected gradient descent, PGD)ì´ë‹¤.\\[x^{t+1}=\\mathrm{\\Pi}_{x+\\mathcal{S}}(x^t+\\alpha \\ \\text{sgn}(\\nabla_x L(\\theta, x, y))).\\]ë¬´ì‘ìœ„ êµë€ì˜ FGSMê°™ì€ ë‹¤ë¥¸ ë°©ë²•ë“¤[29]ì´ ì œì‹œë˜ì–´ ì™”ë‹¤. ëª…í™•í•˜ê²Œ, ì´ëŸ¬í•œ ì ‘ê·¼ë“¤ì€ ëª¨ë‘ (2.1)ì˜ ë‚´ë¶€ ìµœëŒ€í™” ë¬¸ì œë¥¼ í•´ê²°í•˜ë ¤ëŠ” ê°œë³„ì ì¸ ì‹œë„ë¡œ ë³¼ ìˆ˜ ìˆë‹¤.ë°©ì–´ ì¸¡ë©´ì—ì„œ, í›ˆë ¨ ë°ì´í„°ì…‹ì€ ì¢…ì¢… FGSMìœ¼ë¡œ ìƒì„±í•œ ì ëŒ€ì  ì˜ˆì œë“¤ì— ì˜í•´ ë³´ê°•ëœë‹¤. ìµœëŒ€í™” ë¬¸ì œë¥¼ ì„ í˜•í™”í•˜ëŠ” ì´ëŸ¬í•œ ì ‘ê·¼ë„ (2.1)ë¡œë¶€í„° ì–»ì–´ì§„ë‹¤. ë‹¨ìˆœí™”ëœ robust optimization ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ëª¨ë“  í›ˆë ¨ ì˜ˆì œë“¤ì„ FGSMìœ¼ë¡œ êµë€ëœ ì˜ˆì œë“¤ë¡œ ëŒ€ì²´í•˜ì˜€ë‹¤. ì—¬ëŸ¬ adversaryë“¤ë¡œë¶€í„° í›ˆë ¨í•˜ëŠ” ê²ƒ ê°™ì€ ë”ìš± ì •êµí•œ ë°©ì–´ ë©”ì»¤ë‹ˆì¦˜ì´ ë‚´ë¶€ ìµœëŒ€í™” ë¬¸ì œì˜ ë” ì¢‹ê³  ì² ì €í•œ ê·¼ì‚¬ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤.3 ë³´í¸ì ì¸ Robust Networkë¥¼ í–¥í•˜ì—¬ì ëŒ€ì  ì˜ˆì œì˜ í˜„ì¬ì˜ ì—°êµ¬ëŠ” ë³´í†µ íŠ¹ì •í•œ ë°©ì–´ ë©”ì»¤ë‹ˆì¦˜ì´ë‚˜, í˜¹ì€ ê·¸ëŸ¬í•œ ë°©ì–´ì— ëŒ€í•œ ê³µê²©ì— ì§‘ì¤‘í•œë‹¤. ê³µì‹ (2.1)ì˜ ì¤‘ìš”í•œ íŠ¹ì§•ì€ ì‘ì€ ì ëŒ€ì  lossê°€, í—ˆìš©ëœ ê³µê²©ì— ëŒ€í•´ì„œ ì‹ ê²½ë§ì„ ì†ì´ì§€ ëª»í•œë‹¤ëŠ” guaranteeë¥¼ ì¤€ë‹¤ëŠ” ê²ƒì´ë‹¤. ì •ì˜ì— ì˜í•´, ìš°ë¦¬ì˜ ê³µê²© ëª¨ë¸ë¡œë¶€í„° í—ˆìš©ëœ ëª¨ë“  êµë€ì— ëŒ€í•œ lossê°€ ì‘ê¸° ë•Œë¬¸ì—, ì–´ë– í•œ ì ëŒ€ì  êµë€ë„ ê°€ëŠ¥í•˜ì§€ ì•Šë‹¤. ì´ëŸ° ì´ìœ ë¡œ, ì´ì œë¶€í„° (2.1)ì˜ ì–‘ì§ˆì˜ í•´ë¥¼ ì–»ëŠ” ê²ƒì— ì§‘ì¤‘í•  ê²ƒì´ë‹¤.ë¶ˆí–‰í•˜ê²Œ, ë§ì•ˆì¥ì  ë¬¸ì œê°€ ì¤€ ì¢…í•©ì ì¸ guraranteeëŠ” ë¶„ëª…íˆ ìœ ìš©í•˜ì§€ë§Œ, í•©ë¦¬ì ì¸ ì‹œê°„ì— ì¢‹ì€ í•´ë¥¼ ì°¾ì„ ìˆ˜ ìˆëŠ”ì§€ëŠ” ëª…í™•í•˜ì§€ ì•Šë‹¤. ë§ì•ˆì¥ì  ë¬¸ì œ (2.1)ì„ í‘¸ëŠ” ê²ƒì€ non-covexí•œ ì™¸ë¶€ ìµœì†Œí™” ë¬¸ì œì™€ non-concaveí•œ ë‚´ë¶€ ìµœëŒ€í™” ë¬¸ì œë¥¼ ë‘˜ ë‹¤ ë¶™ì¡ê³  ì”¨ë¦„í•˜ëŠ” ê²ƒì„ í¬í•¨í•œë‹¤. ìš°ë¦¬ì˜ ì£¼ìš” ì„±ê³¼ ì¤‘ í•˜ë‚˜ëŠ” ì‹¤ì œë¡œ ë§ì•ˆì¥ì  ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ì…ì¦í•œ ê²ƒì´ë‹¤. íŠ¹íˆ, ì´ì œë¶€í„° ìš°ë¦¬ëŠ” non-concaveí•œ ë‚´ë¶€ ë¬¸ì œ êµ¬ì¡°ì˜ ì‹¤í—˜ì ì¸ ì—°êµ¬ì— ëŒ€í•´ì„œ ë…¼ì˜í•œë‹¤. ìš°ë¦¬ëŠ” ì´ ë¬¸ì œì™€ ì—°ê´€ëœ loss ê³µê°„ì˜ ëª¨ì–‘ì´ ë†€ëê²Œë„ local maximaë¥¼ ë‹¤ë£¨ê¸° ì‰¬ìš´ êµ¬ì¡°ì„ì„ ì…ì¦í•  ê²ƒì´ë‹¤. ë˜í•œ ì´ëŸ° êµ¬ì¡°ëŠ” â€œê¶ê·¹ì ì¸â€ first-order adversaryë¡œì¨ PGDë¥¼ ê°€ë¦¬í‚¨ë‹¤. ì„¹ì…˜ 4ì™€ 5ì—ì„œ, networkê°€ ì¶©ë¶„íˆ í¬ë‹¤ë©´, í›ˆë ¨ëœ networkì˜ ê²°ê³¼ê°€ ê´‘ë²”ìœ„í•œ ê³µê²©ì— ì‹¤ì œë¡œ robustí•˜ë‹¤ëŠ” ê²ƒì„ ë³´ì¸ë‹¤.3.1 ì ëŒ€ì  ì˜ˆì œì˜ Landscapeë‚´ë¶€ ë¬¸ì œê°€ ì£¼ì–´ì§„ networkì™€ ë°ì´í„° í¬ì¸íŠ¸ì— ëŒ€í•´ì„œ ì ëŒ€ì  ì˜ˆì œë¥¼ ì°¾ëŠ” ê²ƒì„ì„ ìƒê¸°í•˜ì (ìš°ë¦¬ì˜ ê³µê²© ëª¨ë¸ë¡œ). ì´ ë¬¸ì œëŠ” highly nonconcaveí•œ í•¨ìˆ˜ë¥¼ ìµœëŒ€í™”í•  ê²ƒì„ ìš”êµ¬í•˜ë¯€ë¡œ, ë‹¤ë£¨ê¸° ì–´ë µë‹¤ê³  ìƒê°í•  ìˆ˜ ìˆë‹¤. ì‹¤ì œë¡œ, ì´ê²ƒì€ ë‚´ë¶€ ìµœëŒ€í™” ë¬¸ì œë¥¼ ì„ í˜•í™”í•˜ëŠ” ë° ì˜ì¡´í•œ ì´ì „ ì—°êµ¬ì— ì˜í•´ ë„ë‹¬í•œ ê²°ë¡ ì´ë‹¤[15, 26]. ìœ„ì—ì„œ ì§€ì í•œ ë°”ì™€ ê°™ì´, ì´ëŸ¬í•œ ì„ í˜•í™” ì ‘ê·¼ì€ FGSMê³¼ ê°™ì´ ì˜ ì•Œë ¤ì§„ ë°©ì‹ì„ ì‚°ì¶œí•œë‹¤. FGSM adversariesì— ëŒ€í•´ í›ˆë ¨í•˜ëŠ” ê²ƒì€ ì¼ë¶€ ì„±ê³µì„ ë³´ì˜€ì§€ë§Œ, ìµœê·¼ ì—°êµ¬ëŠ” ì´ one-step ì ‘ê·¼ë²•ì˜ ì¤‘ìš”í•œ ë‹¨ì ì„ ê°•ì¡°í•œë‹¤. ì¦‰, ë¯¸ì„¸í•˜ê²Œ ë” ì •êµí•œ adversaryë“¤ì´ ì—¬ì „íˆ ë†’ì€ lossë¥¼ ê°–ëŠ” ì…ë ¥ì„ ì°¾ì„ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤.ë” ìì„¸í•˜ê²Œ ë‚´ë¶€ ë¬¸ì œë¥¼ ì´í•´í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” MNISTì™€ CIFAR10ì—ì„œì˜ ì—¬ëŸ¬ ëª¨ë¸ì˜ local maxima ê³µê°„ì˜ ëª¨ì–‘ì„ ì—°êµ¬í•œë‹¤. large-scale constrained opimizationì˜ í‘œì¤€ ë°©ë²•ì´ê¸° ë•Œë¬¸ì—, ì‹¤í—˜ì˜ ì£¼ìš” ë„êµ¬ëŠ” PGDì´ë‹¤. loss ê³µê°„ì˜ ëª¨ì–‘ì˜ ë§ì€ ë¶€ë¶„ì„ íƒìƒ‰í•˜ê¸° ìœ„í•´, ê° ê²€ì¦ ì…‹íŠ¸ì˜ ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ë‘˜ëŸ¬ì‹¸ëŠ” $\\ell_\\infty$-ball ì˜ ë§ì€ ì§€ì ì—ì„œ PGDë¥¼ ì¬ì‹œì‘í•œë‹¤.ë†€ëê²Œë„, ì‹¤í—˜ í›„ ì ì–´ë„ first-order ë°©ë²•ë“¤ì—ì„œëŠ” ë‚´ë¶€ ë¬¸ì œê°€ ë‹¤ë£¨ê¸° ì‰½ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆë‹¤. $x_i+\\mathcal{S}$ì•ˆì— ë§ì€ local maximaë¥¼ ê°–ëŠ” ì ëŒ€ì  ì…ë ¥ì´ ë„“ê³  ë„ì—„ë„ì—„í•˜ê²Œ í©ë¿Œë ¤ì ¸ ìˆì—ˆì§€ë§Œ, ë§¤ìš° ì¼ê´€ëœ loss ê°’ì„ ê°–ëŠ” ê²½í–¥ì´ ìˆì—ˆë‹¤. ì´ëŠ” loss(model parameterì— ëŒ€í•œ í•¨ìˆ˜ë¡œì¨)ê°€ ì¼ë°˜ì ìœ¼ë¡œ ë§¤ìš° ìœ ì‚¬í•œ ê°’ì„ ê°€ì§„ ë§ì€ local maximaë¥¼ ê°€ì§€ê¸° ë•Œë¬¸ì— ì‹ ê²½ë§ í›ˆë ¨ì´ ê°€ëŠ¥í•˜ë‹¤ëŠ” ì „í†µì ì¸ ë¯¿ìŒì„ ë°˜ì˜í•œë‹¤.ì‹¤í—˜ì€ ì•„ë˜ì™€ ê°™ì€ íŠ¹ë³„í•œ í˜„ìƒë“¤ì„ ë°œê²¬í–ˆë‹¤. ìš°ë¦¬ëŠ” $x+\\mathcal{S}$ì•ˆì˜ ë¬´ì‘ìœ„ë¡œ ì„ íƒëœ ì‹œì‘ì ì—ì„œ projected $\\ell_\\infty$ gradient descentë¥¼ ì‚¬ìš©í•  ë•Œ adversaryì— ì˜í•´ ë‹¬ì„±ëœ lossê°€ ìƒë‹¹íˆ ì¼ê´€ì ìœ¼ë¡œ ë¹ ë¥´ê²Œ ì¦ê°€í•˜ëŠ” ê²ƒì„ ë°œê²¬í–ˆë‹¤. ([ê·¸ë¦¼1] ì°¸ì¡°) [ê·¸ë¦¼1] MNISTì™€ CIFAR10 ê²€ì¦ ë°ì´í„°ì…‹ì—ì„œ ì ëŒ€ì  ì˜ˆì œë¥¼ ìƒì„±í•˜ëŠ” ë™ì•ˆì˜ cross-entropy lossê°’. ì´ ê·¸ë¦¼ë“¤ì€ PGDê°€ 20 step ë™ì‘í•  ë™ì•ˆ ì†ì‹¤ì´ ì–´ë–»ê²Œ ì¦ê°€í•˜ëŠ” ì§€ ë³´ì—¬ì¤€ë‹¤. ê°ê°ì˜ ë™ì‘ì€ ë™ì¼í•œ ì¼ë°˜ ì…ë ¥ì„ ë‘˜ëŸ¬ì‹¸ê³  ìˆëŠ” $\\ell_\\infty$-ballì•ˆì˜ ê· ë“±í•˜ê²Œ ë¬´ì‘ìœ„ì¸ ì ì—ì„œ ì‹œì‘í•˜ì˜€ë‹¤(ë‹¤ë¥¸ ì˜ˆì œì— ëŒ€í•œ ì¶”ê°€ì ì¸ ê·¸ë¦¼ì€ [ê·¸ë¦¼11]ì— ìˆë‹¤). ì ëŒ€ì  ì†ì‹¤ì€ ì ì€ ìˆ˜ì˜ ë°˜ë³µ ì´í›„ì— ìˆ˜í‰ì„ ì´ë£¬ë‹¤. ìµœì í™” ê¶¤ì ê³¼ ìµœì¢… loss ê°’ì´ CIFAR10ì—ì„œ íŠ¹íˆ, ìƒë‹¹íˆ ëª°ë ¤ìˆë‹¤. ë”ìš±ì´, ì ëŒ€ì ìœ¼ë¡œ í›ˆë ¨ëœ networkì˜ ìµœì¢… loss ê°’ì€ í‘œì¤€ í›ˆë ¨ë³´ë‹¤ í›¨ì”¬ ì‘ë‹¤. maximaì˜ ì§‘ì¤‘ì— ëŒ€í•´ ë”ìš± ì¡°ì‚¬í•˜ì—¬, ë§ì€ ìˆ˜ì˜ ë¬´ì‘ìœ„ ì¬ì‹œì‘ì„ ê´€ì°°í•˜ì˜€ê³ , ìµœì¢… ë°˜ë³µì˜ loss ê°’ì´ ê·¹ë‹¨ì ì¸ ì´ìƒì¹˜ ì—†ì´ ì˜ ì§‘ì¤‘ëœ ë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤ëŠ” ê²ƒì„ ê´€ì°°í•˜ì˜€ë‹¤. ([ê·¸ë¦¼2] ì°¸ì¡°; $10^5$ë²ˆì˜ ì¬ì‹œì‘ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ ì§‘ì¤‘ì„ í™•ì¸í•˜ì˜€ë‹¤) [ê·¸ë¦¼2] MNISTì™€ CIFAR10 ê²€ì¦ ë°ì´í„°ì…‹ì—ì„œ ë‹¤ì„¯ê°œì˜ ì˜ˆë“¤ì— ëŒ€í•œ cross-entropy lossì—ì„œ ì£¼ì–´ì§„ local maximaê°’ë“¤. ê° ì˜ˆë“¤ì€ ì˜ˆì œë“¤ì„ ë‘˜ëŸ¬ì‹¼ $\\ell_\\infty$-ballì•ˆì˜ ê· ì¼í•˜ê²Œ ë¬´ì‘ìœ„í•œ $10^5$ê°œì˜ ì§€ì ì—ì„œ PGDë¥¼ ì‹œì‘í•˜ì˜€ê³ , ì†ì‹¤ì´ í‰í‰í•´ì§ˆ ë•Œê¹Œì§€ PGDë¥¼ ë°˜ë³µí•˜ì˜€ë‹¤. íŒŒë€ íˆìŠ¤í† ê·¸ë¨ì€ í‘œì¤€ networkì˜ ì†ì‹¤ì— í•´ë‹¹í•˜ëŠ” ë°˜ë©´, ë¹¤ê°„ íˆìŠ¤í† ê·¸ë¨ì€ ì ëŒ€ì ìœ¼ë¡œ í›ˆë ¨ëœ networkì˜ ì†ì‹¤ì— í•´ë‹¹í•œë‹¤. ì ëŒ€ì ìœ¼ë¡œ í›ˆë ¨ëœ networkì˜ ì†ì‹¤ì´ ëˆˆì— ë„ê²Œ ì‘ê³ , ìµœì¢… ì†ì‹¤ê°’ë“¤ì´ ì´ìƒì¹˜ ì—†ì´ ë§¤ìš° ì§‘ì¤‘ì ì´ë‹¤. maximaê°€ ëˆˆì— ë„ê²Œ ë¶„ë¦¬ë˜ì–´ ìˆë‹¤ëŠ” ê²ƒì„ ë³´ì´ê¸° ìœ„í•´ ëª¨ë“  ìŒ ì‚¬ì´ì˜ $\\ell_2$ ê±°ë¦¬ì™€ ê°ë„ë¥¼ ì¸¡ì •í•˜ì˜€ê³ , ê±°ë¦¬ë“¤ì´ $\\ell_\\infty$-ballì•ˆì˜ ë‘ ê°œì˜ ë¬´ì‘ìœ„ ì§€ì  ì‚¬ì´ì˜ ì˜ˆìƒëœ ê±°ë¦¬ì™€ ìœ ì‚¬í•˜ê²Œ ë¶„í¬ë˜ì—ˆë‹¤ëŠ” ê²ƒê³¼, ìˆ˜ì§ì— ê°€ê¹Œìš´ ê°ë„ë¥¼ ê°€ì§„ë‹¤ëŠ” ê²ƒì„ ê´€ì°°í•˜ì˜€ë‹¤. local maxima ì‚¬ì´ì˜ ì„ ë¶„ì— ë”°ë¥´ë©´, lossëŠ” convexí•˜ë©°, ëì ì—ì„œ ìµœëŒ“ê°’ì„ ì´ë£¨ê³  ì¤‘ê°„ì—ì„œ ìƒìˆ˜ ì¸ìì— ì˜í•´ ê°ì†Œëœë‹¤. ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³ , ì „ì²´ ì„ ë¶„ì—ì„œ ì†ì‹¤ì€ ë¬´ì‘ìœ„ ì§€ì ì—ì„œì˜ ì†ì‹¤ë³´ë‹¤ ìƒë‹¹íˆ ë†’ë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ìš°ë¦¬ëŠ” maximaì˜ ë¶„í¬ê°€ ìµœê·¼ ë°œì „ëœ ì ëŒ€ì  ì˜ˆì œì— ëŒ€í•œ ë¶€ë¶„ ê³µê°„ ê´€ì ì´ ê³µê²©ì˜ í’ë¶€í•¨[29]ì„ ì™„ì „íˆ í¬ì°©í•˜ì§€ ëª»í•œë‹¤ëŠ” ê²ƒì„ ì‹œì‚¬í•œë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆë‹¤. íŠ¹íˆ, ì…ë ¥ì˜ ê·¸ë ˆë””ì–¸íŠ¸ì™€ í•¨ê»˜ ìŒì˜ ë‚´ì ì„ ì‚¬ìš©í•œ ì ëŒ€ì  êµë€ê³¼, êµë€ì˜ ê·œëª¨ê°€ ì¦ê°€í•¨ì— ë”°ë¼ ê·¸ë ˆë””ì–¸íŠ¸ ë°©í–¥ê³¼ì˜ ì „ë°˜ì ì¸ ìƒê´€ê´€ê³„ê°€ ì•½í™”ëœë‹¤ëŠ”ì„ ê´€ì°°í–ˆë‹¤.ì´ëŸ¬í•œ ëª¨ë“  ì¦ê±°ë“¤ì€ ë‹¤ìŒì— ë³´ê²Œ ë  ê²ƒì²˜ëŸ¼ PGDê°€ first-order ì ‘ê·¼ë²•ë“¤ ì‚¬ì´ì—ì„œ â€œë³´í¸ì ì¸â€ adversaryë¼ëŠ” ê²ƒì„ ê°€ë¦¬í‚¨ë‹¤.3.2 First-Order Adversariesìš°ë¦¬ì˜ ì‹¤í—˜ì€ PGDê°€ ì°¾ì€ local maximaê°€ ì¼ë°˜ì ìœ¼ë¡œ í›ˆë ¨ëœ networkì™€ ì ëŒ€ì ìœ¼ë¡œ í›ˆë ¨ëœ network ì—ì„œ ëª¨ë‘ ë¹„ìŠ·í•œ ì†ì‹¤ê°’ì„ ê°€ì§„ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤€ë‹¤. ì´ëŸ° ì§‘ì¤‘ì ì¸ í˜„ìƒì€ PGD adversaryì— ëŒ€í•œ robustnessê°€ ëª¨ë“  first-order adversaryë“¤ì— ëŒ€í•œ robustnessë¥¼ ì‚°ì¶œí•œë‹¤ëŠ” ë¬¸ì œì— ëŒ€í•œ í¥ë¯¸ë¡œìš´ ê´€ì ì„ ì‹œì‚¬í•œë‹¤. adversaryê°€ ì…ë ¥ì— ê´€í•œ ì†ì‹¤ í•¨ìˆ˜ì˜ ê·¸ë ˆë””ì–¸íŠ¸ë§Œ ì‚¬ìš©í•˜ëŠ” í•œ, PGDë³´ë‹¤ í›¨ì”¬ ë” ë‚˜ì€ local maximaë¥¼ ì°¾ì§€ ëª»í•  ê²ƒìœ¼ë¡œ ê°„ì£¼ëœë‹¤. ì´ ê°€ì„¤ì— ëŒ€í•œ ë”ìš± ì‹¤í—˜ì ì¸ ê·¼ê±°ë¥¼ ì„¹ì…˜5ì—ì„œ ë‹¤ë£°ê²ƒì´ë‹¤: ë§Œì•½ PGD adversaryë“¤ì— robustí•˜ë„ë¡ networkë¥¼ í›ˆë ¨í•œë‹¤ë©´, ì´ê²ƒì€ ê´‘ë²”ìœ„í•œ ë‹¤ë¥¸ ê³µê²©ì—ë„ robustí•˜ë‹¤.ë¬¼ë¡ , PGDì— ëŒ€í•œ ìš°ë¦¬ì˜ ì—°êµ¬ëŠ” í›¨ì”¬ ë” í° í•¨ìˆ«ê°’ì„ ê°–ëŠ” ì–´ë–¤ ê³ ë¦½ëœ maximaì˜ ì¡´ì¬ë¥¼ ë°°ì œí•˜ì§€ ì•ŠëŠ”ë‹¤. ê·¸ëŸ¬ë‚˜, ìš°ë¦¬ì˜ ì‹¤í—˜ì€ ê·¸ëŸ¬í•œ ë” í° local maximaê°€ first-order methodë¡œëŠ” ì°¾ê¸° í˜ë“¤ ê²ƒì„ì„ ì‹œì‚¬í•œë‹¤. ë§ì€ ë¬´ì‘ìœ„ ì¬ì‹œì‘ì˜ ì‹œë„ì—ë„, í¬ê²Œ ë‹¤ë¥¸ ì†ì‹¤ê°’ì˜ í•¨ìˆ«ê°’ì„ ì°¾ì§€ ëª»í•˜ì˜€ë‹¤. adversaryì˜ ê³„ì‚° ëŠ¥ë ¥ì„ attack modelì— í†µí•©í•˜ëŠ” ê²ƒì€ í˜„ëŒ€ ì•”í˜¸í•™ì˜ ì´ˆì„ì¸ polynomially bounded adversaryì˜ ê°œë…ì„ ì—°ìƒì‹œì¼œì•¼ í•œë‹¤. ê±°ê¸°ì„œ, ì´ ê³ ì „ì ì¸ attack modelì€ adversaryì—ê²Œ í•´ê²°í•˜ëŠ” ë° ë‹¤í•­ ì‹œê°„ì´ ë“œëŠ” ë¬¸ì œë“¤ë§Œ í’€ ìˆ˜ ìˆë„ë¡ í—ˆë½í•œë‹¤. ì—¬ê¸°ì„œ ìš°ë¦¬ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ë§¥ë½ì— ë” ì í•©í•˜ë„ë¡ adversaryì˜ ëŠ¥ë ¥ì— optimization-based ê´€ì ì„ ì±„ìš©í•˜ì˜€ë‹¤. ê²°êµ­ì—ëŠ”, ìš°ë¦¬ëŠ” ë§ì€ ìµœê·¼ ë¨¸ì‹  ëŸ¬ë‹ ë¬¸ì œë“¤ì˜ ëŒ€í•œ ê³„ì‚°ë³µì¡ë„ì˜ ì² ì €í•œ ì´í•´ë¥¼ ì•„ì§ ê°œë°œí•˜ì§€ ëª»í–ˆë‹¤. ê·¸ëŸ¬ë‚˜, MLì˜ ëŒ€ë¶€ë¶„ì˜ optimization ë¬¸ì œëŠ” first-order ë°©ë²•ìœ¼ë¡œ í•´ê²°ë˜ë©°, SGDì˜ ë³€í˜•ë“¤ì€ íŠ¹íˆ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ëŠ” ê°€ì¥ íš¨ê³¼ ì ì¸ ë°©ë²•ì´ë‹¤. ë”°ë¼ì„œ ìš°ë¦¬ëŠ” first-orderì •ë³´ì— ì˜ì¡´í•˜ëŠ” í˜•ì‹ì˜ ê³µê²©ì´, ì–´ë–¤ ì˜ë¯¸ì—ì„œëŠ”, ë”¥ëŸ¬ë‹ì˜ í˜„ì¬ ê´€í–‰ì— ë³´í¸ì ì´ë¼ê³  ë¯¿ëŠ”ë‹¤.ì´ ë‘ê°€ì§€ ì•„ì´ë””ì–´ë¥¼ ì¢…í•©í•˜ë©´, robustnessê°€ ë³´ì¥ëœ ë¨¸ì‹  ëŸ¬ë‹ ëª¨ë¸ë¡œ ê°€ëŠ” ê¸¸ì´ ë„í‘œí™” ëœë‹¤. ë„¤íŠ¸ì›Œí¬ë¥¼ PGD adversaryì— ëŒ€í•´ robustí•˜ë„ë¡ í›ˆë ¨í•˜ë©´ í˜„ì¬ì˜ ëª¨ë“  ì ‘ê·¼ ë°©ì‹ì„ í¬ê´„í•˜ëŠ” ê´‘ë²”ìœ„í•œ ê³µê²©ì— ëŒ€í•´ robustí•´ì§ˆ ê²ƒì´ë‹¤.ì‹¤ì œë¡œ, ì´ëŸ¬í•œ robustnessëŠ” black-box attacksì˜ ë§¥ë½ì—ì„œ ë”ìš± ê°•í•´ì§€ëŠ” ê²ƒì„ ë³´ì¥í•œë‹¤. ë¸”ë°• ì–´íƒì´ë€, adversaryê°€ target networkì— ì§ì ‘ì ì¸ ì ‘ê·¼ì´ ë¶ˆê°€ëŠ¥í•œ ìƒíƒœì—ì„œ í•˜ëŠ” ê³µê²©ì„ ëœ»í•œë‹¤. ëŒ€ì‹ , adversaryëŠ” (ëŒ€ëµì ì¸)ëª¨ë¸ì˜ ì•„í‚¤í…ì³ë‚˜ í›ˆë ¨ ë°ì´í„°ì…‹ê³¼ ê°™ì€ ë³´ë‹¤ ì ì€ íŠ¹ì •í•œ ì •ë³´ë§Œì„ ê°€ì§„ë‹¤. ì´ëŸ¬í•œ attack modelì„ â€œzero orderâ€ ê³µê²©ì˜ ì˜ˆì‹œë¡œ ë³¼ ìˆ˜ ìˆë‹¤. â€œzero orderâ€ ê³µê²©ì´ë€, adversaryê°€ ë¶„ë¥˜ê¸°ì— ì§ì ‘ì ì¸ ì ‘ê·¼ì´ ë¶ˆê°€ëŠ¥í•˜ë©°, gradient feedbackì´ ì—†ëŠ” íŠ¹ì • ì˜ˆì œì— ëŒ€í•œ ê²€ì¦ë§Œì´ ê°€ëŠ¥í•œ ê³µê²©ì„ ë§í•œë‹¤.ìš°ë¦¬ëŠ” appendixì˜ ì„¹ì…˜ Bì—ì„œ transferabilityì— ëŒ€í•´ ë…¼ì˜í•œë‹¤. ìš°ë¦¬ëŠ” network capacityë¥¼ ëŠ˜ë¦¬ê³  í›ˆë ¨í•˜ëŠ” ìƒëŒ€(í‘œì¤€ì ì¸ í›ˆë ¨ ëŒ€ì‹  FGSM or PGD í›ˆë ¨)ë¥¼ ê°•í™”ì‹œí‚¤ë©´ transfer attackì— ëŒ€í•œ ë‚´ì„±ì´ í–¥ìƒëœë‹¤ëŠ” ê²ƒì„ ê´€ì°°í–ˆë‹¤. ë˜í•œ, ì˜ˆìƒí•œ ê²ƒì²˜ëŸ¼, ê·¸ëŸ¬í•œ ê³µê²©ì— ëŒ€í•œ ìš°ë¦¬ì˜ ìµœê³ ì˜ ëª¨ë¸ì˜ ë‚´ì„±ì€ (ê°€ì¥ ê°•í•œ)first order ê³µê²©ë³´ë‹¤ í›¨ì”¬ ë” í° ê²½í–¥ì´ ìˆë‹¤.3.3 ì ëŒ€ì  í›ˆë ¨ì˜ Descent Directionsì•ì„œí•œ ë…¼ì˜ëŠ” ë‚´ë¶€ optimization problemì´ PGDë¥¼ ì ìš©í•¨ìœ¼ë¡œì¨ ì„±ê³µì ìœ¼ë¡œ í•´ê²°ë  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ì‹œì‚¬í•œë‹¤. adversarially robust networkë¥¼ í›ˆë ¨í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” (2.1) ë§ì•ˆì¥ì  ê³µì‹ì˜ ì™¸ë¶€ optimization ë¬¸ì œ ë˜í•œ í•´ê²°í•  í•„ìš”ê°€ ìˆë‹¤. ì¦‰, ë‚´ë¶€ ìµœëŒ€í™” ë¬¸ì œì˜ â€œì ëŒ€ì  ì†ì‹¤â€ì„ ìµœì†Œí™”í•˜ëŠ” model parameterë¥¼ ì°¾ëŠ” ê²ƒì´ë‹¤.ì‹ ê²½ë§ í›ˆë ¨ì˜ ë§¥ë½ì—ì„œ, ì†ì‹¤í•¨ìˆ˜ë¥¼ ìµœì†Œí™” í•˜ëŠ” ëŒ€í‘œì ì¸ ë°©ë²•ì€ Stochastic Gradient Descent (SGD)ì´ë‹¤. ì™¸ë¶€ ë¬¸ì œì˜ ê·¸ë ˆë””ì–¸íŠ¸ì¸ $\\nabla_\\theta\\rho(\\theta)$ë¥¼ ê³„ì‚°í•˜ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ë°©ë²•ì€ ë‚´ë¶€ ë¬¸ì œì˜ ìµœëŒ€ì¹˜ì—ì„œ ì†ì‹¤í•¨ìˆ˜ì˜ ê·¸ë ˆë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•˜ëŠ” ê²ƒì´ë‹¤. ì´ëŠ” ì ëŒ€ì  êµë€ìœ¼ë¡œ ì…ë ¥ì„ ëŒ€ì²´í•˜ê³  êµë€ëœ ì…ë ¥ì— ëŒ€í•´ ì¼ë°˜ì ì¸ í›ˆë ¨ì„ í•˜ëŠ”ê²ƒì— í•´ë‹¹ëœë‹¤. ì´ê²ƒì´ ë§ì•ˆì¥ì  ë¬¸ì œì— ëŒ€í•œ ìœ íš¨í•œ descent directionì¸ì§€ëŠ” ëª…í™•í•˜ì§€ ì•Šë‹¤. ê·¸ëŸ¬ë‚˜, ì—°ì†ì´ê³  ë¯¸ë¶„ê°€ëŠ¥í•œ í•¨ìˆ˜ì˜ ê²½ìš°, Danskin ì •ë¦¬(opimizationì˜ ê³ ì „ì ì¸ ì •ë¦¬)ëŠ” ì´ê²ƒì´ ì‹¤ì œë¡œ ì°¸ì´ë©°, ë‚´ë¶€ ìµœëŒ€ì¹˜ì—ì„œì˜ ê·¸ë ˆë””ì–¸íŠ¸ëŠ” ë§ì•ˆì¥ì  ë¬¸ì œì—ì„œì˜ ì˜¬ë°”ë¥¸ descent directionì„ì„ ì„¤ëª…í•œë‹¤.Danskin ì •ë¦¬ì˜ ì •í™•í•œ ê°€ì •ì€ ìš°ë¦¬ì˜ ë¬¸ì œì— í•´ë‹¹í•˜ì§€ ì•Šì§€ë§Œ (ReLUì™€ max-pooling ìœ ë‹›ìœ¼ë¡œ ì¸í•´, í•¨ìˆ˜ëŠ” ë¶ˆì—°ì†ì´ê³  ë¯¸ë¶„ ë¶ˆê°€ëŠ¥í•˜ë©°, ë‚´ë¶€ ë¬¸ì œì˜ ê·¼ì‚¬ì ì¸ ìµœëŒ€ì¹˜ë§Œ ê³„ì‚°í•˜ê³  ìˆë‹¤). ìš°ë¦¬ì˜ ì‹¤í—˜ì€ ë¬¸ì œë¥¼ ìµœì í™”í•˜ê¸° ìœ„í•´ ì´ëŸ¬í•œ ê·¸ë ˆë””ì–¸íŠ¸ë¥¼ ì—¬ì „íˆ ì‚¬ìš©í•  ìˆ˜ ìˆìŒì„ ì•Œë ¤ì¤€ë‹¤. ì ëŒ€ì  ì˜ˆì œì—ì„œ ì†ì‹¤ì˜ ê·¸ë ˆë””ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ SGDë¥¼ ì ìš©í•˜ë©´ [ê·¸ë¦¼5]ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ í›ˆë ¨ ì¤‘ ë§ì•ˆì¥ì  ë¬¸ì œì˜ ì†ì‹¤ì„ ì§€ì†ì ìœ¼ë¡œ ì¤„ì¼ ìˆ˜ ìˆë‹¤. ì´ëŸ¬í•œ ê´€ì°°ì€ ìš°ë¦¬ê°€ ì‹ ë¢°í•  ìˆ˜ ìˆê²Œ ë§ì•ˆì¥ì  ë¬¸ì œ (2.1)ì„ ìµœì í™”í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒê³¼, ë”°ë¼ì„œ robust ë¶„ë¥˜ê¸°ë¥¼ í›ˆë ¨í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ì‹œì‚¬í•œë‹¤. ìš°ë¦¬ëŠ” Danskin ì •ë¦¬ë¥¼ ìˆ˜ì‹ì ìœ¼ë¡œ ì„¤ëª…í•˜ê³  ìš°ë¦¬ì˜ ë¬¸ì œì— ì–´ë–»ê²Œ ì ìš©ë¬ëŠ”ì§€ Appendix. Aì—ì„œ ì„¤ëª…í•œë‹¤.4 Network Capacityì™€ ì ëŒ€ì  Robustnessì„±ê³µì ìœ¼ë¡œ (2.1) ë°©ì •ì‹ì„ í•´ê²°í•˜ëŠ” ê²ƒì€ robustë¥¼ ë³´ì¦í•˜ê³ , ë¶„ë¥˜ê¸°ë¥¼ ì •í™•í•˜ê²Œ í•˜ëŠ” ê²ƒì— ì¶©ë¶„í•˜ì§€ ì•Šë‹¤. í•´ë‹¹ ë¬¸ì œì— ëŒ€í•œ value(ì ëŒ€ì  ì˜ˆì œì— ëŒ€í•´ì„œ ë‹¬ì„±í•œ ìµœì¢… loss)ê°€ ì‘ê³ , ë”°ë¼ì„œ ë¶„ë¥˜ê¸°ì˜ ë™ì‘ì´ guaranteeë¥¼ ì œê³µí•œë‹¤ëŠ” ê²ƒì„ ì…ì¦í•  í•„ìš”ê°€ ìˆë‹¤. íŠ¹íˆ, ë§¤ìš° ì‘ì€ loss ê°’ì˜ ë‹¬ì„±ì€ ì ëŒ€ì  ì…ë ¥ì— robustí•œ ì™„ë²½í•œ ë¶„ë¥˜ê¸°ì— í•´ë‹¹í•œë‹¤.ê°€ëŠ¥í•œ êµë€ë“¤ì˜ ê³ ì •ëœ ì§‘í•© $\\mathcal{S}$ì— ëŒ€í•´, ì´ ë¬¸ì œì˜ ê°’ì€ ìš°ë¦¬ê°€ í•™ìŠµí•˜ëŠ” ë¶„ë¥˜ê¸°ì˜ ì•„í‚¤í…ì³ì— ì™„ì „íˆ ì¢…ì†ì ì´ë‹¤. ê²°ê³¼ì ìœ¼ë¡œ, ëª¨ë¸ì˜ ì•„í‚¤í…ì²˜ capacityëŠ” ì „ì²´ì ì¸ ì„±ëŠ¥ì˜ ì˜í–¥ì„ ì£¼ëŠ” ì£¼ìš”í•œ ìš”ì¸ì´ë‹¤. ë†’ì€ ìˆ˜ì¤€ì—ì„œ ë§í•˜ìë©´(ì¶”ìƒì ìœ¼ë¡œ), robustí•œ ë°©ì‹ìœ¼ë¡œ ì˜ˆì œë“¤ì„ ë¶„ë¥˜í•˜ëŠ” ê²ƒì€ ê°•ë ¥í•œ ë¶„ë¥˜ê¸°ë¥¼ ìš”êµ¬í•˜ëŠ”ë°, ì´ëŠ” ì ëŒ€ì  ì˜ˆì œì˜ ì¡´ì¬ê°€ ë¬¸ì œì˜ decision boundaryë¥¼ ë³´ë‹¤ ë³µì¡í•˜ê²Œ ë§Œë“¤ê¸° ë•Œë¬¸ì´ë‹¤. ([ê·¸ë¦¼3] ì°¸ì¡°) [ê·¸ë¦¼3] í‘œì¤€ decision boundaryì™€ ì ëŒ€ì  decision boundaryì˜ ê°œë…ë„. ì™¼ìª½ì€ ê°„ë‹¨í•œ decision boundaryë¡œ ì‰½ê²Œ ë¶„ë¥˜ ê°€ëŠ¥í•œ ì ë“¤ì˜ ì§‘í•©ì„. ê°€ìš´ë°ëŠ” ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ë‘˜ëŸ¬ì‹¸ëŠ” $\\ell_\\infty$-ball(ì‚¬ê°í˜•)ì„ ë¶„ë¥˜í•˜ì§€ ëª»í•˜ëŠ” ë‹¨ìˆœí•œ decision boundary. ë”°ë¼ì„œ ì ëŒ€ì  ì˜ˆì œë“¤(ë¹¨ê°„ ë³„)ì´ ì˜¤ë¶„ë¥˜ëœë‹¤. ì˜¤ë¥¸ìª½ì€ $\\ell_\\infty$-ballì„ ë¶„ë¥˜í•˜ê¸° ìœ„í•œ ë” ë³µì¡í•œ decision boundaryì„. í•´ë‹¹ ë¶„ë¥˜ê¸°ëŠ” ìœ ê³„ $\\ell_\\infty$-norm êµë€ì˜ ì ëŒ€ì  ì˜ˆì œì— ëŒ€í•´ robustí•˜ë‹¤.ìš°ë¦¬ì˜ ì‹¤í—˜ì€ capacityê°€ ê°•ë ¥í•œ adversaryë“¤ì— ëŒ€í•˜ì—¬ ì„±ê³µì ìœ¼ë¡œ í›ˆë ¨í•˜ëŠ” ê²ƒê³¼, robustnessì— ì¤‘ìš”í•˜ë‹¤ëŠ” ê²ƒì„ ì¦ëª…í–ˆë‹¤. MNIST ë°ì´í„°ì…‹ì—ì„œ, ìš°ë¦¬ëŠ” ê°„ë‹¨í•œ í•©ì„±ê³± ì‹ ê²½ë§ì„ ê³ ë ¤í•˜ì˜€ê³ , ì—¬ëŸ¬ adversaryë“¤ë¡œë¶€í„° networkì˜ í¬ê¸°ë¥¼ ë‘ ë°°ì”© ëŠ˜ë¦´ ë•Œ ì–´ë–»ê²Œ í–‰ë™ì´ ë³€í™”í•˜ëŠ”ì§€ ì—°êµ¬í•˜ì˜€ë‹¤. (í•©ì„±ê³± í•„í„°ì˜ ìˆ˜ì™€ fully connected layerì˜ í¬ê¸°ë¥¼ ë‘ ë°°ë¡œ ëŠ˜ë ¸ë‹¤.) networkëŠ” 2ê°œ í•„í„°ì˜ í•©ì„±ê³± layerì™€, ì´ì–´ì„œ 4ê°œì˜í•„í„°ê°€ ìˆëŠ” ë˜ ë‹¤ë¥¸ í•©ì„±ê³± ë ˆì´ì–´ ê·¸ë¦¬ê³  64ê°œì˜ ìœ ë‹›ì˜ fully connected layerë¡œ ì´ˆê¸°í™”ë˜ì—ˆë‹¤. í•©ì„±ê³± ë ˆì´ì–´ ë’¤ì—ëŠ” $2\\times 2$ max-pooling ë ˆì´ì–´ê°€ ë”°ë¥´ê³  $\\epsilon=0.3$ì˜ ì ëŒ€ì  ì˜ˆì œë¡œ êµ¬ì„±ë˜ì—ˆë‹¤. ê²°ê³¼ëŠ” [ê·¸ë¦¼4]ì— ìˆë‹¤.CIFAR10 ë°ì´í„°ì…‹ì—ì„œëŠ” ResNet ëª¨ë¸ì„ ì‚¬ìš©í•˜ì˜€ë‹¤. random cropsì™€ flipsë¥¼ ì´ìš©í•˜ì—¬ data augmentaionê³¼ image standarizationì„ ìˆ˜í–‰í•˜ì˜€ë‹¤. capacityë¥¼ ëŠ˜ë¦¬ê¸° ìœ„í•´, networkì˜ ë” ë„“ì€ ë ˆì´ì–´ë¥¼ í¬í•¨í•˜ëŠ” ë ˆì´ì–´ë¥¼ 10ë°°ë¡œ ìˆ˜ì •í•˜ì˜€ë‹¤. ì´ëŠ” ê°ê° (16, 160, 320, 640)ì˜ í•„í„°ë¥¼ ê°€ì§„ 5ê°œì˜ residual unitì˜ networkë¥¼ ë§Œë“¤ì–´ëƒˆë‹¤. ì´ networkëŠ” ì¼ë°˜ì ì¸ ì…ë ¥ì—ì„œ í›ˆë ¨í–ˆì„ ë•Œ 95.2%ì˜ ì •í™•ë„ë¥¼ ë‹¬ì„±í•  ìˆ˜ ìˆì—ˆë‹¤. ì ëŒ€ì  ì˜ˆì œëŠ” $\\epsilon=8.$ë¡œ ë§Œë“¤ì–´ì¡Œë‹¤. capacity ì‹¤í—˜ì— ëŒ€í•œ ê²°ê³¼ëŠ” [ê·¸ë¦¼ 4]ì— ìˆë‹¤. [ê·¸ë¦¼4] networkì˜ ì„±ëŠ¥ì—ì„œì˜ network capacityì˜ ì˜í–¥. ë‹¤ì–‘í•œ capacityì—ì„œ MNISTì™€ CIFAR10 networkë¥¼ í›ˆë ¨í•˜ì˜€ë‹¤. (a)ëŠ” ì¼ë°˜ì ì¸ ì…ë ¥ì´ê³ , (b)ëŠ” FGSMì´ ë§Œë“  ì ëŒ€ì  ì…ë ¥ë“¤, (c)ëŠ” PGDê°€ ë§Œë“  ì ëŒ€ì  ì…ë ¥ì´ë‹¤. ê° ë°ì´í„°ì…‹ì˜ ì²« ì„¸ ê°œì˜ ê·¸ë¦¼ê³¼ í‘œì—ì„œ, í‘œì¤€ê³¼ ì ëŒ€ì ì¸ ê°ê°ì˜ í›ˆë ¨ ì²´ì œ í•˜ì—ì„œì˜ capacityì— ë”°ë¥¸ ì •í™•ë„ì˜ ë³€í™”ë¥¼ ë³´ì˜€ë‹¤. ë§ˆì§€ë§‰ ê·¸ë¦¼ê³¼ í‘œì—ì„œëŠ”, networkê°€ í›ˆë ¨ëœ ì ëŒ€ì  ì…ë ¥ë“¤ì˜ cross-entropy lossì˜ ê°’ì„ ë³´ì˜€ë‹¤. ì´ëŠ” í—ˆìš©ëœ êµë€ë“¤ì˜ ì—¬ëŸ¬ ì§‘í•©ë“¤ì— ëŒ€í•œ ë§ì•ˆì¥ì  ë¬¸ì œ(2.1)ì˜ ê°’ì— í•´ë‹¹í•œë‹¤.ìš°ë¦¬ëŠ” ë‹¤ìŒê³¼ ê°™ì€ í˜„ìƒë“¤ì„ ê´€ì°°í–ˆë‹¤:capacityë§Œìœ¼ë¡œë„ ë„ì›€ì´ëœë‹¤. ìš°ë¦¬ëŠ” ì¼ë°˜ì ì¸ ì˜ˆì œë“¤ë§Œìœ¼ë¡œ í›ˆë ¨í•  ë•Œ, networkì˜ capacityë¥¼ ëŠ˜ë¦¬ëŠ” ê²ƒì´ one-step êµë€ì˜ robustnessë¥¼ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì„ ê´€ì°°í–ˆë‹¤.FGSM adversaryë“¤ì€ robustnessë¥¼ í–¥ìƒì‹œí‚¤ì§€ ì•ŠëŠ”ë‹¤ (í° $\\epsilon$ ì— ëŒ€í•´ì„œ). FGSMì—ì„œ ìƒì„±ëœ ì ëŒ€ì  ì…ë ¥ë“¤ì„ ì‚¬ìš©í•˜ì—¬ networkë¥¼ í›ˆë ¨í•  ë•Œ, networkê°€ ì´ëŸ¬í•œ ì ëŒ€ì  ì˜ˆì œì— ê³¼ì í•©ë˜ëŠ” ê²ƒì„ ë°œê²¬í–ˆë‹¤. ì´ëŸ¬í•œ í–‰ë™ì€ label leaking[18]ìœ¼ë¡œ ì•Œë ¤ì ¸ ìˆìœ¼ë©°, adversaryê°€ networkê°€ ê³¼ì í•© í•  ìˆ˜ ìˆëŠ” ë§¤ìš° ì œí•œì ì¸ ì ëŒ€ì  ì˜ˆì œë“¤ì˜ ì§‘í•©ì„ ìƒì„±í•œë‹¤ëŠ” ì‚¬ì‹¤ì—ì„œ ë¹„ë¡¯ëœë‹¤. ì´ëŸ¬í•œ networkë“¤ì€ ì¼ë°˜ì ì¸ ì…ë ¥ì—ì„œ ì¢‹ì§€ ì•Šì€ ì„±ëŠ¥ì„ ê°€ì§€ë©°, PGD adversaryì— ëŒ€í•œ ì–´ë–¤ ì¢…ë¥˜ì˜ robustnessë„ ë³´ì´ì§€ ì•Šì•˜ë‹¤. ë” ì‘ì€ $\\epsilon$ì˜ ê²½ìš°, ì¼ë°˜ì ì¸ ì…ë ¥ì„ ë‘˜ëŸ¬ì‹¸ê³  ìˆëŠ” $\\ell_\\infty$-ballì—ì„œì˜ lossëŠ” ì¢…ì¢… ì¶©ë¶„íˆ ì„ í˜•ì ì´ì–´ì„œ, FGSMì€ PGDì— ì˜í•´ ë°œê²¬ë˜ëŠ” ê²ƒë“¤ê³¼ ìœ ì‚¬í•œ ì ëŒ€ì  ì˜ˆì œë¥¼ ë°œê²¬í•˜ê¸° ë•Œë¬¸ì—, í›ˆë ¨í•˜ê¸°ì— í•©ë¦¬ì adversaryê°€ ë˜ëŠ” ê²ƒì´ë‹¤.ë‚˜ì•½í•œ ëª¨ë¸ì€ ë¹„ìëª…í•œ ë¶„ë¥˜ê¸°ë¥¼ í•™ìŠµí•˜ëŠ” ë° ì‹¤íŒ¨í•  ìˆ˜ ìˆë‹¤. ì‘ì€ capacityì˜ networkì˜ ê²½ìš°, ì¼ë°˜ì ì¸ í›ˆë ¨ì—ì„œëŠ” ì •í™•í•œ ë¶„ë¥˜ê¸°ê°€ ë  ìˆ˜ ìˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³ , ê°•ë ¥í•œ adversary (PGD)ì— ëŒ€í•œ í›ˆë ¨ì˜ ì‹œë„ëŠ” ìœ ì˜ë¯¸í•œ ê²ƒë“¤ì˜ í•™ìŠµì„ ë§‰ëŠ”ë‹¤. ì´ networkëŠ” í•­ìƒ ê³ ì •ëœ í´ë˜ìŠ¤ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì— ìˆ˜ë ´í•œë‹¤. networkì˜ ì‘ì€ capacityëŠ” ì ëŒ€ì ì¸ ì…ë ¥ì— ëŒ€í•œ ì–´ë–¤ ì¢…ë¥˜ë˜ì§€, robustnessë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ í•™ìŠµ ê³¼ì •ì—ì„œ ì¼ë°˜ì ì¸ ì…ë ¥ì— ëŒ€í•œ ì„±ëŠ¥ì„ í¬ìƒì‹œí‚¤ëŠ” ê²ƒì„ ê°•ì œí•œë‹¤.ë§ì•ˆì¥ì  ë¬¸ì œì˜ ê°’ì€ capacityë¥¼ ì¦ê°€ì‹œí‚¨ ë§Œí¼ ê°ì†Œí•œë‹¤. adversary ëª¨ë¸ì„ ê³ ì •ì‹œí‚¤ê³ , ê·¸ê²ƒì— ëŒ€í•´ í›ˆë ¨ì‹œí‚¬ ë•Œ, (2.1)ì˜ ê°’ì€ capacityê°€ ì¦ê°€í•œ ë§Œí¼ ê°ì†Œí–ˆìœ¼ë©°, ì´ëŠ” ëª¨ë¸ì´ ì ëŒ€ì  ì˜ˆì œì— ë” ì í•©ë  ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•œë‹¤.í° capacityì™€ ê°•ë ¥í•œ adversaryë“¤ì€ transferabilityë¥¼ ê°ì†Œì‹œí‚¨ë‹¤. networkì˜ capacityë¥¼ ì¦ê°€ì‹œí‚¤ê±°ë‚˜, ë‚´ë¶€ ìµœì í™” ë¬¸ì œì— ê°•ë ¥í•œ ë°©ë²•ì„ ì“°ëŠ” ê²ƒì€ ì „ì´ê°€ëŠ¥í•œ ì ëŒ€ì  ì…ë ¥ì˜ íš¨ìœ¨ì„±ì„ ê°ì†Œì‹œí‚¨ë‹¤. ìš°ë¦¬ëŠ” source networkì™€ transfer networkì˜ ê·¸ë ˆë””ì–¸íŠ¸ ê°„ì˜ ìƒê´€ ê´€ê³„ê°€ capacityê°€ ì¦ê°€í•  ìˆ˜ë¡ ëœ ì¤‘ìš”í•´ì§€ëŠ” ê²ƒì„ ê´€ì°°í•˜ì—¬ ì´ê²ƒì„ ì‹¤í—˜ì ìœ¼ë¡œ ê²€ì¦í–ˆë‹¤. appendix Bì—ì„œ ì´ ì‹¤í—˜ì— ëŒ€í•´ ì„¤ëª…í•œë‹¤.5 ì‹¤í—˜: ë³´í¸ì ìœ¼ë¡œ Robustí•œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ì „ ì„¹ì…˜ì—ì„œì˜ ë¬¸ì œì— ëŒ€í•œ ì´í•´ì— ë”°ë¼, robustí•œ ë¶„ë¥˜ê¸°ë¥¼ í›ˆë ¨í•˜ëŠ”ë° ìš°ë¦¬ê°€ ì œì•ˆí•œ ì ‘ê·¼ë²•ì„ ì ìš©ì‹œí‚¬ ìˆ˜ ìˆë‹¤. ìš°ë¦¬ì˜ ì‹¤í—˜ë“¤ì´ ì§€ê¸ˆê¹Œì§€ ì…ì¦í–ˆë“¯ì´, ë‘ ê°€ì§€ í•µì‹¬ ìš”ì†Œì— ì´ˆì ì„ ë§ì¶œ í•„ìš”ê°€ ìˆë‹¤: a) ì¶©ë¶„íˆ í° capacityì˜ networkë¥¼ í›ˆë ¨ì‹œí‚¤ê³ , b) ê°€ëŠ¥í•œ ê°€ì¥ ê°•ë ¥í•œ adversaryë¥¼ ì‚¬ìš©í•œë‹¤.MNISTì™€ CIFAR10 ëª¨ë‘ì—ì„œ, ì„ íƒëœ adversaryëŠ” ì¼ë°˜ì ì¸ ì…ë ¥ ì£¼ë³€ì˜ ë¬´ì‘ìœ„ êµë€ì—ì„œ ì‹œì‘í•˜ëŠ” PGDê°€ ë  ê²ƒì´ë‹¤. ì´ëŠ” â€œì™„ì „í•œâ€ first-order adversaryì— ëŒ€í•œ ìš°ë¦¬ì˜ ê°œë…ì— í•´ë‹¹í•˜ë©°, ì˜¤ì§ first order ì •ë³´ë§Œì„ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ì— ëŒ€í•œ lossë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ìµœëŒ€í™”í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì´ë‹¤. ì—¬ëŸ¬ ì—í­ìœ¼ë¡œ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ê¸° ë•Œë¬¸ì—, ë°°ì¹˜ë§ˆë‹¤ ì—¬ëŸ¬ë²ˆ PGDë¥¼ ì¬ì‹œì‘í•˜ëŠ” ê²ƒì€ ì•„ë¬´ ì´ë“ë„ ì—†ë‹¤. ì¦‰, ê° ì…ë ¥ì„ ë§ˆì£¼ì¹  ë•Œë§ˆë‹¤ ìƒˆë¡œìš´ ì‹œì‘ì ì´ ì„ íƒë  ê²ƒì´ë‹¤.ì´ëŸ¬í•œ adversaryì— ëŒ€í•´ì„œ í›ˆë ¨ì‹œí‚¬ ë•Œ, [ê·¸ë¦¼ 5]ì—ì„œ ë‚˜ì˜¤ë“¯ì´, ì ëŒ€ì  ì˜ˆì œì˜ training lossì—ì„œì˜ ê¾¸ì¤€í•œ ê°ì†Œë¥¼ ê´€ì°°í–ˆë‹¤. ì´ëŸ¬í•œ í–‰ë™ì€ í›ˆë ¨ì‹œí‚¤ëŠ” ë™ì•ˆ ì‹¤ì œë¡œ ì„±ê³µì ìœ¼ë¡œ ì›ë˜ì˜ optimization ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ìˆë‹¤ëŠ” ê²ƒì„ ê°€ë¦¬í‚¨ë‹¤. [ê·¸ë¦¼5]: í›ˆë ¨ì‹œí‚¤ëŠ” ë™ì•ˆ ì ëŒ€ì  ì˜ˆì œì— ëŒ€í•œ training loss. ì´ ê·¸ë¦¼ë“¤ì€ PGD adversaryì— ëŒ€í•œ MNISTì™€ CIFAR10 networkì˜ í›ˆë ¨ ì˜ˆì œì—ì„œì˜ adversarial lossê°€ ì–´ë–»ê²Œ ì§„í–‰ë˜ëŠ”ì§€ ë³´ì—¬ì¤€ë‹¤. CIFAR 10ê·¸ë¦¼ì—ì„œì˜ ê¸‰ê²©í•œ ê°ì†ŒëŠ” í›ˆë ¨ step í¬ê¸°ë¥¼ ê°ì†Œì‹œí‚¨ê²ƒì— í•´ë‹¹í•œë‹¤. ì´ ê·¸ë¦¼ë“¤ì€ ì§€ì†ì ìœ¼ë¡œ ë§ì•ˆì¥ì  ë¬¸ì œ (2.1)ì˜ ë‚´ë¶€ ë¬¸ì œì˜ ê°’ì„ ê°ì†Œì‹œí‚¤ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ê³ , ë”°ë¼ì„œ robust ë¶„ë¥˜ê¸°ë¥¼ í–¥ìƒì ì´ê²Œ ìƒì„±í•˜ê³  ìˆë‹¤.ìš°ë¦¬ëŠ” ë‹¤ì–‘í•œ ë²”ìœ„ì˜ adversaryì— ëŒ€í•´ì„œ í›ˆë ¨ëœ ëª¨ë¸ë“¤ì„ í‰ê°€í–ˆë‹¤. [í‘œ1]ì—ì„œ MNISTì— ëŒ€í•œ ê²°ê³¼ë¥¼ ë³´ì´ê³ , [í‘œ2]ì—ì„œëŠ” CIFAR10ì—ì„œì˜ ê²°ê³¼ë¥¼ ë³´ì¸ë‹¤. ìš°ë¦¬ê°€ ê³ ë ¤í•œ adversaryëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤: source $A$ë¡œ í‘œì‹œë˜ëŠ” ë‹¤ì–‘í•œ íšŸìˆ˜ì˜ ë°˜ë³µê³¼ ì¬ì‹œì‘ì˜ PGD white-box ê³µê²©. Carlini-Wagner(CW) loss í•¨ìˆ˜(ì •ë‹µê³¼ ì˜¤ë‹µì˜ logitì˜ ì°¨ì´ë¥¼ ì§ì ‘ì ìœ¼ë¡œ optimizingí•¨)[6]ë¥¼ ì‚¬ìš©í•œ PGD white-box ê³µê²©. CWë¡œ í‘œì‹œë˜ë©°, ë†’ì€ ì‹ ë¢°ë„ì˜ íŒŒë¼ë¯¸í„°(k=50)ì˜ í•´ë‹¹ë˜ëŠ” ê³µê²©ì€ CW+ë¡œ í‘œì‹œëœë‹¤. $Aâ€™$ë¡œ í‘œì‹œë˜ëŠ” ë…ë¦½ì ìœ¼ë¡œ í›ˆë ¨ëœ networkì˜ ì‚¬ë³¸ì—ì„œì˜ Black-box ê³µê²©. $A_{nat}$ë¡œ í‘œì‹œë˜ëŠ” ë™ì¼í•œ networkì˜ ì¼ë°˜ì ì¸ ì…ë ¥ì—ì„œë§Œ í›ˆë ¨ëœ ë²„ì „ì—ì„œì˜ black-box ê³µê²©. $B$ë¡œ í‘œì‹œë˜ëŠ” ë‹¤ì–‘í•œ í•©ì„±ê³± ì•„í‚¤í…ì²˜ì—ì„œì˜ black-box ê³µê²©.MNIST. ìš°ë¦¬ëŠ” adversaryë¡œì¨ 0.01ì˜ step sizeë¡œ 40ë²ˆ ë°˜ë³µí•œ PGDì„ ì‚¬ìš©í•˜ì˜€ë‹¤ ($\\ell_\\infty$ normì—ì„œì˜ ê·¸ë ˆë””ì–¸íŠ¸ ìŠ¤í…ì„ ì·¨í•˜ê¸°ë¥¼ ì„ íƒí–ˆë‹¤. ì¦‰, step sizeë¥¼ ê°„ë‹¨íˆ ë§Œë“¤ì–´ì£¼ê¸° ë•Œë¬¸ì—, ê·¸ë ˆë””ì–¸íŠ¸ì˜ ë¶€í˜¸ë¥¼ ë”í•œ ê²ƒì´ë‹¤). $\\epsilon=0.3$í¬ê¸°ì˜ êµë€ì— ëŒ€í•´ì„œ í›ˆë ¨í•˜ê³  ê²€ì¦í•˜ì˜€ë‹¤. 1024 í¬ê¸°ì˜ fully connected ë ˆì´ì–´ì™€, ê°ê° $2\\times 2$ max poolingê³¼, 32ê°œì™€ 64ê°œì˜ í•„í„°ì˜ ë‘ ê°œì˜ í•©ì„±ê³± ë ˆì´ì–´ë¡œ êµ¬ì„±ëœ networkë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤. ì¼ë°˜ì ì¸ ì…ë ¥ì—ì„œ í›ˆë ¨ì‹œí‚¬ ë•Œ, ì´ networkëŠ” ê²€ì¦ ì…‹ì—ì„œ 99.2%ì˜ ì •í™•ë„ë¥¼ ë‹¬ì„±í•˜ì˜€ë‹¤. ê·¸ëŸ¬ë‚˜ FGSMìœ¼ë¡œ êµë€ëœ ì…ë ¥ì—ì„œ ê²€ì¦í–ˆì„ ë•Œ ì •í™•ë„ëŠ” 6.4%ë¡œ ë–¨ì–´ì¡Œë‹¤. ì´ ì ëŒ€ì  ì •í™•ë„ ê²°ê³¼ëŠ” [í‘œ1]ì—ì„œ ë³´ê³ ëœë‹¤. ì£¼ì–´ì§„ MNIST ëª¨ë¸ì˜ ê²°ê³¼ëŠ” $\\ell_\\infty$-bounded adversaryë“¤ì—ê²Œ ë§¤ìš° robustí•˜ì˜€ê³ , ì ëŒ€ì  robustnessì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì§€ ì´í•´í•˜ê¸° ìœ„í•´ í•™ìŠµëœ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì‚¬í•˜ì˜€ë‹¤. ì¡°ì‚¬ì˜ ê²°ê³¼ëŠ” Appendix Cì—ì„œ ì„¤ëª…í•œë‹¤. íŠ¹íˆ, ìš°ë¦¬ëŠ” networkì˜ ì²«ë²ˆì§¸ í•©ì„±ê³± ë ˆì´ì–´ê°€ ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ë“¤ì€ sparseí•œ ê²½í–¥ì„ ë³´ì´ëŠ” ë° ë¹„í•´ ì…ë ¥ í”½ì…€ë“¤ì˜ thresholdë¥¼ í•™ìŠµí•œë‹¤ëŠ” ê²ƒì„ ë°œê²¬í•˜ì˜€ë‹¤. [í‘œ1]: MNIST: ë‹¤ì–‘í•œ adversaryì— ëŒ€í•´ì„œ $\\epsilon=0.3$ìœ¼ë¡œ ì ëŒ€ì  í›ˆë ¨ëœ ëª¨ë¸ì˜ ì„±ëŠ¥. ê° ê³µê²© ëª¨ë¸ì— ëŒ€í•œ ê°€ì¥ ì„±ê³µì ì¸ ê³µê²©ì€ ë³¼ë“œì²´ì„. ê³µê²©ì„ ìœ„í•´ ì‚¬ìš©ëœ source networkëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. ê·¸ network ìì²´ (A) (white-box attack), ë…ë¦½ì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìœ¼ë©°, ì´ í›ˆë ¨ëœ ë„¤íŠ¸ì›Œí¬ì˜ ë³µì‚¬ë³¸ (Aâ€™), [29]ì˜ ì•„í‚¤í…ì²˜ (B).CIFAR10. CIFAR10 ë°ì´í„°ì…‹ì—ì„œ, 4ì—ì„œ ì„¤ëª…í•œ ë‘ ê°œì˜ ì•„í‚¤í…ì³(original ResNetê³¼ ì´ê²ƒì˜ 10x ë³€í˜•)ë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤. ë‹¤ì‹œ $\\ell_\\infty$ PGD adversaryë¥¼ ì‚¬ìš©í•˜ì—¬ networkë¥¼ í›ˆë ¨ì‹œì¼°ê³ , ì´ë²ˆì—ëŠ” size 2ì˜ 7 ìŠ¤í…ì„ ì‚¬ìš©í•˜ì˜€ìœ¼ë©°, ì´ $\\epsilon=0.8$ ì´ë‹¤. ë‹¤ë¥¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì˜ ì„ íƒì´ ì •í™•ë„ì˜ ìœ ì˜ë¯¸í•œ ê°ì†Œë¥¼ ì¼ìœ¼í‚¤ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì—, ê°€ì¥ ë¹¡ì„¼ adversaryë¡œ ê°™ì€ ì„¤ì •ì˜ 20ìŠ¤í…ì„ ì„ íƒí•˜ì˜€ë‹¤. ì‹¤í—˜ì˜ ê²°ê³¼ëŠ” [í‘œ2]ì— ë‚˜ì™€ìˆë‹¤. [í‘œ2]: CIFAR10: $\\epsilon=8$ì˜ ë‹¤ì–‘í•œ adversaryì— ëŒ€í•´ì„œ ì ëŒ€ì ìœ¼ë¡œ í›ˆë ¨ëœ ëª¨ë¸ë“¤ì˜ ì„±ëŠ¥. ê° ê³µê²© ëª¨ë¸ì— ëŒ€í•´ì„œ ê°€ì¥ íš¨ê³¼ì ì¸ ê³µê²©ì€ ë³¼ë“œì²´ë¡œ í‘œì‹œí•˜ì˜€ë‹¤. ê³µê²©ì„ ìœ„í•´ ê³ ë ¤ëœ source networkëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤: ì´ network ìì²´ (A) (white-box attack), ë…ë¦½ì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ê³ , ì´ ëª¨ë¸ì˜ í›ˆë ¨ëœ ë³µì‚¬ë³¸ (Aâ€™), ì¼ë°˜ì ì¸ ì…ë ¥ì—ì„œ í›ˆë ¨ëœ networkì˜ ë³µì‚¬ë³¸ ($A_{nat}$)ë°˜ë³µì ì¸ adversaryë“¤ì˜ í˜ì„ ê³ ë ¤í•  ë•Œ networkì˜ ì ëŒ€ì  robustnessëŠ” ìƒë‹¹í•œ ìˆ˜ì¤€ì´ì—ˆì§€ë§Œ ë§Œì¡±í•˜ê¸°ì—” ë¶€ì¡±í–ˆë‹¤. ì´ëŸ¬í•œ ë°©í–¥ìœ¼ë¡œ ë°€ê³  ë‚˜ê°€ëŠ” ê²ƒê³¼ ë” í° capacityì˜ networkë¥¼ í›ˆë ¨ì‹œí‚´ìœ¼ë¡œì¨ ì´ëŸ¬í•œ ê²°ê³¼ë¥¼ ê°œì„ í•  ìˆ˜ ìˆë‹¤ê³  ë¯¿ëŠ”ë‹¤.$\\ell_2$ ì™€ $\\epsilon$ì˜ ì—¬ëŸ¬ ê°’ë“¤ì— ë”°ë¥¸ ì €í•­-bounded attacks. ëª¨ë¸ì˜ ì ëŒ€ì  robustnessì˜ ë„“ì€ í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ê¸° ìœ„í•´, ë‘ê°€ì§€ ì¶”ê°€ì ì¸ ì‹¤í—˜ì„ í•˜ì˜€ë‹¤. í•˜ë‚˜ëŠ” ì—¬ëŸ¬ê°’ë“¤ì˜ $\\epsilon$ì— ë”°ë¥¸ $\\ell_\\infty$ bounded attackì— ëŒ€í•œ ë‚´ì„±ì„ ì¡°ì‚¬í•˜ëŠ” ê²ƒì´ì—ˆê³ , ë‹¤ë¥¸ í•˜ë‚˜ëŠ” $\\ell_\\infty$-normê³¼ ë°˜ëŒ€ë¡œ $\\ell_2$-normì—ì„œì˜ bouned attackì— ëŒ€í•œ ì €í•­ì„ ì‹œí—˜í•˜ëŠ” ê²ƒì´ì—ˆë‹¤. $\\ell_2$-bouned PGDì˜ ê²½ìš°, ë¶€í˜¸ê°€ ì•„ë‹Œ ê·¸ë ˆë””ì–¸íŠ¸ ë°©í–¥ìœ¼ë¡œ ìŠ¤í…ì„ ì·¨í•˜ê³  ìŠ¤í… ì‚¬ì´ì¦ˆ ì¡°ì •ì„ ìš©ì´í•˜ê²Œ í•˜ê¸° ìœ„í•´ ìŠ¤í…ì„ ê³ ì •ëœ í¬ê¸°ë¡œ ì •ê·œí™”í–ˆë‹¤. ëª¨ë“  PGD ê³µê²©ì—ì„œ $\\epsilon$-ballì•ˆì˜ ì–´ë–¤ ì ì—ì„œ ì‹œì‘í•˜ë˜ì§€ ê·¸ê²ƒì˜ ê²½ê³„ì— ë„ë‹¬í•˜ëŠ” ê²ƒì„ ë³´ì¥í•˜ê¸° ìœ„í•´ 100ìŠ¤í…ì„ ì‚¬ìš©í•˜ì˜€ê³ , ìŠ¤í… ì‚¬ì´ì¦ˆë¥¼ $2.5\\cdot \\epsilon/100$ìœ¼ë¡œ í•˜ì˜€ë‹¤. (ê²½ê³„ì—ì„œì˜ ì›€ì§ì„ì€ ì—¬ì „íˆ í—ˆìš©ëœë‹¤.) $\\ell_\\infty$-bounded attackì— ëŒ€í•´ í›ˆë ¨ëœ ëª¨ë¸ì€ MNISTì—ì„œ $\\epsilon=0.3,$ CIFAR10ì—ì„œ $\\epsilon=8$ì„ ì‚¬ìš©í–ˆìŒì„ ìƒê¸°í•˜ì. [ê·¸ë¦¼6]ì— ì´ ê²°ê³¼ê°€ ë‚˜ì™€ìˆë‹¤. [ê·¸ë¦¼6]: ë‹¤ì–‘í•œ ê°•ë„ì˜ PGD adversaryë“¤ì— ëŒ€í•´ì„œ ì ëŒ€ì ìœ¼ë¡œ í›ˆë ¨ networkì˜ ì„±ëŠ¥. MNISTì™€ CIFAR10 networkëŠ” ê°ê° $\\epsilon=0.3$ê³¼ $\\epsilon=8$ì˜ PGD $\\ell_\\infty$ adversaryì— ëŒ€í•´ì„œ í›ˆë ¨ë˜ì—ˆë‹¤. (ì´ í›ˆë ¨ $\\epsilon$ì€ $\\ell_\\infty$í”Œë¡¯ì—ì„œ ë¹¨ê°„ ì ì„ ìœ¼ë¡œ í‘œí˜„ëœë‹¤. MNISTì—ì„œ ì ëŒ€ì ìœ¼ë¡œ í›ˆë ¨ëœ networkì˜ ì‚¬ë¡€ì—ì„œ, ìš°ë¦¬ëŠ” í‘œì¤€ì ì¸ 2000ìŠ¤í…ì˜ Decision Boundary Attack(DBA) [4]ì™€ PGD, ê·¸ë¦¬ê³  ê°ê°ì— ëŒ€í•´ì„œ ì ëŒ€ì ìœ¼ë¡œ í›ˆë ¨ëœ ëª¨ë¸ì„ í‰ê°€í•˜ì˜€ë‹¤. ìš°ë¦¬ëŠ” í›ˆë ¨ì— ì‚¬ìš©ëœ $\\epsilon$ì˜ ê°’ë³´ë‹¤ ì‘ê±°ë‚˜ ê°™ì„ ë•Œ, ì„±ëŠ¥ì´ í¬ê±°ë‚˜ ê°™ë‹¤ëŠ” ê²ƒì„ ê´€ì°°í•˜ì˜€ë‹¤. MNISTì—ì„œëŠ” ì§§ì€ ì§„í–‰ í›„ ë‚ ì¹´ë¡­ê²Œ ë–¨ì–´ì¡Œë‹¤. ë”ìš±ì´, MNISTì—ì„œ PGDë¥¼ ì‚¬ìš©í•œ $\\ell_2$-trained networkì˜ ì„±ëŠ¥ì´ ì¢‹ì§€ì•Šê³ , ëª¨ë¸ì˜ robustnessë¥¼ í¬ê²Œ ê³¼ëŒ€í‰ê°€í•˜ê³  ìˆë‹¤ëŠ” ê²ƒì„ ê´€ì°°í–ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ í•™ìŠµí•œ threshold filterê°€ loss ê·¸ë ˆë””ì–¸íŠ¸ë¥¼ maskingí•˜ëŠ” ê²ƒì— ê¸°ì¸í•  ê°€ëŠ¥ì„±ì´ ìˆë‹¤. (decision-based attackì€ ê·¸ë ˆë””ì–¸íŠ¸ë¥¼ ì´ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤.)ìš°ë¦¬ëŠ” í›ˆë ¨í•˜ëŠ” ë™ì•ˆ ì‚¬ìš©í•œ ê²ƒë³´ë‹¤ ë” ì‘ì€ $\\epsilon$ì˜ ê²½ìš°, ì˜ˆìƒê³¼ ê°™ê±°ë‚˜ ë” ë†’ì€ ì •í™•ë„ë¥¼ ë‹¬ì„±í•˜ëŠ” ê²ƒì„ ê´€ì°°í–ˆë‹¤. MNISTì—ì„œ, í•™ìŠµëœ threshold ì—°ì‚°ìë“¤ì´ í›ˆë ¨ì— ì‚¬ìš©ëœ ì •í™•í•œ ê°’ì˜ $\\epsilon$ì— ë§ì¶”ì–´ì§ˆ ê°€ëŠ¥ì„± ë•Œë¬¸ì—, ë¯¸ì„¸í•˜ê²Œ í° $\\epsilon$ ê°’ë“¤ì—ì„œ robustnessì˜ í° í•˜ë½ì´ ìˆìŒì„ ì•Œ ìˆ˜ ìˆë‹¤. (Appendix C) ë°˜ë©´, CIFAR 10ì˜ ì‚¬ë¡€ì—ì„œì˜ ê°ì‡ ëŠ” ë³´ë‹¤ ë¶€ë“œëŸ¬ì› ë‹¤.MNISTì—ì„œì˜ $\\ell_2$-bounded attackì˜ ì‚¬ë¡€ì—ì„œ, PGDê°€ $\\epsilon=4.5$ì™€ ê°™ì´ ê½¤ í° $\\epsilon$ì—ë„ ë¶ˆêµ¬í•˜ê³ , ì ëŒ€ì  ì˜ˆì œë¥¼ ì°¾ì§€ ëª»í•œë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆë‹¤. ì´ $\\epsilon$ì˜ ê°’ì„ ê´€ì ì ìœ¼ë¡œ ë³´ê¸° ìœ„í•´, Appendix Dì˜ [ê·¸ë¦¼12]ì—ì„œ í•´ë‹¹í•˜ëŠ” ì ëŒ€ì  ì˜ˆì œì˜ ìƒ˜í”Œë“¤ì„ ì œê³µí•œë‹¤. ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ êµë€ë“¤ì´ ì´ë¯¸ì§€ì˜ ground-truth labelì„ ë°”ê¾¸ëŠ” ë° ì¶©ë¶„íˆ ìœ ì˜ë¯¸í•˜ë‹¤ëŠ” ê²ƒì„ ê´€ì°°í•˜ì˜€ê³ , ìš°ë¦¬ì˜ ëª¨ë¸ì´ ì‹¤ì œë¡œ ê·¸ë ‡ê²Œ robustí•  ê²ƒ ê°™ì§€ ì•Šì•˜ë‹¤. ì‹¤ì œë¡œ, í•˜ìœ„ ì—°êµ¬ [20, 25]ëŠ” PGDê°€ ì‚¬ì‹¤ ì´ ëª¨ë¸ì˜ $\\ell_2$ robustnessë¥¼ ê³¼ëŒ€í‰ê°€í•˜ê³  ìˆë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆë‹¤. ì´ëŸ¬í•œ í–‰ë™ì€ í•™ìŠµëœ threshold filter(Appendix C)ë“¤ì´ ê·¸ë ˆë””ì–¸íŠ¸ë¥¼ ê°€ë¦¬ëŠ” ê²ƒê³¼, PGDê°€ lossë¥¼ ìµœëŒ€í™”í•˜ëŠ” ê²ƒì— ëŒ€í•œ ë°©í•´ë¥¼ ìœ ë°œí•  ê°€ëŠ¥ì„±ì´ ìˆë‹¤. ëª¨ë¸ì˜ ê·¸ë ˆë””ì–¸íŠ¸ì— ì˜ì¡´í•˜ì§€ ì•Šê³  decision-based attackìœ¼ë¡œ ëª¨ë¸ì„ ê³µê²©í•˜ëŠ” ê²ƒì€ ëª¨ë¸ì´ $\\ell_2$-bounded attackì— ëŒ€í•´ ë³´ë‹¤ ë” í¬ê²Œ ì·¨ì•½í•˜ë‹¤ëŠ” ê²ƒì„ ë“œëŸ¬ë‚¸ë‹¤. ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³ , $\\ell_\\infty$ trained modelì€ ì—¬ì „íˆ ì¼ë°˜ì ì¸ ëª¨ë¸ì— ë¹„í•´ì„œ $\\ell_2$ê³µê²©ì— ëŒ€í•´ ì—¬ì „íˆ ë” robustí•˜ë‹¤.6 ê´€ë ¨ëœ ì—°êµ¬ë“¤ì ëŒ€ì  ì˜ˆì œë“¤ì— ëŒ€í•œ ì—°êµ¬ë“¤ì´ ë§ê¸° ë•Œë¬¸ì—, ê°€ì¥ ê´€ë ¨ì´ ìˆëŠ” ë…¼ë¬¸ë“¤ë§Œ ì •ë¦¬í•˜ì˜€ë‹¤. ìš°ë¦¬ì˜ ê¸°ì—¬ì™€ ë¹„êµí•˜ê¸° ì „ì—, robust optimizationì´ ìˆ˜ì‹­ë…„ë™ì•ˆ ë”¥ëŸ¬ë‹ì˜ ì£¼ì œ ë°–ì—ì„œ ì—°êµ¬ë˜ì—ˆìŒì„ ìƒê¸°í•˜ì. ë˜í•œ ì ëŒ€ì  ML ì—°êµ¬ê°€ ë”¥ëŸ¬ë‹ì˜ ê´‘ë²”ìœ„í•œ ì‚¬ìš©ë³´ë‹¤ ì•ì„  ê²ƒì„ì— ì£¼ì˜í•˜ë¼.(Ian J Goodfellow, Jonthan Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples (ICLR), 2015) ì—ì„œ ì ëŒ€ì  í›ˆë ¨ì´ ë„ì…ë˜ì—ˆì§€ë§Œ, adversaryì˜ í™œìš©ì€ í”í•˜ì§€ ì•Šì•˜ë‹¤. ì¦‰, ë°ì´í„° í¬ì¸íŠ¸ ì£¼ë³€ì˜ lossë¥¼ ì„ í˜•í™”í•˜ëŠ”ë° ì˜ì¡´í•˜ì˜€ë‹¤. ê²°ê³¼ì ìœ¼ë¡œ, ëª¨ë¸ì€ ë¶€ë¶„ì ì¸ adversaryì— ëŒ€í•´ì„œëŠ” robustí•˜ì˜€ì§€ë§Œ iterative ê³µê²©ì´ í™œìš©ëœ ì •êµí•œ adversaryë“¤ì—ê²ŒëŠ” ì™„ì „íˆ ì·¨ì•½í•˜ì˜€ë‹¤.ë˜í•œ ì ëŒ€ì  í›ˆë ¨ì— ëŒ€í•œ ImageNetì—ì„œì˜ ìµœê·¼ì˜ ì—°êµ¬(Alexey Kurakin, Ian J. Goodfellow, and Samy Bengio. Adversarial machine learning at scale (ICLR), 2017)ëŠ” model capacityê°€ ì ëŒ€ì  í›ˆë ¨ì— ìˆì–´ì„œ ì¤‘ìš”í•˜ë‹¤ëŠ” ê²ƒì„ ë°í˜€ëƒˆë‹¤. ì´ ë…¼ë¬¸ê³¼ ë¹„êµí•˜ë©´, ìš°ë¦¬ëŠ” multi-step ë°©ë²• (PGD)ìœ¼ë¡œ í›ˆë ¨í•˜ëŠ” ê²ƒì´ ì´ëŸ¬í•œ adversaryë“¤ì— ëŒ€í•œ ì €í•­ì„ ì´ëŒì–´ ë‚¼ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ë°í˜€ëƒˆë‹¤.ë˜í•œ, (Ruitong Huang, Bing Xu, Dale Schuurmans, and Csaba Szepesvari. Learning with a strong adversary. arXiv preprint arXiv:1511.03034, 2015.)ì™€ (Uri Shaham, Yutaro Yamada, and Sahand Negahban. Understanding adversarial training: Increasing local stability of supervised models through robust optimization. Neurocomputing, 307:195â€“204, 2018.)ì—ì„œ min-max optimization ë¬¸ì œì˜ ë²„ì „ì´ ì ëŒ€ì  í›ˆë ¨ì—ì„œ ê³ ë ¤ë˜ì—ˆë‹¤. ê·¸ëŸ¬ë‚˜, ì•ì„œ ì´ ë…¼ë¬¸ë“¤ì—ì„œ ì–¸ê¸‰ëœ ê²°ê³¼ì™€ ë³¸ ë…¼ë¬¸ ì‚¬ì´ì—ëŠ” ì„¸ê°€ì§€ ì¤‘ìš”í•œ ì°¨ì´ì ì´ ì¡´ì¬í•œë‹¤. ì²«ì§¸, ì €ìë“¤ì€ inner maximization problemì´ í•´ê²°í•˜ê¸° ì–´ë µë‹¤ê³  ì£¼ì¥í•œ ë°˜ë©´, ìš°ë¦¬ëŠ” ë”ìš± ìì„¸í•˜ê²Œ loss surfaceë¥¼ ì¡°ì‚¬í•˜ì˜€ê³  randomly re-started projected gradien descentê°€ ëŒ€ì¡°ì ì¸ í€„ë¦¬í‹°ë¡œ ì¢…ì¢… ì†”ë£¨ì…˜ì— ìˆ˜ë ´í•œë‹¤ëŠ” ê²ƒì„ ë°œê²¬í•˜ì˜€ë‹¤. ì´ëŠ” inner maximiztion problemì—ì„œ ì¶©ë¶„íˆ ì¢‹ì€ ì†”ë£¨ì…˜ì„ ì–»ëŠ” ê²ƒì´ ê°€ëŠ¥í•˜ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ì—ˆìœ¼ë©°, ì‹¬ì¸µ ì‹ ê²½ë§ì´ ì ëŒ€ì  ì˜ˆì œì— ëŒ€í•œ ë‚´ì„±ì„ ê°€ì§ˆ ìˆ˜ ìˆë‹¤ëŠ” ì¦ê±°ë¡œ ì œì‹œëœë‹¤. ë‘˜ì§¸, ì´ë“¤ì€ one-step adversaryë§Œì„ ê³ ë ¤í•˜ì˜€ì§€ë§Œ, ìš°ë¦¬ëŠ” multi-step methodë¥¼ ì‚¬ìš©í•˜ì—¬ ì—°êµ¬í•˜ì˜€ë‹¤. ì¶”ê°€ì ìœ¼ë¡œ, Uri Shaham ì™¸ ì—°êµ¬ì§„ë“¤ì˜ ë…¼ë¬¸ì—ì„œì˜ ì‹¤í—˜ì€ ìœ ë§í•œ ê²°ê³¼ë¥¼ ë§Œë“¤ì–´ëƒˆì§€ë§Œ ì˜¤ì§ FGSMì— ëŒ€í•´ì„œë§Œ ê²€ì¦í•˜ì˜€ë‹¤. ê·¸ëŸ¬ë‚˜, FGSMë§Œì„ ì´ìš©í•œ ê²€ì¦ì€ ì™„ì „íˆ ì‹ ë¢°í•  ìˆ˜ ì—†ë‹¤. ìµì„œì— ëŒ€í•œ ì¦ê±° ì¤‘ í•˜ë‚˜ë¡œëŠ” Uri Sahamì™¸ ì—°êµ¬ì§„ë“¤ì˜ ë¶„ë¥˜ê¸°ëŠ” $\\epsilon=0.7$ì¼ ë•Œ 70%ì˜ ì •í™•ë„ë¥¼ ì‚°ì¶œí•˜ì˜€ì§€ë§Œ, ê° í”½ì…€ì„ $0.5$ì´ìƒ êµë€í•  ìˆ˜ ìˆëŠ” ìƒëŒ€ë¼ë©´ ê· ì¼í•˜ê²Œ íšŒìƒ‰ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ ìˆ˜ ìˆê³ , ë”°ë¼ì„œ ì´ ë¶„ë¥˜ê¸°ë¥¼ ì†ì¼ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤.ë˜í•œ (Florian Tramer, Nicolas Papernot, Ian Goodfellow, and Patrick McDaniel Dan Boneh. The space of transferable adversarial examples. In ArXiv preprint arXiv:1704.03453, 2017.)ì™€ ê°™ì€ ë”ìš± ìµœê·¼ì˜ ì—°êµ¬ì—ì„œëŠ” transferability í˜„ìƒì„ ì¡°ì‚¬í•˜ì˜€ë‹¤. ì´ ì—°êµ¬ëŠ” ì†ì‹¤ì´ ì„ í˜•(ì— ê°€ê¹Œìš´) ìì—°ì ì¸ ì˜ˆì œë“¤ì˜ ì£¼ë³€ ì§€ì—­ì— ì§‘ì¤‘ë˜ì–´ ì§„í–‰ë˜ì—ˆë‹¤. í° êµë€ì´ ìˆì„ ë•Œ, ì´ ì§€ì—­ì€ adversarial landscapeì˜ ì™„ì „í•œ pictureë¥¼ ì£¼ì§€ ì•ŠëŠ”ë‹¤. ì´ê²ƒì€ ìš°ë¦¬ì˜ ì‹¤í—˜ì— ì˜í•´ í™•ì¸ë  ë¿ë§Œ ì•„ë‹ˆë¼ Florian Tramerì™¸ ì—°êµ¬ì§„ë“¤ì— ì˜í•´ì„œë„ ì§€ì ë˜ì—ˆë‹¤.7 ê²°ë¡ ìš°ë¦¬ì˜ ë°œê²¬ì€ ì‹¬ì¸µì‹ ê²½ë§ì´ ì ëŒ€ì  ê³µê²©ì— ë‚´ì„±ì„ ê°€ì§ˆ ìˆ˜ ìˆë‹¤ëŠ” ì¦ê±°ë¥¼ ì œì‹œí•œë‹¤. ìš°ë¦¬ì˜ ì´ë¡ ê³¼ ì‹¤í—˜ì´ ê°€ë¦¬í‚¤ë“¯ì´, ìš°ë¦¬ëŠ” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì ëŒ€ì  í›ˆë ¨ ë°©ë²•ì„ ì„¤ê³„í•  ìˆ˜ ìˆë‹¤. ì´ê²ƒì˜ ë’¤ì— ìˆëŠ” ì¤‘ìš”í•œ í†µì°°ì¤‘ í•˜ë‚˜ëŠ”, ê¸°ë³¸ì ì¸ ìµœì í™”ì˜ ì˜ˆìƒ ì™¸ì˜ ê·œì¹™ì ì¸ êµ¬ì¡°ì˜€ë‹¤. ê´€ë ¨ëœ ë¬¸ì œëŠ” ë§ì€ ëšœë ·í•œ êµ­ì†Œ ìµœëŒ“ê°’ì„ ê°–ëŠ” ê³ ë„ë¡œ non-concave í•¨ìˆ˜ì˜ ìµœëŒ€í™”ì— í•´ë‹¹í•˜ì§€ë§Œ, ê·¸ ê°’ë“¤ì€ ë§¤ìš° ì§‘ì¤‘ë˜ì–´ ìˆë‹¤. ì¢…í•©í•˜ìë©´, ìš°ë¦¬ì˜ ë°œê²¬ì€ adversarially robustí•œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ í˜„ì¬ ë„ë‹¬ ë²”ìœ„ ë‚´ì— ìˆì„ ìˆ˜ ìˆë‹¤ëŠ” í¬ë§ì„ ì¤€ë‹¤.MNIST ë°ì´í„°ì…‹ì—ì„œ, ìš°ë¦¬ì˜ networkëŠ” ë§¤ìš° robustí•˜ì˜€ê³ , ê´‘ë²”ìœ„í•˜ê³  ê°•ë ¥í•œ $l_\\infty$ bound adversariesì™€ í° perturbationì— ëŒ€í•´ì„œ ë†’ì€ ì •í™•ë„ë¥¼ ë‹¬ì„±í–ˆë‹¤. CIFAR10 ë°ì´í„°ì…‹ì—ì„œì˜ ì‹¤í—˜ì€ ì•„ì§ ì´ëŸ¬í•œ ìˆ˜ì¤€ê¹Œì§€ ë„ë‹¬í•˜ì§€ ëª»í•˜ì˜€ë‹¤. ê·¸ëŸ¬ë‚˜, ìš°ë¦¬ì˜ ê²°ê³¼ëŠ” ìš°ë¦¬ì˜ ê¸°ìˆ ì´ networkì˜ robustnessì˜ ì¤‘ìš”í•œ í–¥ìƒì„ ì´ëŒì–´ ë‚¸ë‹¤ëŠ” ê²ƒì„ ì´ë¯¸ ë³´ì—¬ì£¼ì—ˆë‹¤. ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ ë°©í–¥ì˜ ë” ë§ì€ íƒêµ¬ê°€ ì´ ë°ì´í„°ì…‹ì˜ adversarially robust networkë¥¼ ì´ëŒì–´ ë‚¼ ìˆ˜ ìˆìœ¼ë¦¬ë¼ê³  ë¯¿ëŠ”ë‹¤." }, { "title": "ì ëŒ€ì  ì˜ˆì œì˜ ì„¤ëª…ê³¼ í™œìš© (Fast Gradient Sign Method, FGSM) - Ian J.Goodfellow, Jonathan Shelens & Christian Szegedy", "url": "/posts/fgsm/", "categories": "ADVERSARIAL TRAINING, FGSM", "tags": "adversarial example", "date": "2022-07-28 15:00:00 +0900", "snippet": "ì˜ì—­ 99%, ì§€ì  íƒœí´ í™˜ì˜ì›ë¬¸: Explaining and harnessing adversarial exampleì´ˆë¡ì‹ ê²½ë§ì„ í¬í•¨í•œ ì¼ë¶€ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë“¤ì€ ì ëŒ€ì  ì˜ˆì œë“¤ì„ ì¼ê´€ì ìœ¼ë¡œ ì˜¤ë¶„ë¥˜í•œë‹¤. ì ëŒ€ì  ì˜ˆì œë€, ë°ì´í„°ì…‹ì—ì„œ ë¯¸ì„¸í•˜ì§€ë§Œ ì˜ë„ì ìœ¼ë¡œ worst-case ë°©í–¥ìœ¼ë¡œ êµë€(perturbation, ì´í•˜ êµë€)ì„ ì£¼ì–´ì„œ ë§Œë“  ì…ë ¥ê°’ë¥¼ ë§í•œë‹¤. ì´ë ‡ê²Œ í•¨ìœ¼ë¡œì¨ ëª¨ë¸ì€ ë†’ì€ ì‹ ë¢°ë„(confidence, ë™ì¼í•œ ì¸¡ì •ëŒ€ìƒì„ ì¸¡ì •í•˜ì˜€ì„ ë•Œ ì¼ê´€ì„± ìˆëŠ” ì¸¡ì • ê²°ê³¼ë¥¼ ì‚°ì¶œí•˜ëŠ” ì •ë„)ë¡œ ì˜ëª»ëœ ë‹µì„ ë‚´ë†“ê²Œ ëœë‹¤. ì´ëŸ¬í•œ ì·¨ì•½ì ì€ ì›ë˜ ë¹„ì„ í˜•ì„±ê³¼ ê³¼ì í•©ì— ì§‘ì¤‘ë˜ì–´ ì„¤ëª…ë˜ê³  ìˆì—ˆëŠ”ë°, ìš°ë¦¬ëŠ” ì´ì™€ ë‹¤ë¥´ê²Œ ì„ í˜•ì„±ì— ìˆë‹¤ê³  ì£¼ì¥í•  ê²ƒì´ë‹¤. ì´ëŠ” ìƒˆë¡œìš´ ìˆ˜ì¹˜ì ì¸ ê·¼ê±°ë¡œ ë’·ë°›ì¹¨ë˜ë©°, ìµœì´ˆë¡œ ëª¨ë¸ì˜ ì•„í‚¤í…ì²˜ì™€ í›ˆë ¨ ë°ì´í„°ì…‹ì„ ì•„ìš°ë¥´ëŠ” ì¼ë°˜í™”(generalization)ì— ëŒ€í•œ í¥ë¯¸ë¡œìš´ ì„¤ëª…ì„ ì œì‹œí•  ê²ƒì´ë‹¤. ë˜í•œ ì´ëŸ¬í•œ ê´€ì ì—ì„œ ì ëŒ€ì  ì˜ˆì œë¥¼ ìƒì„±í•˜ëŠ” ê°„ë‹¨í•˜ê³  ë¹ ë¥¸ ë°©ë²•ì„ ì œì‹œí•  ê²ƒì´ë‹¤. ì´ëŸ¬í•œ ë°©ë²•ì„ ì´ìš©í•œ ì˜ˆì œë“¤ì„ ì ëŒ€ì  í›ˆë ¨ì— ì´ìš©í•œ ê²°ê³¼, MNIST ë°ì´í„°ì…‹ì—ì„œì˜ maxout networkì˜ í…ŒìŠ¤íŠ¸ì…‹ì—ì„œì˜ ì—ëŸ¬ë¥¼ ì¤„ì¼ ìˆ˜ ìˆì—ˆë‹¤.ê°œìš”Szegedy et al,. (2014b)ëŠ” SOA(State-Of-Art, í˜„ì¡´ ìµœê³  ì„±ëŠ¥) ì‹ ê²½ë§ì„ í¬í•¨í•œ ì¼ë¶€ ë¨¸ì‹  ëŸ¬ë‹ ëª¨ë¸ë“¤ì´ ì ëŒ€ì  ì˜ˆì œì— ì·¨ì•½í•˜ë‹¤ëŠ” ì ì„ ë°œê²¬í–ˆë‹¤. ì¦‰ ì´ëŸ¬í•œ ë¨¸ì‹  ëŸ¬ë‹ ëª¨ë¸ë“¤ì€ ì˜¬ë°”ë¥´ê²Œ ë¶„ë¥˜ëœ ì˜ˆì‹œì— ë¯¸ì„¸í•œ ë³€ê²½ë§Œì„ ê°€í•´ë„ ì´ê²ƒì„ ì˜ëª» ë¶„ë¥˜í•œë‹¤ëŠ” ê²ƒì´ë‹¤. ì„œë¡œ ë‹¤ë¥¸ ì•„í‚¤í…ì³ë¥¼ ê°€ì§„ ë‹¤ì–‘í•œ ëª¨ë¸ ëŒ€ë¶€ë¶„ì´ ë™ì¼í•œ ì ëŒ€ì  ì˜ˆì œë¥¼ ì˜¤ë¶„ë¥˜í–ˆë‹¤. ì´ëŠ” ì ëŒ€ì  ì˜ˆì œê°€ í˜„ì¡´ í›ˆë ¨ ì•Œê³ ë¦¬ì¦˜ì´ ê·¼ë³¸ì ì¸ ë§¹ì (blind spot)ì„ ê°€ì§€ê³  ìˆë‹¤ëŠ” ê²ƒì„ ì•Œë ¤ì¤€ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤.ì§€ê¸ˆê¹Œì§€ ìœ„ í˜„ìƒì˜ ì›ì¸ì€ ë¯¸ìŠ¤í…Œë¦¬ì˜€ë‹¤. ì‹ ê²½ë§ì˜ ê³¼ë„í•œ ë¹„ì„ í˜•ì„±ì´ ì›ì¸ìœ¼ë¡œ ì œì‹œ ë˜ì—ˆìœ¼ë©°, ìˆœìˆ˜í•œ ì§€ë„ í•™ìŠµ ë¬¸ì œì˜ ë¶ˆì¶©ë¶„í•œ model averagingê³¼ ë¶ˆì¶©ë¶„í•œ ì •ê·œí™”, ê·¸ë¦¬ê³  ì‹ ê²½ë§ì˜ ê³¼ë„í•œ ë¹„ì„ í˜•ì„±ì´ ì›ì¸ìœ¼ë¡œ ì¶”ì¸¡ë˜ê³  ìˆì—ˆë‹¤. ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ ê°€ì„¤ì´ í•„ìš”ì—†ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤„ ê²ƒì´ë‹¤. ê³ ì°¨ì› ê³µê°„ì—ì„œì˜ ì„ í˜• í–‰ë™ì€ ìœ„ í˜„ìƒì˜ ì›ì¸ì´ ë˜ê¸°ì— ì¶©ë¶„í•˜ë‹¤. ì´ ê´€ì ì„ í†µí•´ ì ëŒ€ì  í›ˆë ¨ì„ ì‹¤ìš©í™” í•  ìˆ˜ ìˆë„ë¡ ì ëŒ€ì  ì‚¬ë¡€ë¥¼ ìƒì„±í•˜ëŠ” ë¹ ë¥¸ ë°©ë²•ì„ ì„¤ê³„í•  ìˆ˜ ìˆë‹¤. ìš°ë¦¬ëŠ” ì ëŒ€ì  í›ˆë ¨ì´ ë“œë¡­ì•„ì›ƒ(Srivastava et al., 2014)ì„ ë‹¨ë…ìœ¼ë¡œ ì‚¬ìš©í•¨ìœ¼ë¡œì¨ ì œê³µë˜ëŠ” ê²ƒë³´ë‹¤ ë” ë§ì€ ì •ê·œí™” ì´ì ì„ ì œê³µí•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤€ë‹¤. ë“œë¡­ì•„ì›ƒ, ì‚¬ì „í•™ìŠµ, model averagingê³¼ ê°™ì€ ì¼ë°˜ì ì¸ ì •ê·œí™” ì „ëµë“¤ì€ ì ëŒ€ì  ì‚¬ë¡€ì— ëŒ€í•œ ëª¨ë¸ì˜ ì·¨ì•½ì ì„ í¬ê²Œ ì—†ì• ì£¼ì§€ ì•ŠëŠ”ë‹¤. ê·¸ëŸ¬ë‚˜ RBF networkì™€ ê°™ì€ ë¹„ì„ í˜• ëª¨ë¸ë¥˜ë¡œ ë°”ê¾¸ëŠ” ê²ƒì€ ê·¸ë ‡ê²Œ í•  ìˆ˜ ìˆë‹¤.ìš°ë¦¬ì˜ ì„¤ëª…ì€ ì„ í˜•ì„±ìœ¼ë¡œ ì¸í•œ ëª¨ë¸ í›ˆë ¨ì˜ ìš©ì´ì„±ê³¼ ë¹„ì„ í˜•ì„±ìœ¼ë¡œ ì¸í•œ ì ëŒ€ì  ì˜ˆì œì— ëŒ€í•œ ëª¨ë¸ì˜ ë‚´ì„± ì‚¬ì´ì˜ ê·¼ë³¸ì ì¸ ê· í˜•ì„ ì œì•ˆí•œë‹¤. ì¥ê¸°ì ìœ¼ë¡œ ë” ë§ì€ ë¹„ì„ í˜• ëª¨ë¸ì„ ì„±ê³µì ìœ¼ë¡œ í›ˆë ¨ì‹œí‚¬ ìˆ˜ ìˆëŠ” ë” ê°•ë ¥í•œ ìµœì í™” ë°©ë²•ì„ ì„¤ê³„í•¨ìœ¼ë¡œì¨ ì´ëŸ¬í•œ trade-offë¥¼ í”¼í•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•˜ë‹¤ê³  ë³´ê³  ìˆë‹¤.2 ê´€ë ¨ëœ ì—°êµ¬Szegedy et al,. (2014b)ëŠ” ì‹ ê²½ë§ê³¼ ê´€ë ¨ëœ ëª¨ë¸ë“¤ì˜ ë‹¤ì–‘í•˜ê³  ë†€ë¼ìš´ íŠ¹ì§•ì„ ë°œê²¬í–ˆë‹¤. ì•„ë˜ëŠ” ë³¸ë¬¸ê³¼ ê°€ì¥ ì—°ê´€ëœ ì—°êµ¬ë“¤ì´ë‹¤. Box-constrained L-BFGS can reliably find adversarial examples. On some datasets, such as ImageNet (Deng et al., 2009), the adversarial examples were so close to the original examples that the differences were indistinguishable to the human eye. The same adversarial example is often misclassified by a variety of classifiers with different architectures or trained on different subsets of the training data. Shallow softmax regression models are also vulnerable to adversarial examples. Training on adversarial examples can regularize the modelâ€”however, this was not practical at the time due to the need for expensive constrained optimization in the inner loop.ì´ëŸ¬í•œ ê²°ê³¼ëŠ” í˜„ëŒ€ ê¸°ê³„ í•™ìŠµ ê¸°ìˆ ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ë¶„ë¥˜ê¸°ê°€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ì–»ëŠ” ë¶„ë¥˜ê¸°ì¼ì§€ë¼ë„ ì˜¬ë°”ë¥¸ ì¶œë ¥ ë ˆì´ë¸”ì„ ê²°ì •í•˜ëŠ” ì§„ì •í•œ ê¸°ë³¸ ê°œë…ì„ í•™ìŠµí•˜ì§€ ëª»í•˜ê³  ìˆìŒì„ ì‹œì‚¬í•œë‹¤. ì´ë“¤ ì•Œê³ ë¦¬ì¦˜ì€ ìì—°ì ìœ¼ë¡œ ë°œìƒí•˜ëŠ” ë°ì´í„°ì—ëŠ” ì˜ ì‘ë™í•˜ì§€ë§Œ, ë°ì´í„° ë¶„í¬ì—ì„œ ê±°ì˜ ë°œìƒí•˜ì§€ ì•ŠëŠ” ì…ë ¥ì„ ì£¼ë©´ ê°€ì§œì¸ ê²ƒì´ ë“¤í†µë‚˜ëŠ” í¬í…œí‚¨ ë§ˆì„ì„ êµ¬ì¶•í–ˆë‹¤. ì´ê²ƒì€ ì¡°ê¸ˆ ì‹¤ë§ìŠ¤ëŸ¬ìš´ë°, ì™œëƒí•˜ë©´ computer visionì—ì„œ ì¸ê¸°ìˆëŠ” ì ‘ê·¼ì€ í•©ì„±ê³± ì‹ ê²½ë§ featureë¥¼ ì§€ê° ê±°ë¦¬ì—ì„œ ìœ í´ë¦¬ë“œ ê±°ë¦¬ë¡œ ê·¼ì‚¬í•˜ëŠ” ê³µê°„ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ”ê²ƒì´ê¸° ë•Œë¬¸ì´ë‹¤. ì¸¡ì •í•  ìˆ˜ ì—†ì„ ì •ë„ë¡œ ì‘ì€ ì§€ê° ê±°ë¦¬ë¥¼ ê°€ì§„ ì´ë¯¸ì§€ê°€ ë„¤íŠ¸ì›Œí¬ í‘œí˜„ì—ì„œ ì™„ì „íˆ ë‹¤ë¥¸ í´ë˜ìŠ¤ì— í•´ë‹¹í•œë‹¤ë©´ ì´ëŸ¬í•œ ìœ ì‚¬ì„±ì€ ë¶„ëª…íˆ ê²°í•¨ì´ ìˆë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤.ìœ„ ê²°ê³¼ëŠ” ì„ í˜• ë¶„ë¥˜ê¸°ê°€ ë™ì¼í•œ ë¬¸ì œë¥¼ ê°€ì§€ê³  ìˆìŒì—ë„ íŠ¹íˆ ì‹¬ì¸µ ì‹ ê²½ë§ì˜ ë‹¨ì ìœ¼ë¡œ í•´ì„ë˜ì–´ì™”ë‹¤. ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ ê²°í•¨ì„ ê·¸ê²ƒì„ í•´ê²°í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒ ì‹œí‚¬ ê¸°íšŒë¡œ ì—¬ê¸°ê³  ìˆë‹¤. ì‹¤ì œë¡œ í´-ë¦°í•œ ì…ë ¥ì— ëŒ€í•´ ìµœì‹  ì •í™•ë„ë¥¼ ìœ ì§€í•˜ë©´ì„œ ì„±ê³µì ìœ¼ë¡œ ìˆ˜í–‰ëœ ëª¨ë¸ì€ ì•„ì§ ì—†ì§€ë§Œ, Gu &amp; Rigazio(2014)ì™€ Chalupka ë“±(2014)ì€ ì ëŒ€ì  êµë€ì— ì €í•­í•˜ëŠ” ëª¨ë¸ì„ ì„¤ê³„í•˜ê¸° ìœ„í•œ ì²« ë‹¨ê³„ë¥¼ ì´ë¯¸ ì‹œì‘í–ˆë‹¤.ì ëŒ€ì  ì˜ˆì œì™€ ì„ í˜•ì„±ì— ëŒ€í•œ ì„¤ëª…ì„ í˜• ëª¨ë¸ì—ì„œì˜ ì ëŒ€ì  ì˜ˆì œì˜ ì¡´ì¬ë¶€í„° ì„¤ëª…í•˜ê² ë‹¤.ë§ì€ ë¬¸ì œì—ì„œ, ê°œë³„ ì…ë ¥ featureì˜ ì •ë°€ë„ëŠ” ìœ í•œí•˜ë‹¤. ì—ë¥¼ ë“¤ì–´ ë””ì§€í„¸ ì´ë¯¸ì§€ëŠ” í”½ì…€ ë‹¹ 8ë¹„íŠ¸ì„ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì—, 1/255ì´í•˜ í¬ê¸°ì¸ ëª¨ë“  ì •ë³´ë¥¼ ë²„ë¦°ë‹¤. ì´ì™€ ê°™ì´ featureë“¤ì˜ ì •ë°€ë„ëŠ” ìœ í•œí•˜ë©°, êµë€ëœ ì…ë ¥ê³¼ ì›ë˜ ì…ë ¥ì˜ ì°¨ì´ê°€ ì •ë°€ë„ ì´í•˜ë¼ë©´, ë¶„ë¥˜ê¸°ê°€ ì…ë ¥ $x$ì™€ êµë€ëœ ì ëŒ€ì  ì˜ˆì œ$\\tilde{x}=x+\\eta$ë¥¼ ë‹¤ë¥¸ í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜í•˜ëŠ”ê²ƒì€ íƒ€ë‹¹í•˜ì§€ ì•Šë‹¤. ìˆ˜ì‹ì ìœ¼ë¡œ, ê· ì¼í•˜ê²Œ ë¶„í¬ëœ í´ë˜ìŠ¤ë¥¼ ë¶„ë¥˜í•˜ëŠ” ë¬¸ì œì—ì„œ $||\\eta||_\\infty&lt;\\epsilon$ ì¼ ë•Œ, ë¶„ë¥˜ê¸°ëŠ” $x$ì™€ $\\tilde{x}$ë¥¼ ê°™ì€ í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜í•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ëœë‹¤. ì´ ë•Œ $\\epsilon$ì€ ì €ì¥ ì¥ì¹˜ë‚˜ ì„¼ì„œì—ê²Œ ë¬´ì‹œë  ìˆ˜ ìˆì„ ì •ë„ë¡œ ì¶©ë¶„íˆ ì‘ì€ ê°’ì´ë‹¤.ì´ì œ ê°€ì¤‘ì¹˜ ë²¡í„° $w$ì™€ ì ëŒ€ì  ì˜ˆì œ $\\tilde{x}$ ì‚¬ì´ì˜ ë‚´ì ì„ ê³ ë ¤í•˜ì.\\[w\\cdot \\tilde{x}=w\\cdot x+w\\cdot \\eta\\]ì ëŒ€ì  êµë€ì€ í™œì„±í™” ê°’ì„ $w\\cdot \\eta$ ë§Œí¼ ì¦ê°€ ì‹œí‚¨ë‹¤.$\\eta=sign(w)$ë¡œ ì„¤ì •í•¨ìœ¼ë¡œì¨ $\\eta$ì— max norm constraint($sign((1, -2, 3))=(1, -1, 1),$ ì´ì™€ ê°™ì´ ë²¡í„°ì˜ ê° ì›ì†Œì˜ í¬ê¸°ê°€ 1ë¡œ ë³€ê²½ ë˜ì–´ ìµœì¢… norm í¬ê¸°ê°€ ì œí•œëœë‹¤)ì„ ê°€í•˜ì—¬, ì´ ì¦ê°€ë¥¼ ìµœëŒ€í™” í•  ìˆ˜ ìˆë‹¤. $w$ ê°€ $n$ ì°¨ì›ì´ê³  ê°€ì¤‘ì¹˜ ë²¡í„°ì˜ ê° ìš”ì†Œì˜ í‰ê·  í¬ê¸°ê°€ $m$ ì¼ ë•Œ, í™œì„±í™” ê°’ì€ $mn$ë§Œí¼ ì¦ê°€í•œë‹¤.$||\\eta||_\\infty$ ëŠ” ë¬¸ì œì˜ ì°¨ì›ì— ë”°ë¼ ì¦ê°€í•˜ì§€ ì•Šì§€ë§Œ, $\\eta$ ì— ì˜í•œ êµë€ìœ¼ë¡œ ì¸í•œ í™œì„±í™” ê°’ì€ $n$ ì— ë”°ë¼ ì¦ê°€ í•  ìˆ˜ ìˆê³ , ê³ ì°¨ì› ë¬¸ì œë¼ë©´ ì…ë ¥ê°’ì— ìˆ˜ë§ì€ ë¬´í•œì†Œ ë³€ê²½ì„ ê°€í•˜ì—¬ ì¶œë ¥ê°’ì— í° ë³€í™”ë¥¼ ì¤„ ìˆ˜ ìˆë‹¤. ì„ í˜• ëª¨ë¸ì€ ì—¬ëŸ¬ ì‹ í˜¸ê°€ ì¡´ì¬í•˜ê³ , ë‹¤ë¥¸ ì‹ í˜¸ë“¤ì´ ë‹¤ë¥¸ ì‹ í˜¸ë“¤ì´ ë”ìš± í° ì§„í­ì„ ê°€ì¡Œë”ë¼ë„, ëª¨ë“  ê°€ì¤‘ì¹˜ë“¤ì— ê°€ì¥ ê°€ê¹Œìš´ ì‹ í˜¸ìª½ìœ¼ë¡œ ì •ë ¬ë˜ë„ë¡ ê°•ì œëœë‹¤. ì´ê²ƒì„ â€œìš°ë°œì  ìŠ¤í…Œê°€ë…¸ê·¸ë˜í”¼ (accidental steganography)â€ë¼ê³  ìƒê°í•  ìˆ˜ ìˆë‹¤.ìœ„ ì„¤ëª…ì€ ë‹¨ìˆœ ì„ í˜• ëª¨ë¸ì—ì„œ ì…ë ¥ê°’ì´ ê³ ì°¨ì›ì¼ ê²½ìš° ì ëŒ€ì  ì˜ˆì œë¥¼ ê°€ì§ˆ ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤€ë‹¤. ì ëŒ€ì  ì˜ˆì œì— ëŒ€í•œ ê¸°ì¡´ì˜ ì„¤ëª…ë“¤ì€ ì‹ ê²½ë§ì˜ ê³ ë„ì˜ ë¹„ì„ í˜•ì„±ë“± ê³¼ ê°™ì€ ê°€ì •ëœ íŠ¹ì§•ì„ ì‚¬ìš©í•˜ì˜€ë‹¤. ê·¸ëŸ¬ë‚˜ ì„ í˜•ì„±ì— ê¸°ë°˜í•œ ê°€ì„¤ì€ ì´ë³´ë‹¤ ë” ê°„ë‹¨í•˜ë©°, softmax regression ì´ ì™œ ì ëŒ€ì  ì˜ˆì œì— ì·¨ì•½í•œì§€ì— ëŒ€í•´ì„œë„ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤. Softmax regression, $x$ê°€ $768 \\times 1$ ì´ë¼ë©´ êµë€ë¬ì„ ë•Œ ì¶œë ¥ì˜ ë³€ê²½ì´ ìœ ì˜ë¯¸í•´ì§ˆ ìˆ˜ ìˆë‹¤.4 ë¹„ì„ í˜• ëª¨ë¸ë“¤ì˜ ì„ í˜• êµë€ì ëŒ€ì  ì˜ˆì œê°€ ì„ í˜•ì„± ë•Œë¬¸ì´ë¼ëŠ” ê´€ì ì€ ì´ê²ƒì„ ë¹ ë¥´ê²Œ ìƒì„±í•˜ëŠ” ë°©ë²•ì„ ì œê³µí•œë‹¤. ìš°ë¦¬ëŠ” ì‹ ê²½ë§ì´ ì ëŒ€ì  ì˜ˆì œì— ì €í•­í•˜ê¸°ì—ëŠ” ë„ˆë¬´ ì„ í˜•ì ì´ë¼ëŠ” ê°€ì„¤ì„ ì„¸ì› ë‹¤. LSTM, ReLUs, ê·¸ë¦¬ê³  maxout networkëŠ” ëª¨ë‘ ìµœì í™”í•˜ê¸°ì— ìš©ì´í•˜ë„ë¡, ì˜ë„ì ì—ê²Œ ì„ í˜•ì ìœ¼ë¡œ ì„¤ê³„ë˜ì—ˆë‹¤. sigmoid networkì™€ ê°™ì€ ëª¨ë¸ë“¤ì€ ìœ„ì™€ ê°™ì€ ì´ìœ ë¡œ ê·¸ë“¤ì˜ ì‹œê°„ì„ ê±°ì˜ non-saturatingí•˜ê±°ë‚˜ ì„ í˜•í™”í•˜ëŠ”ë° ì“°ë„ë¡ ì„¸ì‹¬íˆ íŠœë‹ë˜ì—ˆë‹¤. ì´ëŸ¬í•œ ì„ í˜•ì„±ì€ ëª¨ë¸ì„ ì‰½ê³ , ë¶„ì„ì ì¸ êµë€ìœ¼ë¡œ ì†ìƒ ì‹œí‚¬ ìˆ˜ ìˆê²Œí•œë‹¤. [ê·¸ë¦¼1] ë¹ ë¥¸ ì ëŒ€ì  ì˜ˆì œ ìƒì„±ì´ ImageNetì˜ GoogLeNetì— ì ìš©ëœ ëª¨ìŠµì´ë‹¤. ë¬´ì‹œí•  ìˆ˜ ìˆì„ ë§Œí¼ ì‘ì€ ë²¡í„°ë¥¼ cost functionì˜ ê¸°ìš¸ê¸°ì™€ ë¶€í˜¸ë¥¼ ë™ì¼í•˜ê²Œ í•˜ì—¬ ë”í•¨ìœ¼ë¡œì¨, GoogLeNetì˜ ì´ë¯¸ì§€ ë¶„ë¥˜ ê²°ê³¼ë¥¼ ë°”ê¿€ ìˆ˜ ìˆë‹¤. ì´ ë–„ GoogLeNetì˜ ì‹¤ìˆ˜ ë³€í™˜ í›„ 8ë¹„íŠ¸ ì´ë¯¸ì§€ ì¸ì½”ë”©ì—ì„œ ê°€ì¥ ì‘ì€ ë¹„íŠ¸ì˜ í¬ê¸°(ì •ë°€ë„)ëŠ” $\\epsilon=0.007$ì¼ ë•Œì´ë‹¤.ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ë¥¼ $\\theta,$ ì…ë ¥ì„ $x$, $x$ì— ë”°ë¥¸ ì •ë‹µ ë ˆì´ë¸”ì„ $y$ë¼ê³  í•˜ê³  ì‹ ê²½ë§ì˜ í›ˆë ¨ì— ì‚¬ìš©í•˜ëŠ” cost functionì„ $J(\\theta, x, y)$ë¼ê³  í•˜ì. $\\theta$ì˜ í˜„ì¬ ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ë¹„ìš©í•¨ìˆ˜ë¥¼ ì„ í˜•í™” í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤. ë˜í•œ ì´ë•Œ ë‹¤ìŒê³¼ ê°™ì€ ìµœì ì˜ max-norm-contraintëœ êµë€ê°’ $\\eta$ì„ ì–»ì„ ìˆ˜ ìˆë‹¤.\\[\\eta=\\epsilon sign(\\nabla_xJ(\\theta, x, y))\\]ì´ê²ƒì„ ì ëŒ€ì  ì˜ˆì œ ìƒì„±ì˜ â€œë¹ ë¥¸ ê·¸ë ˆë””ì–¸íŠ¸ ë¶€í˜¸ ë°©ë²•(fast gradient($:=\\nabla_x$) sign($:= sign()$) method, FGSM)â€ì´ë¼ê³  ì¹­í•œë‹¤. ì´ë•Œ ì—­ì „íŒŒë¥¼ ì‚¬ìš©í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ ê·¸ë ˆë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤.ìš°ë¦¬ëŠ” ì´ ë°©ë²•ì´ ë‹¤ì–‘í•œ ëª¨ë¸ë“¤ì˜ ì˜¤ë¶„ë¥˜ë¥¼ ìœ ë°œí•œë‹¤ëŠ” ê²ƒì„ í™•ì‹¤í•˜ê²Œ ë°œê²¬í–ˆë‹¤. [ê·¸ë¦¼1]ì˜ ImageNetì—ì„œì˜ ì‹œì—°ì„ ì°¸ê³ í•˜ì. ì´ë•Œ ì‚¬ìš©í•œ $\\epsilon=0.25$ì´ë‹¤. ë˜í•œ ìš°ë¦¬ëŠ” MNIST ë°ì´í„°ì…‹ì—ì„œ shallow softmax classifierê°€ 79.3%ì˜ ì‹ ë¢°ë„ë¡œ 99.9%ì˜ ì—ëŸ¬ìœ¨ì„ ë‚´ë„ë¡ ìœ ë°œí•˜ì˜€ë‹¤. ê°™ì€ ì„¸íŒ…ì—ì„œ maxout networkëŠ” ìš°ë¦¬ì˜ ì ëŒ€ì  ì˜ˆì œë“¤ì„ í‰ê·  ì‹ ë¢°ë„ 97.6%ë¡œ 89.4% ì˜ëª» ë¶„ë¥˜ í•˜ì˜€ë‹¤. ë¹„ìŠ·í•˜ê²Œ, ë§ˆì°¬ê°€ì§€ë¡œ, $\\epsilon=0.1$ì¼ ë•Œ, CIFAR-10 í…ŒìŠ¤íŠ¸ ì…‹ì˜ ì „ì²˜ë¦¬ëœ ë²„ì „ì—ì„œ convolutional maxout networkë¥¼ ì‚¬ìš©í•˜ì˜€ì„ ë•Œ 87.15%ì˜ ì—ëŸ¬ìœ¨ê³¼ ì˜ëª»ëœ ë ˆì´ë¸”ì— í• ë‹¹ë  í‰ê·  í™•ë¥  96.6%ë¥¼ ì–»ì—ˆë‹¤. ì ëŒ€ì  ì˜ˆì œë¥¼ ìƒì„±í•˜ëŠ” ë‹¤ë¥¸ ì‰¬ìš´ ë°©ë²•ë„ ê°€ëŠ¥í•˜ë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì…ë ¥ $x$ë¥¼ ê·¸ë ˆë””ì–¸íŠ¸$(\\nabla_x J)$ë°©í–¥ìœ¼ë¡œ ì‘ì€ ê°ë„ë¡œ íšŒì „ì‹œí‚¤ë©´ í™•ì‹¤í•˜ê²Œ or ì•ˆì •ì ìœ¼ë¡œ (reliably) ì ëŒ€ì  ì˜ˆì œë¥¼ ìƒì„±í•  ìˆ˜ ìˆë‹¤.ì´ëŸ¬í•œ ê°„ë‹¨í•˜ê³  ì €ë¹„ìš©ì˜ ì•Œê³ ë¦¬ì¦˜ì´ ì˜¤ë¶„ë¥˜ë¥¼ ìœ ë°œí•˜ëŠ” ì ëŒ€ì  ì˜ˆì œë¥¼ ìƒì„±í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì€ ì ëŒ€ì  ì˜ˆì œë¥¼ ì„ í˜•ì„±ì˜ ê²°ê³¼ë¡œ í•´ì„í•˜ëŠ” ê·¼ê±°ë¡œ ìœ ë¦¬í•˜ê²Œ ì‘ìš©í•œë‹¤. ì´ ì•Œê³ ë¦¬ì¦˜ì€ ì ëŒ€ì  í›ˆë ¨ (ì ëŒ€ì  ì˜ˆì œë¥¼ ëª¨ë¸ í›ˆë ¨ì— ì‚¬ìš©í•˜ëŠ” ê²ƒ)ì˜ ì†ë„ë¥¼ ë†’ì´ê±°ë‚˜, í›ˆë ¨ëœ ëª¨ë¸ì˜ ë¶„ì„ì—ë„ ìœ ìš©í•˜ë‹¤.5 ì„ í˜• ëª¨ë¸ë“¤ì˜ ì ëŒ€ì  í›ˆë ¨ vs ê°€ì¤‘ì¹˜ ê°ì‡ (WEIGHT DECAY) [ê·¸ë¦¼2] logistic regrssionì— ì ìš©ëœ FGSM. ì´ ë•Œ ì´ê²ƒì€ ê·¼ì‚¿ê°’ì´ ì•„ë‹ˆë¼ ì§„ì§œë¡œ max-norm boxì—ì„œ ê°€ì¥ í•´ë¡œìš´ ì ëŒ€ì  ì‚¬ë¡€ì´ë‹¤. a) MNIST ë°ì´í„°ì…‹ì—ì„œ í›ˆë ¨ëœ logistic regressionì˜ ê°€ì¤‘ì¹˜ë“¤b) MNIST ë°ì´í„°ì…‹ì—ì„œ í›ˆë ¨ëœ logistic regressionì˜ ê°€ì¤‘ì¹˜ë“¤ì˜ ë¶€í˜¸. ì´ê²Œ ìµœì ì˜ êµë€ê°’ì´ë‹¤. ëª¨ë¸ì´ low-capacity(íŒŒë¼ë¯¸í„°ì˜ ê°œìˆ˜, ìš©ëŸ‰)ì´ê³  ì˜ ì í•©ë˜ì§€ë§Œ, ì´ëŸ° êµë€ì€ ì¸ê°„ì´ 3ê³¼ 7ì„ í˜¼ë™í•˜ê²Œ í•˜ê¸° ì–´ë µë‹¤.c) MNIST ë°ì´í„°ì…‹ì˜ 3ë“¤ê³¼ 7ë“¤. logistic regressionì€ ì´ ì˜ˆì œë“¤ì„ 3ê³¼ 7ë¡œ ë¶„ë¥˜í•˜ëŠ” ì‘ì—…ì—ì„œ 1.6%ì˜ ì—ëŸ¬ìœ¨ì„ ë³´ì˜€ë‹¤.d) FGSMìœ¼ë¡œ ìƒì„±í•œ ì ëŒ€ì  ì˜ˆì œë“¤. $\\epsilon=0.25$ë¡œ í•˜ê³  logistic regressionì— ì ìš©í•˜ì˜€ë‹¤. ì´ ì˜ˆì œë“¤ì˜ logistic regression ëª¨ë¸ì˜ ì—ëŸ¬ìœ¨ì€ ë¬´ë ¤ 99%ì´ë‹¤.ìš°ë¦¬ê°€ ì‹¤í—˜í•´ë³¼ ìˆ˜ ìˆëŠ” ê°€ì¥ ê°„ë‹¨í•œ ëª¨ë¸ì€ ì•„ë§ˆë„ logistic regressionì¼ ê²ƒì´ë‹¤. ì´ ê²½ìš°, FGSMì´ ì ì ˆí•˜ë‹¤. ì´ ì‚¬ë¡€ë¥¼ ì´ìš©í•´ ê°„ë‹¨í•œ í™˜ê²½ì—ì„œ ì ëŒ€ì  ì˜ˆì œê°€ ì–´ë–»ê²Œ ìƒì„±ë˜ëŠ”ì§€ì— ëŒ€í•œ ì§ê´€ì„ ì–»ì–´ë³´ë„ë¡í•˜ì. [ê·¸ë¦¼2]ì˜ ì´ë¯¸ì§€ë“¤ì„ ì°¸ì¡°í•˜ì.ë ˆì´ë¸” $y={-1, 1}$ì—ì„œ $P(y=1)=\\sigma(w\\cdot x+b)$ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë‹¨ì¼ ëª¨ë¸ì„ í›ˆë ¨í•œë‹¤ê³  ê°€ì •í•˜ì. ì´ ë•Œ $\\sigma(z)$ëŠ” logistic sigmoid functionì´ë‹¤. í›ˆë ¨ì€ ë‹¤ìŒê³¼ ê°™ì€ ê²½ì‚¬ í•˜ê°•ìœ¼ë¡œ êµ¬ì„±ëœë‹¤.\\[\\mathbb{E}_{x,y\\sim p_{data}}\\zeta(-y(w\\cdot x+b))\\]$x, y \\sim p_{data}$ : true data ë¶„í¬ $p_{data}$ ì†ì˜ $x, y$$\\zeta(z)=\\log(1+\\exp(z))$ì¸ softplus functionì´ë‹¤. ì•„ë˜ì™€ ê°™ì´ graident sign êµë€ì— ê¸°ë°˜í•˜ì—¬, ì›ë˜ $x$ ëŒ€ì‹  $x$ì˜ ìµœì•…ì˜ ì ëŒ€ì  êµë€ì—ì„œ í›ˆë ¨í•˜ëŠ” ê°„ë‹¨í•œ ìˆ˜ì‹ì„ ìœ ë„í•  ìˆ˜ ìˆë‹¤. ê·¸ë ˆë””ì–¸íŠ¸ì˜ ë¶€í˜¸ëŠ” $-sign(w)$ì´ê³ , $w\\cdot sign(w)=||w||$ì„ì— ìœ ì˜í•˜ë¼. ë”°ë¼ì„œ logistic regressionì˜ ì ëŒ€ì  í›ˆë ¨ì€ ì•„ë˜ ìˆ˜ì‹ì„ ìµœì†Œí™” í•˜ëŠ” ê²ƒì´ë‹¤.\\[\\begin{align*}&amp;\\quad \\ \\mathbb{E}_{x,y\\sim p_{data}}\\zeta(-y(w\\cdot \\tilde{x}+b)) \\\\ \\\\ &amp;= \\mathbb{E}_{x,y\\sim p_{data}}\\zeta(-y(w\\cdot (x-\\epsilon sign(w))+b))\\\\ \\\\&amp;=\\mathbb{E}_{x,y\\sim p_{data}}\\zeta(y(\\epsilon||w||-w\\cdot x-b))\\end{align*}\\]$L^1$ ì •ê·œí™”ì™€ ë‹¤ì†Œ ìœ ì‚¬í•´ ë³´ì¸ë‹¤. ê·¸ëŸ¬ë‚˜ ì¤‘ìš”í•œ ì°¨ì´ì ë“¤ì´ ìˆë‹¤. ê°€ì¥ ì¤‘ìš”í•œê²ƒì€, $L^1$ í˜ë„í‹°ëŠ” í›ˆë ¨ ë¹„ìš©ì— ì¶”ê°€ë˜ê¸° ë³´ë‹¤ëŠ”, í›ˆë ¨ ì¤‘ ëª¨ë¸ì˜ í™œì„±í™”ì—ì„œ ì°¨ê°ëœë‹¤. ì´ëŠ” ëª¨ë¸ì´ $\\zeta$ë¥¼ í¬í™”ì‹œí‚¬ë§Œí¼ ì¶©ë¶„íˆ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì˜ˆì¸¡ì„ í•œë‹¤ë©´ ê²°êµ­ì—” í•´ë‹¹ í˜ë„í‹°ê°€ ì‚¬ë¼ì§€ê¸° ì‹œì‘í•œë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.ì´ê²ƒì´ ì¼ì–´ë‚œë‹¤ê³ ëŠ” ë³´ì¥í•  ìˆ˜ ì—†ë‹¤. underfitting ì²´ì œí•˜ì—ì„œëŠ”, ì ëŒ€ì  í›ˆë ¨ì€ ë‹¨ì§€ underfittingì„ ë”ìš± ì•…í™”ì‹œí‚¬ ë¿ì´ë‹¤. ë”°ë¼ì„œ $L^1$ weight decayë¥¼ ì ëŒ€ì  ì˜ˆì œë³´ë‹¤ ë” ìµœì•…ì˜ ì‚¬ë¡€ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤. ì™œëƒí•˜ë©´ good marginì˜ ê²½ìš°ì—ì„œëŠ” ë¹„í™œì„±í™”ì— ì‹¤íŒ¨í•˜ê¸° ë•Œë¬¸ì´ë‹¤.logistic regressionì„ ë„˜ì–´ì„œ ë‹¤ì¤‘ ë¶„ë¥˜ softm max regressionì˜ ê²½ìš°, $L^1$ weight decayëŠ” ë”ìš± ì•”ìš¸í•´ì§„ë‹¤. ì™œëƒí•˜ë©´ ê° softmaxì˜ ì¶œë ¥ì„ ë…ë¦½ì ìœ¼ë¡œ êµë€ë  ìˆ˜ ìˆëŠ” ê²ƒìœ¼ë¡œ ì·¨ê¸‰í•˜ê¸° ë•Œë¬¸ì´ë‹¤. ì‹¤ì œë¡œ ëª¨ë“  í´ë˜ìŠ¤ì˜ ê°€ì¤‘ì¹˜ ë²¡í„°ë“¤ê³¼ ë§ì¶°ì„œ ì¡°ì •í•  ìˆ˜ ìˆëŠ” $\\eta$ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤. Weight decayëŠ” ë‹¤ì¤‘ hidden statesì˜ ì‹¬ì¸µ ì‹ ê²½ë§ì˜ ê²½ìš° êµë€ìœ¼ë¡œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì†ì‹¤ì„ ê³¼ëŒ€í‰ê°€í•œë‹¤. ì´ì™€ ê°™ì´ $L^1$ weight decayëŠ” ì ëŒ€ë¡œ ì¸í•œ ì†ì‹¤ì„ ê³¼ëŒ€í‰ê°€í•˜ê¸° ë•Œë¬¸ì—, featureì˜ ì •ë°€ë„ë³´ë‹¤ ë” ì‘ì€ $L^1$ weight decay ê³„ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ í•„ìˆ˜ì´ë‹¤. MNIST ë°ì´í„°ì…‹ì—ì„œ maxout networkë¥¼ í›ˆë ¨í•  ë•Œ, $\\epsilon=0.25$ë¥¼ ì‚¬ìš©í•œ ì ëŒ€ì  í›ˆë ¨ì—ì„œ ìš°ë¦¬ëŠ” ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì—ˆë‹¤. ì²« ë²ˆì§¸ ì¸µì— $L^1$ weight decayë¥¼ ì ìš©í–ˆì„ ë•Œ, 0.0025ì˜ ê³„ìˆ˜ì¡°ì°¨ë„ ë„ˆë¬´ í° ê²ƒì„ ë°œê²¬í•˜ì˜€ë‹¤. ë˜í•œ íŠ¸ë ˆì´ë‹ ì…‹ì—ì„œ 5% ì´ìƒì˜ ì—ëŸ¬ìœ¨ì„ ìœ ë°œí•˜ì—¬ ëª¨ë¸ì„ ê³ ì°©ì‹œì¼°ë‹¤. ë” ì‘ì€ weight decay ê³„ìˆ˜ê°€ ì„±ê³µì ì¸ í›ˆë ¨ì„ í•  ìˆ˜ ìˆê²Œ í•´ì£¼ì§€ë§Œ, ì •ê·œí™” íš¨ê³¼ëŠ” ì—†ì—ˆë‹¤.ìœ„ ë‹¨ë½ì€ ë­”ë§ì¸ì§€ ì´í•´í•  ìˆ˜ ì—†ì—ˆë‹¤. ì•„ë˜ ì›ë¬¸ ì°¸ì¡°If we move beyond logistic regression to multiclass softmax regression, $L^1$ weight decay becomes even more pessimistic, because it treats each of the softmaxâ€™s outputs as independently perturbable, when in fact it is usually not possible to find a single $\\eta$ that aligns with all of the classâ€™s weight vectors. Weight decay overestimates the damage achievable with perturbation even more in the case of a deep network with multiple hidden units. Because $L^1$ weight decay overestimates the amount of damage an adversary can do, it is necessary to use a smaller $L^1$ weight decay coefficient than the associated with the precision of our features. When training maxout networks on MNIST, we obtained good results using adversarial training with $\\epsilon=.25$. When applying $L^1$ weight decay to the first layer, we found that even a coefficient of .0025 was too large, and caused the model to get stuck with over 5% error on the training set. Smaller weight decay coefficients permitted succesful training but conferred no regularization benefit.6 ì‹ ê²½ë§ì˜ ì ëŒ€ì  í›ˆë ¨ì ëŒ€ì  ì˜ˆì œì— ëŒ€í•œ ì·¨ì•½ì„±ìœ¼ë¡œ ì¸í•œ ì‹¬ì¸µ ì‹ ê²½ë§ì˜ ë¹„íŒì€ ë‹¤ì†Œ ì˜¤í•´ê°€ ìˆë‹¤. ì–•ì€ ì„ í˜• ëª¨ë¸ë“¤ê³¼ ë‹¬ë¦¬, ì‹¬ì¸µ ì‹ ê²½ë§ì€ ì ì–´ë„ ì ëŒ€ì  êµë€ì— ëŒ€í•­í•˜ëŠ” í•¨ìˆ˜ë¥¼ í‘œí˜„ í•  ìˆ˜ ìˆë‹¤. The universal approximator theorem (Hornik et al ., 1989)ëŠ” ì¶©ë¶„í•œ ìˆ˜ì˜ ìœ ë‹›ë“¤ì´ ìˆëŠ”, ì ì–´ë„ í•˜ë‚˜ì˜ hidden layerì„ ê°€ì§€ê³  ìˆëŠ” ì‹ ê²½ë§ì€ ì„ì˜ì˜ ì •í™•ë„ë¡œ ì–´ë– í•œ í•¨ìˆ˜ë¼ë„ í‘œí˜„í•  ìˆ˜ ìˆìŒì„ ë³´ì¥í•œë‹¤. ì–•ì€ ì„ í˜• ëª¨ë¸ì€ training points ë¶€ê·¼ì—ì„œ ì¼ê´€ë  ìˆ˜ ì—†ëŠ” ë°˜ë©´, ë‹¤ë¥¸ training pointsì—ì„œ ë‹¤ë¥¸ ì¶œë ¥ì„ í• ë‹¹í•  ìˆ˜ ìˆë‹¤.ë‹¹ì—°í•˜ê²Œë„, the universal approximator theoremì€ í›ˆë ¨ ì•Œê³ ë¦¬ì¦˜ì´ ëª¨ë“  ëª©ì ì— ëŒ€ì‘í•˜ëŠ” í•¨ìˆ˜ë¥¼ í‘œí˜„ í•  ìˆ˜ ìˆë‹¤ê³  ë§í•˜ì§€ëŠ” ì•Šì•˜ë‹¤. ëª…ë°±í•˜ê²Œ, í‘œì¤€ì ì¸ ì§€ë„ í›ˆë ¨ì€ ì ëŒ€ì  ì˜ˆì œì— ë‚´ì„±ì„ ê°€ì§€ëŠ” í•¨ìˆ˜ê°€ ìˆë‹¤ëŠ” ê²ƒì„ ëª…ì‹œí•˜ì§€ ì•ŠëŠ”ë‹¤. ì´ê²ƒì€ ë”°ë¡œ í›ˆë ¨ ê³¼ì •ì— í¬í•¨ì‹œì¼œì•¼ í•œë‹¤.Szegedy et al,. (2014b)ëŠ” ê¹¨ë—í•œ ì˜ˆì œì™€ ì ëŒ€ì  ì˜ˆì œì˜ í˜¼í•©ìœ¼ë¡œ í•œ í›ˆë ¨ì—ì„œ, ì‹ ê²½ë§ì´ ë‹¤ì†Œ ì •ê·œí™”ê°€ ë  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ë³´ì˜€ë‹¤. ì ëŒ€ì  ì˜ˆì œì—ì„œ í›ˆë ¨ì‹œí‚¤ëŠ” ê²ƒì€ ë‹¤ë¥¸ data augmentation ë°©ë²•ë“¤ê³¼ëŠ” ë‹¤ì†Œ ì°¨ì´ê°€ ìˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ì…‹ì—ì„œ ì‹¤ì œë¡œ ìˆì„ ê²ƒ ê°™ì€, ë²ˆì—­ë“±ê³¼ ê°™ì€ ë³€í™˜ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë³´ê°•(augments)í•œë‹¤. ì´ì™€ ë‹¬ë¦¬, ì ëŒ€ì  ì˜ˆì œì˜ data augmentationì€ ìì—°ì ìœ¼ë¡œ ë°œìƒí•  ê²ƒ ê°™ì§€ ì•Šì€, ì¦‰ ëª¨ë¸ ì˜ì‚¬ ê²°ì • ê¸°ëŠ¥ ë°©ì‹ì˜ ê²°í•¨ì„ íŒŒí—¤ì¹˜ëŠ” ì…ë ¥ì„ ì‚¬ìš©í•œë‹¤. ê¸°ì¡´ì— ì´ëŸ¬í•œ ê³¼ì •ì€ ë²¤ì¹˜ë§ˆí¬ì—ì„œ drop outì„ ë„˜ì–´ì„œëŠ” ì„±ëŠ¥ê°œì„ ìœ¼ë¡œ ì…ì¦ëœ ì ì´ ì—†ì—ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë¶€ë¶„ì ìœ¼ë¡œ, ì´ëŠ” L-BFGSì— ê¸°ë°˜í•œ ê³ ë¹„ìš©ì˜ ì ëŒ€ì  ì‚¬ë¡€ë¡œ ê´‘ë²”ìœ„í•˜ê²Œ ì‹¤í—˜í•˜ëŠ” ê²ƒì´ ì–´ë µê¸° ë•Œë¬¸ì´ë‹¤.ìš°ë¦¬ëŠ” FGSMì— ê¸°ë°˜í•œ ì•„ë˜ì™€ ê°™ì€ ì ëŒ€ì  ëª©ì  í•¨ìˆ˜ê°€ íš¨ê³¼ì ì¸ ì •ê·œí™”ì¥ì¹˜ë¼ëŠ” ê²ƒì„ ë°œê²¬í–ˆë‹¤.\\[\\tilde{J}(\\theta, x, y)=\\alpha J(\\theta, x, y)+(1-\\alpha)J(\\theta, x+\\epsilon sign(\\nabla_x J(\\theta, x, y))\\]ìš°ë¦¬ëŠ” ëª¨ë“  ì‹¤í—˜ì—ì„œ $\\alpha=0.5$ë¡œ ì„¤ì •í•˜ì˜€ë‹¤. ë‹¤ë¥¸ ê°’ì´ ë” ë‚˜ì„ ìˆ˜ ìˆë‹¤. ìš°ë¦¬ëŠ” ì´ ëª¨ìˆ˜ì— ëŒ€í•œ ì´ˆê¸° ì„¤ì •ì´ ì¶©ë¶„íˆ ì˜ ì‘ë™í•˜ì—¬ ë” ë‚˜ì€ ê°’ì„ ì°¾ì„ í•„ìš”ë¥¼ ëŠë¼ì§€ ëª»í•˜ì˜€ë‹¤. ìœ„ì™€ ê°™ì€ ì ‘ê·¼ ë°©ì‹ì€ í˜„ì œ ëª¨ë¸ì— ì €í•­í•˜ê¸° ìœ„í•˜ì—¬, ì§€ì†ì ìœ¼ë¡œ ì ëŒ€ì  ì˜ˆì œë“¤ì„ ê°±ì‹ í•œë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤. drop outìœ¼ë¡œ ì •ê·œí™”ëœ maxout networkì— ì´ ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•œ ê²°ê³¼, ì ëŒ€ì  í›ˆë ¨ì„ í•˜ì§€ ì•Šì•˜ì„ ë•Œ ì—ëŸ¬ìœ¨ 0.94% ì—ì„œ ì ëŒ€ì  í›ˆë ¨ì„ í–ˆì„ ë•Œ ì—ëŸ¬ìœ¨ 0.84%ë¡œ ì¤„ì¼ ìˆ˜ ìˆì—ˆë‹¤.ìš°ë¦¬ëŠ” í›ˆë ¨ ì„¸íŠ¸ì˜ ì ëŒ€ì  ì˜ˆì œì— ëŒ€í•œ ì˜¤ë¥˜ìœ¨ì´ 0ì´ ë˜ì§€ ì•ŠëŠ” ê²ƒì„ ê´€ì°°í–ˆë‹¤. ìš°ë¦¬ëŠ” ì´ ë¬¸ì œë¥¼ ë‘ ê°€ì§€ì˜ ë³€í™”ë¥¼ ì¤Œìœ¼ë¡œì¨ í•´ê²°í–ˆë‹¤. ì²«ì§¸ë¡œ, ëª¨ë¸ì˜ í¬ê¸°ë¥¼ í‚¤ì› ë‹¤. ì´ ë¬¸ì œ ë•Œë¬¸ì— ë ˆì´ì–´ë‹¹ 240ê°œì˜ ìœ ë‹›ì„ ì‚¬ìš©í•˜ëŠ” ì›ë˜ maxout networkëŒ€ì‹  ë ˆì´ì–´ë‹¹ 1600ê°œì˜ ìœ ë‹›ì„ ì‚¬ìš©í•˜ì˜€ë‹¤. ì ëŒ€ì  í›ˆë ¨ì´ ì—†ë‹¤ë©´ ì´ê²ƒì€ ì‚´ì§ ê³¼ì í•©ì„ ìœ ë°œí•˜ë©°, í…ŒìŠ¤íŠ¸ì…‹ì—ì„œ 1.14%ì˜ ì˜¤ë¥˜ìœ¨ì„ ì–»ì—ˆë‹¤. ì ëŒ€ì  í›ˆë ¨í•˜ì—ì„œ, ê²€ì¦ ì…‹ì˜ ì—ëŸ¬ê°€ ë§¤ìš° ëŠë¦¬ê²Œ, ì ì§„ì ìœ¼ë¡œ ìˆ˜í‰ì„ ì´ë£¨ëŠ” ê²ƒì„ ë°œê²¬í–ˆë‹¤. ê¸°ì¡´ maxout networkì˜ ê²°ê³¼ëŠ” early stoppingì„ ì´ìš©í•˜ì˜€ê³ , ê²€ì¦ ì…‹ì˜ ì—ëŸ¬ìœ¨ì´ 100ì—í­ë™ì•ˆ ê°ì†Œí•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ í•™ìŠµì„ ì¢…ë£Œí•˜ì˜€ë‹¤. ìš°ë¦¬ëŠ” ê²€ì¦ì…‹ì˜ ì—ëŸ¬ê°€ ë§¤ìš° í‰í‰í•œ ë°˜ë©´, ì ëŒ€ì  ê²€ì¦ ì…‹ì€ ê·¸ë ‡ì§€ ì•Šë‹¤ëŠ” ê²ƒì„ ë°œê²¬í•˜ì˜€ë‹¤. ë”°ë¼ì„œ ìš°ë¦¬ëŠ” ì ëŒ€ì  ê²€ì¦ì…‹ì— early stoppingì„ ì ìš©í•˜ì˜€ë‹¤. í›ˆë ¨í•  ì—í­ì˜ ìˆ˜ë¥¼ ê²°ì •í•˜ê¸° ìœ„í•´ ì´ëŸ¬í•œ í‰ê°€ ê¸°ì¤€(criterion)ì„ ì‚¬ìš©í•˜ì˜€ê³ , 60000ê°œì˜ ì˜ˆì œì— ëŒ€í•˜ì—¬ ë‹¤ì‹œ í›ˆë ¨ì‹œì¼°ë‹¤. í›ˆë ¨ ë°ì´í„°ì˜ ë¯¸ë‹ˆ ë°°ì¹˜, ëª¨ë¸ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”, drop out mask ìƒì„±ì— ë‚œìˆ˜ ìƒì„±ì‹œë¥¼ ì‚¬ìš©í•œ ì„œë¡œ ë‹¤ë¥¸ seedë“¤ì˜ 5ê°œì˜ í›ˆë ¨ì—ì„œ, í…ŒìŠ¤íŠ¸ì…‹ì—ì„œì˜ ì—ëŸ¬ìœ¨ì€ 0.77%ì´ 4ê°œ, ë‚˜ë¨¸ì§€ í•˜ë‚˜ì—ì„œ 0.83%ì˜ ì—ëŸ¬ìœ¨ì´ ë‚˜ì™”ë‹¤. ì´ 0.782%ì˜ í‰ê· ì€ MNISTì˜ ìˆœì—´ ë¶ˆë³€ ë²„ì „ì— ëŒ€í•´ ì•Œë ¤ì§„ ìµœìƒì˜ ê²°ê³¼ì´ë‹¤. ë‹¨, 0.79%ë¡œ DBMì„ ë¯¸ì„¸ ì¡°ì •í•˜ì—¬ ì–»ì€ ê²°ê³¼ì™€ í†µê³„ì ìœ¼ë¡œ êµ¬ë³„í•  ìˆ˜ ì—†ë‹¤(Srivastata et al., 2014). [ê·¸ë¦¼ 3] MNIST ë°ì´í„°ì…‹ì—ì„œ í›ˆë ¨ëœ maxout network ê°€ì¤‘ì¹˜ë“¤ì˜ ì‹œê°í™”. ê° í–‰ì€ ë‹¨ì¼ maxout ìœ ë‹›ì˜ filterë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. ì™¼ìª½ì€ ì¼ë°˜ì ìœ¼ë¡œ í›ˆë ¨ëœ ëª¨ë¸ì´ê³ , ì˜¤ë¥¸ìª½ì€ ì ëŒ€ì  í›ˆë ¨ëœ ëª¨ë¸ì´ë‹¤.ì´ ëª¨ë¸ì€ ë˜í•œ ì ëŒ€ì  ì˜ˆì œì— ëŒ€í•œ ë‚´ì„±ì„ ë‹¤ì†Œ ê°€ì§„ë‹¤. ì ëŒ€ì  í›ˆë ¨ì—†ëŠ” ì´ëŸ¬í•œ ì¢…ë¥˜ì˜ ëª¨ë¸ì´ FGSMì˜ ì ëŒ€ì  ì˜ˆì œì—ì„œ 89.4%ì˜ ì—ëŸ¬ìœ¨ì„ ë³´ì˜€ë‹¤ëŠ” ê²ƒì„ ìƒê¸°í•˜ì. ì ëŒ€ì  í›ˆë ¨ê³¼ í•¨ê»˜í•œë‹¤ë©´, ì´ ì—ëŸ¬ìœ¨ì´ 17.9%ë¡œ ë–¨ì–´ì§„ë‹¤. ê°ê°ì˜ ëª¨ë¸ë“¤ì´ ìƒì„±í•œ ì ëŒ€ì  ì˜ˆì œë“¤ì€ ë‘ ëª¨ë¸ ê°„ì— ì „ì†¡ë  ìˆ˜ ìˆì§€ë§Œ, ì ëŒ€ì  í›ˆë ¨ëœ ëª¨ë¸ì´ ë” robustnessí•¨ì„ ë³´ì—¬ì¤€ë‹¤. ê¸°ì¡´ ëª¨ë¸ì„ í†µí•´ ìƒì„±ëœ ì ëŒ€ì  ì˜ˆì œëŠ” ì ëŒ€ì  í›ˆë ¨ ëª¨ë¸ì—ì„œ 19.6%ì˜ ì—ëŸ¬ìœ¨ì„ ë³´ì˜€ì§€ë§Œ, ì ëŒ€ì  í›ˆë ¨ ëª¨ë¸ì—ì„œ ìƒì„±ëœ ì ëŒ€ì  ì˜ˆì œëŠ” ê¸°ì¡´ ëª¨ë¸ì—ì„œ 40.9%ì˜ ì—ëŸ¬ìœ¨ì„ ë‚˜íƒ€ëƒˆë‹¤. ì ëŒ€ì  í›ˆë ¨ ëª¨ë¸ì´ ì ëŒ€ì  ì˜ˆì œë¥¼ ì˜ëª» ë¶„ë¥˜í•  ê²½ìš°, ë¶ˆí–‰í•˜ê²Œë„ ê·¸ ì˜ˆì¸¡ì€ ì—¬ì „íˆ ë†’ì€ ì‹ ë¢°ë„ë¥¼ ê°–ëŠ”ë‹¤. ì˜¤ë¶„ë¥˜ëœ ì˜ˆì œë“¤ì˜ í‰ê·  ì‹ ë¢°ë„ëŠ” 81.4%ì˜€ë‹¤. ìš°ë¦¬ëŠ” ë˜í•œ ì¼ë°˜ì ìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ê°€ ì ëŒ€ì  í›ˆë ¨ì„ í•  ê²½ìš° í¬ê²Œ ë³€ê²½ë˜ë©°, ì ëŒ€ì  í›ˆë ¨ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ê°€ ìƒë‹¹íˆ ë” êµ­ì†Œí™”ë˜ê³  í•´ì„ ê°€ëŠ¥í•˜ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆë‹¤(ê·¸ë¦¼ 3 ì°¸ì¡°).ì´ ì ëŒ€ì  í›ˆë ¨ ê³¼ì •ì€ ë°ì´í„°ê°€ ìƒëŒ€ë°©(adversary)ì— ì˜í•´ êµë€ë˜ì—ˆì„ ë•Œ ìµœì•…ì˜ ì˜ˆì œì˜ ì—ëŸ¬ë¥¼ ìµœì†Œí™” ì‹œí‚¤ëŠ” ê²ƒì²˜ëŸ¼ ë³´ì¼ ìˆ˜ ìˆë‹¤. ì´ê²ƒì€ í•™ìŠµì„ í•˜ê¸° ìœ„í•´ ì ëŒ€ì  ê²Œì„ì„ í•˜ëŠ” ê²ƒ, ë˜ëŠ” $U(-\\epsilon, \\epsilon)$ ë²”ìœ„ì˜ ë…¸ì´ì¦ˆê°€ ì„ì¸ ìƒ˜í”Œë“¤ì„ ì…ë ¥ì— ì¶”ê°€í–ˆì„ ë•Œ ê¸°ëŒ€ë˜ëŠ” costì˜ ìƒê³„ë¥¼ ìµœì†Œí™”í•˜ëŠ” ê²ƒìœ¼ë¡œ í•´ì„ë  ìˆ˜ ìˆë‹¤. ë˜í•œ ì ëŒ€ì  í›ˆë ¨ì€ ëª¨ë¸ì´ ìŠ¤ìŠ¤ë¡œ ìƒˆë¡œìš´ ì§€ì ì—ì„œì˜ ë ˆì´ë¸”ì„ ìœ ì¶”í•˜ëŠ” ëŠ¥ë™ì ì¸ í•™ìŠµìœ¼ë¡œ ë³¼ ìˆ˜ ìˆë‹¤. ì´ ê²½ìš° ì¸ê°„ labelerëŠ” nearby pointsì—ì„œ labelì„ ë³µì‚¬í•˜ëŠ” íœ´ë¦¬ìŠ¤í‹± labelerë¡œ ëŒ€ì²´ëœë‹¤.ë˜í•œ $\\epsilon$ max norm boxì˜ ëª¨ë“  í¬ì¸íŠ¸ë“¤ í˜¹ì€ box ë‚´ì˜ ë§ì€ ì ë“¤ì„ ìƒ˜í”Œë§í•˜ì—¬ í›ˆë ¨ì„ ì‹¤ì‹œí•¨ìœ¼ë¡œì¨ featureì˜ $\\epsilon$ ì •ë°€ë„ ì´í•˜ ë³€í™”ì— ë‘”ê°í•´ì§€ë„ë¡ ì •ê·œí™”í•  ìˆ˜ ìˆë‹¤. ì´ëŠ” í›ˆë ¨ ì¤‘ì— max norm $\\epsilon$ì˜ ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒê³¼ ê´€ë ¨ìˆë‹¤. ê·¸ëŸ¬ë‚˜, í‰ê· ê³¼ ê³µë¶„ì‚°ì´ 0ì¸ ë…¸ì´ì¦ˆëŠ” ì ëŒ€ì  ì˜ˆì œë¥¼ ì˜ˆë°©í•˜ëŠ” ë° ë§¤ìš° ë¹„íš¨ìœ¨ì ì´ë‹¤. ì°¸ì¡°ëœ ì–´ë– í•œ ë²¡í„°ì™€ í•´ë‹¹ ë…¸ì´ì¦ˆì™€ì˜ ë‚´ì ì˜ ê¸°ëŒ“ê°’ì€ 0ì´ë‹¤. ì´ëŠ” ë§ì€ ê²½ìš°ì— í•´ë‹¹ ë…¸ì´ì¦ˆê°€ ë” ë³µì¡í•œ ì…ë ¥ì„ ë§Œë“¤ ë¿, ì•„ë¬´ëŸ° íš¨ê³¼ê°€ ì—†ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.ì‹¤ì œë¡œ ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ì´ëŸ° ë…¸ì´ì¦ˆëŠ” ë‚®ì€ ëª©ì í•¨ìˆ«ê°’ì„ ë§Œë“¤ì–´ë‚¸ë‹¤. ì ëŒ€ì  í›ˆë ¨ì€ ë¶„ë¥˜ì— ê°•í•˜ê²Œ ì €í•­í•˜ëŠ” ë…¸ì´ì¦ˆ í¬ì¸íŠ¸ë“¤ì„ ê³ ë ¤í•¨ìœ¼ë¡œì¨ ë”ìš± íš¨ìœ¨ì ìœ¼ë¡œ í›ˆë ¨í•˜ê¸° ìœ„í•´ ë…¸ì´ì¦ˆê°€ ìˆëŠ” ì…ë ¥ë“¤ì—ì„œ ì–´ë ¤ìš´ ì˜ˆì œë“¤ì„ ë§ˆì´ë‹ í•˜ëŠ” ê²ƒì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤. ì œì–´ ì‹¤í—˜ìœ¼ë¡œì¨ ê° í”½ì…€ì— ë¬´ì‘ìœ„ë¡œ $\\pm \\epsilon$ì„ í•˜ê±°ë‚˜, $U(-\\epsilon, \\epsilon)$ì˜ ë…¸ì´ì¦ˆë¥¼ ì„ì–´ì„œ maxout networkë¥¼ í›ˆë ¨ì‹œì¼œ ë³´ì•˜ë‹¤. ì´ê²ƒì€ ì‹ ë¢°ë„ 97.3%ì˜ ì‹ ë¢°ë„ì˜ 86.2%ì˜ ì—ëŸ¬ìœ¨ì„ ë‚˜íƒ€ë‚´ì—ˆê³ , FGSMìœ¼ë¡œ ìƒì„±ëœ ì ëŒ€ì  ì˜ˆì œë“¤ì€ ì‹ ë¢°ë„ 97.8%ë¡œ 90.4%ì˜ ì—ëŸ¬ìœ¨ì„ ë‚˜íƒ€ë‚´ì—ˆë‹¤.$sign$í•¨ìˆ˜ì˜ ë¯¸ë¶„ì´ 0ì´ê±°ë‚˜ ì–´ë””ì—ì„œë„ ì •ì˜ë˜ì§€ ì•Šê¸° ë•Œë¬¸ì—, FGSM ê¸°ë°˜ ì ëŒ€ì  ëª©ì  í•¨ìˆ˜ì˜ ê²½ì‚¬í•˜ê°•ë²•ì€ ëª¨ë¸ì´ íŒŒë¼ë¯¸í„°ì˜ ë³€í™”ì— ë”°ë¼ ìƒëŒ€ë°©ì´ ì–´ë–»ê²Œ ëŒ€ì‘í•  ì§€ ì˜ˆì¸¡í•  ìˆ˜ ì—†ê²Œ í•œë‹¤. ëŒ€ì‹  ì‘ì€ íšŒì „ì´ë‚˜, scaled gradientì˜ ë§ì…ˆì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ì ëŒ€ì  ì˜ˆì œë¥¼ ì‚¬ìš©í•œë‹¤ë©´, êµë€ ê³¼ì • ìì²´ê°€ ë¯¸ë¶„ê°€ëŠ¥í•˜ê³  í•™ìŠµ ê³¼ì •ì—ì„œ ìƒëŒ€ë°©ì—ê²Œ ëŒ€ì‘í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤. ê·¸ëŸ¬ë‚˜, ì´ëŸ¬í•œ ì ëŒ€ì  ì˜ˆì œëŠ” í•´ê²°í•˜ê¸°ê°€ ì–´ë µì§€ ì•Šê¸° ë•Œë¬¸ì— ì •ê·œí™” ì‹œí‚¬ë§Œí¼ ê°•ë ¥í•œ ê²ƒì„ ë°œê²¬í•˜ì§€ ëª»í–ˆë‹¤.í•˜ë‚˜ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ì€ ì…ë ¥ì„ êµë€í•˜ëŠ” ê²ƒì´ ë” ë‚˜ì€ê°€ í˜¹ì€ hidden layerë¥¼ êµë€í•˜ëŠ” ê²ƒì´ ë‚˜ì€ê°€, ì•„ë‹ˆë©´ ë‘˜ ë‹¤ êµë€í•˜ëŠ” ê²ƒì´ ë‚˜ì€ê°€ì´ë‹¤. ì—¬ê¸°ì—ì„œëŠ” ê²°ê³¼ê³¼ ì¼ì •í•˜ì§€ ì•Šë‹¤. Szegedy et al,. (2014b)ëŠ” ì ëŒ€ì  êµë€ì€ hidden layerë“¤ì— ì ìš©ë¬ì„ ë•Œ ìµœê³ ì˜ ì •ê·œí™”ë¥¼ ì œê³µí•œë‹¤ëŠ” ê²ƒì„ ë³´ê³ í–ˆë‹¤. ì´ ê²°ê³¼ëŠ” sigmoidal networkì—ì„œ ì–»ì–´ì¡Œë‹¤. ìš°ë¦¬ì˜ FGSMë¥¼ ì‚¬ìš©í•œ ì‹¤í—˜ì—ì„œ í™œì„±í™”ê°€ ìœ ê³„ì´ì§€ ì•Šì€ hidden unitsì˜ networkëŠ” ê·¸ë“¤ì˜ hidden unit í™œì„±í™”ë¥¼ ë§¤ìš° í¬ê²Œí•¨ìœ¼ë¡œì¨ ë‹¨ìˆœíˆ ë°˜ì‘í•œë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆë‹¤. ë”°ë¼ì„œ ì›ë˜ ì…ë ¥ì— êµë€ì„ ì£¼ëŠ” ê²ƒì´ ì¼ë°˜ì ìœ¼ë¡œ ë” ë‚«ë‹¤.Rust ëª¨ë¸ê³¼ ê°™ì€ saturating ëª¨ë¸ë“¤ì—ì„œëŠ” êµë€ëœ ì…ë ¥ì´ hidden layerì˜ êµë€ê³¼ ìœ ì‚¬í•˜ê²Œ ìˆ˜í–‰ëœë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆë‹¤. hidden layerë¥¼ íšŒì „í•˜ëŠ” ê²ƒì— ê¸°ë°˜í•œ êµë€ì€ ìœ ê³„ì´ì§€ ì•Šì€ í™œì„±í™”ê°€ ë°œì‚°í•˜ì—¬ ì¶”ê°€ì ì¸ êµë€ì„ ë¹„êµì— ì˜í•´ ì‘ê²Œ ë§Œë“œëŠ” ë¬¸ì œë¥¼ í•´ê²°í–ˆë‹¤.hidden layerì˜ íšŒì „ êµë€ìœ¼ë¡œ maxout networkë¥¼ ì„±ê³µì ìœ¼ë¡œ í›ˆë ¨ ì‹œí‚¬ ìˆ˜ ìˆì—ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŠ” input layerì— êµë€ì„ ë”í•˜ëŠ” ê²ƒë§Œí¼ì˜ ê°•ë ¥í•œ ì •ê·œí™” íš¨ê³¼ë¥¼ ì‚°ì¶œí•´ë‚´ì§€ ëª»í–ˆë‹¤. ì ëŒ€ì  í›ˆë ¨ì— ëŒ€í•œ ìš°ë¦¬ì˜ ê´€ì ì€ ëª¨ë¸ì´ ì ëŒ€ì  ì˜ˆì œì— ì €í•­í•˜ëŠ” ê²ƒì„ í•™ìŠµí•  ìˆ˜ ìˆì„ ë§Œí•œ capacityê°€ ìˆì„ ë•Œë§Œ ìœ ìš©í•˜ë‹¤ëŠ” ê²ƒì´ë‹¤. ì´ê²ƒì€ universal approximator theoremì´ ì ìš©ë˜ëŠ” ê²½ìš°ì—ë§Œ ì„ ëª…í•˜ê²Œ ì ìš©ëœë‹¤. ì‹ ê²½ë§ì˜ ë§ˆì§€ë§‰ layerì¸ linear sigmoid, linear softmax layerëŠ” ìµœì¢… hidden layer í•¨ìˆ˜ì— ëŒ€í•œ universal approximationì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì—, ìµœì¢… hidden layerì— ì ëŒ€ì  êµë€ì„ ì ìš©í–ˆì„ ë•Œ underfittingì˜ ë¬¸ì œì— ì§ë©´í•  ìˆ˜ ìˆë‹¤. ì‹¤ì œë¡œ ìš°ë¦¬ëŠ” ì´ íš¨ê³¼ë¥¼ ë°œê²¬í–ˆë‹¤. hidden layerì˜ êµë€ì„ ì‚¬ìš©í•œ í›ˆë ¨ì˜ ìµœê³ ì˜ ê²°ê³¼ëŠ” ìµœì¢… hidden layerì— êµë€ì„ ì£¼ì§€ ì•ŠëŠ”ë‹¤.7 ëª¨ë¸ CAPACITY ì˜ ë‹¤ë¥¸ ì¢…ë¥˜ë“¤ì ëŒ€ì  ì˜ˆì œì˜ ì¡´ì¬ê°€ ì§ê´€ì— ë§ì„œëŠ” ê²ƒì²˜ëŸ¼ ë³´ì´ëŠ” ì´ìœ  ì¤‘ í•˜ë‚˜ëŠ” ìš°ë¦¬ëŠ” ëŒ€ë¶€ë¶„ ê³ ì°¨ì› ê³µê°„ì—ì„œ ê±°ì§€ê°™ì€ ì§ê´€(poor intuitions)ì„ ê°€ì§€ê³  ìˆê¸° ë•Œë¬¸ì´ë‹¤. ìš°ë¦¬ëŠ” 3ì°¨ì› ê³µê°„ì—ì„œ ì‚´ê³  ìˆê³ , ë”°ë¼ì„œ ìˆ˜ë°±ê°œì˜ ì°¨ì›ì—ì„œì˜ ì‘ì€ ë³€í™”ê°€ ë”í•´ì ¸ì„œ í•˜ë‚˜ì˜ í° íš¨ê³¼ë¥¼ ë°œíœ˜í•˜ëŠ” ê²ƒì— ìµìˆ™í•˜ì§€ ì•Šë‹¤. ìš°ë¦¬ì˜ ê±°ì§€ê°™ì€ ì§ê´€ì´ ë¯¸ì³ ë‚ ë›°ëŠ” ì¼ì´ í•˜ë‚˜ ë” ìˆë‹¤. ë§ì€ ì‚¬ëŒë“¤ì´ low-capacityì˜ ëª¨ë¸ë“¤ì€ ë‹¤ì–‘í•˜ê³  ì‹ ë¢°ë„ì˜ ì˜ˆì¸¡ì„ í•  ìˆ˜ ì—†ì„ ê²ƒì´ë¼ê³  ìƒê°í•œë‹¤. ì´ê²ƒì€ ì˜ëª»ëœ ìƒê°ì´ë‹¤. low capacityì˜ ëª‡ ëª¨ë¸ë“¤ì€ ì´ëŸ¬í•œ ë™ì‘ì„ í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ë‹¤ìŒê³¼ ê°™ì€ ì–•ì€ RBF networkë¥¼ ì‚¬ìš©í•´ë³´ì.\\[p(y=1|x)=\\exp((x-\\mu)\\cdot \\beta(x-\\mu))\\]ì´ëŠ” $\\mu$ ê·¼ë°©ì— ì–‘ì˜ í´ë˜ìŠ¤ê°€ ì¡´ì¬í•œë‹¤ê³  ë†’ì€ ì‹ ë¢°ë„ë¡œ ì˜ˆì¸¡í•  ìˆ˜ ìˆì„ ë¿ì´ë‹¤. ë‹¤ë¥¸ ê³³ì—ì„œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ í´ë˜ìŠ¤ê°€ ì—†ê±°ë‚˜ ì‹ ë¢°ë„ê°€ ë‚®ì€ ì˜ˆì¸¡ì„ í•œë‹¤.RBF networkëŠ” ìì‹ ì´ ì†ì•˜ì„(fooled) ë•Œ ë‚®ì€ ì‹ ë¢°ë„ë¥¼ ê°€ì§€ê³  ìˆì–´, ì ëŒ€ì  ì˜ˆì œì— ê·¼ë³¸ì ìœ¼ë¡œ ë©´ì—­ì´ë¼ê³  í•  ìˆ˜ ìˆë‹¤. hidden layerê°€ ì—†ëŠ” ì–•ì€ RBF networkëŠ” MNIST ë°ì´í„°ì…‹ì— $\\epsilon=0.25$ë¡œ FGSMì´ ìƒì„±í•œ ì ëŒ€ì  ì˜ˆì œ ì—ì„œ 55.4%ì˜ ì—ëŸ¬ìœ¨ì„ ë³´ì¸ë‹¤. ê·¸ëŸ¬ë‚˜, ì´ ëª¨ë¸ì´ ì˜¤ë¶„ë¥˜í•œ ì˜ˆì œì—ì„œì˜ ì‹ ë¢°ë„ê°€ ì˜¤ì§ 1.2%ì´ë©°, í´-ë¦°í•œ ì˜ˆì œì— ëŒ€í•œ í‰ê·  ì‹ ë¢°ë„ëŠ” 60.6%ì´ë‹¤. ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ ë‚®ì€ capacityì˜ ëª¨ë¸ì´ ê³µê°„ì˜ ëª¨ë“  ì§€ì ì—ì„œ ì˜¬ë°”ë¥¸ ë‹µì„ ë„ì¶œí•  ìˆ˜ ìˆì„ ê²ƒì´ë¼ê³  ê¸°ëŒ€í•  ìˆ˜ ì—†ë‹¤. ê·¸ëŸ¬ë‚˜ ì´ê²ƒì€ ëª¨ë¸ì´ â€œì´í•´í•˜ì§€ ëª»í•œâ€ ì§€ì ì„ ê³ ë ¤í•˜ì—¬ ì‹ ë¢°ë„ë¥¼ ìƒë‹¹íˆ ë‚®ì¶° ì˜¬ë°”ë¥¸ ë°˜ì‘ì„ í•œë‹¤.ë¶ˆí–‰íˆë„, RBF ìœ ë‹›ë“¤ì€ ìœ ì˜ë¯¸í•œ ë³€í™˜ì— ì‰½ê²Œ ë°˜ì‘í•˜ê¸° ë•Œë¬¸ì—, ì˜ ì¼ë°˜í™”ë˜ì§€ ì•ŠëŠ”ë‹¤. ìš°ë¦¬ëŠ” ì„ í˜• ìœ ë‹›ë“¤ê³¼ RBF ìœ ë‹›ë“¤ì„ precision-recall tradeoff ê³¡ì„ ì˜ ë‹¤ë¥¸ ì ë“¤ë¡œ ë³¼ ìˆ˜ ìˆë‹¤. ì„ í˜• ìœ ë‹›ë“¤ì€ íŠ¹ì • ë°©í–¥ì˜ ëª¨ë“  ì…ë ¥ì—ì„œ ë†’ì€ recall ì„ ë‹¬ì„±í•˜ì§€ë§Œ, ë‚®ì„  ìƒí™©ì— ë„ˆë¬´ ì˜ˆë¯¼í•˜ê²Œ ë°˜ì‘í•˜ì—¬ ë‚®ì€ precisionì„ ê°€ì§ˆ ìˆ˜ ìˆë‹¤. RBF ìœ ë‹›ë“¤ì€ ê³µê°„ì˜ íŠ¹ì • ì§€ì ì—ë§Œ ë°˜ì‘í•˜ì—¬ ë†’ì€ precisionì„ ë‹¬ì„±í•˜ì§€ë§Œ, ê·¸ë ‡ê²Œ í•¨ìœ¼ë¡œì¨ recallì„ í¬ìƒí•œë‹¤. ì´ëŸ¬í•œ ì•„ì´ë””ì–´ë¥´ ë°”íƒ•ìœ¼ë¡œ, ìš°ë¦¬ëŠ” ì‹¬ì¸µ RBF networkë¥¼ í¬í•¨í•˜ì—¬ 2ì°¨(quadratic) ìœ ë‹›ë“¤ê³¼ ê´€ë ¨ëœ ë‹¤ì–‘í•œ ëª¨ë¸ì„ íƒêµ¬í•˜ê¸°ë¡œ ê²°ì •í–ˆë‹¤. ìš°ë¦¬ëŠ” ì´ê²ƒì´ ì–´ë ¤ìš´ ì‘ì—…ì´ë¼ëŠ” ê²ƒì„ ë°œê²¬í–ˆë‹¤. ì ëŒ€ì  êµë€ì— ì €í•­ í•  ìˆ˜ ìˆì„ ë§Œí¼ì˜ 2ì°¨ ì–µì œë¥¼ ê°€ì§„ ëª¨ë“  ëª¨ë¸ì€ SGDë¡œ í›ˆë ¨í•  ë•Œ ë†’ì€ í›ˆë ¨ ì…‹ ì—ëŸ¬ë¥¼ ì–»ì—ˆë‹¤.8 ì ëŒ€ì  ì˜ˆì œê°€ ì™œ ì¼ë°˜í™”(Generalize)ë˜ëŠ”ê°€?ì ëŒ€ì  ì˜ˆì œì˜ í¥ë¯¸ë¡œìš´ ì¸¡ë©´ì€ ì–´ë– í•œ ëª¨ë¸ì„ ìœ„í•´ ìƒì„±ëœ ì˜ˆì œê°€ ë‹¤ë¥¸ ëª¨ë¸ë“¤ì— ì˜í•´ ì˜¤ë¶„ë¥˜ëœë‹¤ëŠ” ì ì´ë‹¤. ê·¸ë“¤ì´ ì„œë¡œ ë‹¤ë¥¸ ì•„í‚¤í…ì³ í˜¹ì€ ìƒí˜¸ë°°íƒ€ì ì¸(disjoint) íŠ¸ë ˆì´ë‹ ì…‹ì—ì„œ í›ˆë ¨ë¬ì„ì§€ë¼ë„ ë§ì´ë‹¤. ë”ìš±ì´, ì´ ì„œë¡œ ë‹¤ë¥¸ ëª¨ë¸ë“¤ì´ ì ëŒ€ì  ì˜ˆì œë¥¼ ì˜¤ë¶„ë¥˜í•  ë•Œ, ê·¸ë“¤ì€ ì¢…ì¢… ê·¸ê²ƒì˜ í´ë˜ìŠ¤ì— ëŒ€í•´ ì„œë¡œ ë™ì˜í•œë‹¤. ê³ ë„ì˜ ë¹„ì„ í˜•ì„±ê³¼ ê³¼ì í•©ì˜ ê¸°ë°˜í•œ ì„¤ëª…ë“¤ì€ ì´ëŸ¬í•œ í–‰ë™ì— ëŒ€ì‘í•˜ì§€ ëª»í•œë‹¤. ì™œ ê³ ë„ì˜ ë¹„ì„ í˜•ì„±ê³¼ ë„˜ì¹˜ëŠ” capacityë¥¼ ê°€ì§„ ë‹¤ì¤‘ ë¶„ë¥˜ ëª¨ë¸ì´ ì¼ë°˜ì ì¸ ë¶„í¬ì—ì„œ ë²—ì–´ë‚œ ë°ì´í„°ë¥¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì¼ê´€ì ì´ê²Œ ë¶„ë¥˜í•˜ëŠ”ê°€? ì´ëŸ¬í•œ í–‰ë™ì€ ì ëŒ€ì  ì˜ˆì œê°€ ì‹¤ìˆ˜ ì†ì˜ ìœ ë¦¬ìˆ˜ì²˜ëŸ¼ ê³µê°„ì„ ë¯¸ì„¸í•˜ê²Œ íƒ€ì¼ë§í•œë‹¤ëŠ” ê°€ì„¤ì˜ ê´€ì ì—ì„œ ë³¼ ë•Œ íŠ¹íˆ ë†€ë¼ìš´ë°, ì´ëŠ” ì ëŒ€ì  ì˜ˆì œëŠ” ì¼ë°˜ì ì´ì§€ë§Œ ë§¤ìš° ì •í™•í•œ ìœ„ì¹˜ì—ì„œ ë‚˜íƒ€ë‚˜ê¸° ë•Œë¬¸ì´ë‹¤. [ê·¸ë¦¼ 4] ë‹¤ì–‘í•œ ê°’ì˜ $\\epsilon$ì— ë”°ë¼ì„œ, ì˜¬ë°”ë¥¸ ë°©í–¥ìœ¼ë¡œ ì›€ì§ì¸ë‹¤ë©´ $\\epsilon$ì˜ ê±°ì˜ ëª¨ë“  ì¶©ë¶„íˆ í° ê°’ì— ëŒ€í•´ ì ëŒ€ì  ì˜ˆì œê°€ ì•ˆì •ì ìœ¼ë¡œ ë°œìƒí•œë‹¤. ì˜¬ë°”ë¥¸ ë¶„ë¥˜ë“¤ì€ $x$ê°€ ë°œìƒí•˜ëŠ” ë°ì´í„°ì†ì˜ ì–‡ì€ ë‹¤ì–‘ì²´ì•ˆì—ì„œë§Œ ì¼ì–´ë‚œë‹¤. $\\mathbb{R}^n$ê³µê°„ì˜ ëŒ€ë¶€ë¶„ì€ ì ëŒ€ì  ì˜ˆì œì™€ rubbish class ì˜ˆì œë“¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ì´ ê·¸ë¦¼ì€ ì¼ë°˜ì ìœ¼ë¡œ í›ˆë ¨ëœ maxout networkë¡œë¶€í„° ë§Œë“¤ì–´ì¡Œë‹¤. ì™¼ìª½ì˜ ê·¸ë¦¼ì€ í•˜ë‚˜ì˜ ì…ë ¥ ì˜ˆì œì— $\\epsilon$ì„ ë³€í™”ì‹œí‚¬ ë•Œ 10ê°œì˜ MNIST í´ë˜ìŠ¤ ê°ê°ì— ëŒ€í•œ ì†Œí”„íŠ¸ ë§¥ìŠ¤ ê³„ì¸µì˜ ì¸ìˆ˜ë¥¼ ë³´ì—¬ì¤€ë‹¤. ì˜¬ë°”ë¥¸ í´ë˜ìŠ¤ëŠ” 4ì´ë‹¤. ê° í´ë˜ìŠ¤ì— ëŒ€í•œ ì •ê·œí™”ë˜ì§€ ì•Šì€ ë¡œê·¸ í™•ë¥ ë“¤ì€ $\\epsilon$ê³¼ í•¨ê»˜ ëˆˆì— ë„ê²Œ ì„ í˜•ì´ë©° ì˜¤ë¶„ë¥˜ëŠ” $\\epsilon$ê°’ì˜ ë„“ì€ ì˜ì—­ì—ì„œ ì•ˆì •ì ì´ë¼ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ë”ìš±ì´, rubbish ì…ë ¥ì˜ ì²´ì œë¡œ ì´ë™í•  ìˆ˜ ìˆì„ ë§Œí¼ ì¶©ë¶„íˆ $\\epsilon$ì„ ì¦ê°€ì‹œí‚¨ë‹¤ë©´ ì˜ˆì¸¡ì€ ë§¤ìš° ê·¹ë‹¨ì ì´ê²Œ ëœë‹¤. ì˜¤ë¥¸ìª½ ê·¸ë¦¼ì€ ê³¡ì„ ì„ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ì…ë ¥ì´ë‹¤. ì´ ê·¸ë¦¼ì˜ ì™¼ìª½ ìœ„ëŠ” $-\\epsilon$ì„ ì‚¬ìš©í•˜ì˜€ê³ , ì˜¤ë¥¸ìª½ ì•„ë˜ëŠ” $+\\epsilon$ì„ ì‚¬ìš©í•˜ì˜€ë‹¤. ë…¸ë€ìƒ‰ ìƒìëŠ” ì˜¬ë°”ë¥´ê²Œ ë¶„ë¥˜ëœ ì…ë ¥ì„ ë‚˜íƒ€ë‚¸ë‹¤.í•‘í¬ìƒ‰ ì‹¤ì„ ì€ ì˜¬ë°”ë¥´ê²Œ ë¶„ë¥˜ëœ ë°ì´í„°ì˜ ë¶„í¬ì´ê³ , ë‹¤ë¥¸ ìƒ‰ì˜ ì ì„ ë“¤ì€ íŠ¹ì • í´ë˜ìŠ¤ë¡œ ì˜¤ë¶„ë¥˜í•œ ì ëŒ€ì  ì˜ˆì œë“¤ì˜ ë¶„í¬ì´ë‹¤. ì´ì™¸ì˜ ê³µê°„ì€ ì“°ë ˆê¸° ì…ë ¥ì´ë‹¤.ì„ í˜•ì ì¸ ê´€ì ì—ì„œ ì ëŒ€ì  ì˜ˆì œëŠ” ë„“ì€ ë¶€ë¶„ì§‘í•©ë“¤ ì•ˆì— ë‚˜íƒ€ë‚œë‹¤. ë°©í–¥(direction) $\\eta$ëŠ” ì˜¤ì§ ë¹„ìš© í•¨ìˆ˜ì˜ ê·¸ë ˆë””ì–¸íŠ¸ì™€ì˜ ì–‘ì˜ ë‚´ì ì„ í•„ìš”ë¡œ í•˜ë©°, $\\epsilon$ì€ ì¶©ë¶„í•œ í¬ê¸°ë§Œì´ ìš”êµ¬ëœë‹¤. [ê·¸ë¦¼ 4]ëŠ” ì´ëŸ¬í•œ í˜„ìƒì„ ë³´ì—¬ì¤€ë‹¤. $\\epsilon$ì˜ ë‹¤ì–‘í•œ ê°’ë“¤ì„ ì¶”ì í•¨ìœ¼ë¡œì¨, ì ëŒ€ì  ì˜ˆì œê°€ ë¯¸ì„¸í•œ ì£¼ë¨¸ë‹ˆê°€ ì•„ë‹Œ FGSMìœ¼ë¡œ ì •ì˜ëœ 1-D ë¶€ë¶„ ê³µê°„ì˜ ì—°ì†ì ì¸ ì˜ì—­ì—ì„œ ë°œìƒí•œë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ì´ëŠ” ì ëŒ€ì  ì˜ˆì œê°€ ë¬´ìˆ˜íˆ ë§ìœ¼ë©°, ì™œ í•œ ëª¨ë¸ì´ ì˜¤ë¶„ë¥˜í•œ ì ëŒ€ì  ì˜ˆì œë¥¼ ë‹¤ë¥¸ ëª¨ë¸ì´ ìƒë‹¹íˆ ë†’ì€ í™•ë¥ ë¡œ ì˜¤ë¶„ë¥˜í•˜ëŠ”ì§€ë¥¼ ë³´ì—¬ì¤€ë‹¤.ì™œ ë‹¤ì¤‘ ë¶„ë¥˜ê¸°ë“¤ì´ ì ëŒ€ì  ì˜ˆì œë“¤ì„ ê°™ì€ í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜í•˜ëŠ”ì§€ë¥¼ ì„¤ëª…í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” í˜„ì¬ì˜ ë°©ë²•ë¡ ìœ¼ë¡œ í›ˆë ¨ëœ ëª¨ë“  ì‹ ê²½ë§ì´ ë™ì¼í•œ í›ˆë ¨ ì„¸íŠ¸ì—ì„œ í•™ìŠµëœ ì„ í˜• ë¶„ë¥˜ê¸°ì™€ ìœ ì‚¬í•˜ë‹¤ëŠ” ê°€ì •ì„ í–ˆë‹¤. ê¸°ê³„ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì´ generalizeí•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì—, ì´ ë¶„ë¥˜ê¸°ëŠ” í›ˆë ¨ ì„¸íŠ¸ì˜ ë‹¤ë¥¸ ë¶€ë¶„ì§‘í•©ì— ëŒ€í•´ì„œ í›ˆë ¨í•˜ì—¬ë„ ê±°ì˜ ë™ì¼í•œ ë¶„ë¥˜ ê°€ì¤‘ì¹˜ë¥¼ í•™ìŠµ í•  ìˆ˜ ìˆë‹¤. ì´ëŸ¬í•œ ë¶„ë¥˜ê¸° ê°€ì¤‘ì¹˜ì˜ ì•ˆì •ì„±ì€ ì ëŒ€ì  ì˜ˆì œì˜ ì•ˆì •ì„± ë˜í•œ ì´ˆë˜í•œë‹¤.ì´ëŸ° ê°€ì •ì„ ì‹œí—˜í•´ ë³´ê¸°ìœ„í•´, ìš°ë¦¬ëŠ” ì‹¬ì¸µ maxout networkì—ì„œ ì ëŒ€ì  ì˜ˆì œë“¤ì„ ìƒì„±í•˜ì˜€ê³ , ì´ ì˜ˆì œë“¤ì„ ì–•ì€ softmax networkì™€ ì–•ì€ RBF networkë¡œ ë¶„ë¥˜í•˜ì˜€ë‹¤. maxout networkê°€ ì˜¤ë¶„ë¥˜í•œ ì˜ˆì œë“¤ì—ì„œ, RBF networkëŠ” maxount networkê°€ ì˜ˆì¸¡í•œ í´ë˜ìŠ¤ë‘ 16%ë§Œí¼ ì¼ì¹˜í•œ ë°˜ë©´, softmax networkëŠ” 54.6%ê°€ ì¼ì¹˜í•˜ì˜€ë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ìˆ˜ì¹˜ëŠ” ëª¨ë¸ë§ˆë‹¤ ë‹¤ë¥¸ ì—ëŸ¬ìœ¨ì— ì˜í•´ í¬ê²Œ ì¢Œìš°ëœë‹¤. ë¹„êµë˜ëŠ” ë‘ ëª¨ë¸ì´ ì˜¤ë¶„ë¥˜í•˜ëŠ” ì‚¬ë¡€ë“¤ì— ì£¼ì˜ë¥¼ ê¸°ìš¸ì´ì§€ ì•Šìœ¼ë©´, softmax regressionì€ maxoutì´ ì˜ˆì¸¡í•œ í´ë˜ìŠ¤ë‘ 84.6%ì¼ì¹˜í•˜ëŠ” ë°˜ë©´, RBF networkëŠ” maxoutì´ ì˜ˆì¸¡í•œ í´ë˜ìŠ¤ë‘ ì˜¤ì§ 54.3%ë§Œì´ ì¼ì¹˜í–ˆë‹¤. ë¹„êµë¥¼ ìœ„í•´ì„œ, RBF networkëŠ” softmax regressionì˜ í´ë˜ìŠ¤ë¥¼ 53.6% ì˜ˆì¸¡í•  ìˆ˜ ìˆì—ˆë‹¤. ë”°ë¼ì„œ ì´ëŠ” ë™ì‘ ì†ì— ê°•í•œ ì„ í˜• êµ¬ì„±ìš”ì†Œë¥¼ ê°€ì§€ê³  ìˆë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤. ìš°ë¦¬ì˜ ê°€ì„¤ì€ maxout networkì˜ ì˜¤ë¶„ë¥˜ í˜¹ì€ generalize across models í•˜ëŠ” ì˜¤ë¶„ë¥˜ì— ëŒ€í•´ ëª¨ë“  ê²ƒì„ ì„¤ëª…í•˜ì§€ ì•ŠëŠ”ë‹¤. ê·¸ëŸ¬ë‚˜ ì´ ì¤‘ ìƒë‹¹í•œ ë¹„ìœ¨ì€, cross-model generalizationì˜ ì£¼ ì›ì¸ì´ ë˜ëŠ” ì„ í˜•ì  í–‰ë™ê³¼ ì¼ì¹˜í•œë‹¤.9 ë‹¤ë¥¸ ê°€ì„¤ì— ëŒ€í•œ ë°˜ë°•ì—¬ê¸°ì„œëŠ” ì ëŒ€ì  ì˜ˆì œì˜ ì¡´ì¬ì— ëŒ€í•œ ì¼ë¶€ ëŒ€ì•ˆ ê°€ì„¤ì„ ê³ ë ¤í•˜ê³  ë°˜ë°•í•  ê²ƒì´ë‹¤.ì²«ì§¸ë¡œ, generative trainingì´ í›ˆë ¨ ê³¼ì •ì—ì„œ ë”ìš± ë§ì€ ì œì•½ì„ ì¤„ ìˆ˜ ìˆë‹¤ê±°ë‚˜, ëª¨ë¸ì´ ê°€ì§œ ë°ì´í„°ì—ì„œ ì§„ì§œë¥¼ êµ¬ë³„í•˜ëŠ” ê²ƒì„ í•™ìŠµí•˜ëŠ” ê²ƒì„ ê°€ëŠ¥í•˜ê²Œí•˜ë©° ì§„ì§œ ë°ì´í„°ì—ì„œë§Œ ë†’ì€ ì‹ ë¢°ë„ë¥¼ ê°€ì§ˆ ìˆ˜ ìˆê²Œ í•œë‹¤ëŠ” ê°€ì„¤ì´ë‹¤. The MP-DPM(Goodfellow et al,. 2013a)ì— ì´ ê°€ì„¤ì„ ì‹œí—˜í•  ìˆ˜ ìˆëŠ” ì¢‹ì€ ëª¨ë¸ì´ ìˆë‹¤. ì´ ëª¨ë¸ì˜ ì¶”ë¡  ê³¼ì •ì€ ë¯¸ë¶„ê°€ëŠ¥í•˜ë©°, MNIST ë°ì´í„°ì…‹ì—ì„œ ì¢‹ì€ ë¶„ë¥˜ ì •í™•ë„ë¥¼ ì–»ëŠ”ë‹¤. (ì—ëŸ¬ìœ¨ 0.88%) ì¶”ë¡  ê³¼ì •ì´ ë¯¸ë¶„ ë¶ˆê°€ëŠ¥í•œ ë‹¤ë¥¸ ëª¨ë¸ì€ ì ëŒ€ì  ì˜ˆì œë¥¼ ê³„ì‚°í•˜ê¸° í˜ë“¤ê±°ë‚˜, MNIST ë°ì´í„°ì…‹ì—ì„œ ì¢‹ì€ ë¶„ë¥˜ ì •í™•ë„ë¥¼ ì–»ê¸° ìœ„í•´ ë³„ë„ì˜ non-generative discriminator ëª¨ë¸ì„ í•„ìš”ë¡œ í•œë‹¤. MP-DPMì˜ ì‚¬ë¡€ì—ì„œëŠ” generative ëª¨ë¸ ìì²´ê°€ ìœ„ì— ìˆëŠ” non-generative ë¶„ë¥˜ê¸° ëª¨ë¸ë³´ë‹¤ ì ëŒ€ì ì¸ ì˜ˆì— ë°˜ì‘í•˜ê³  ìˆë‹¤ëŠ” ê²ƒì„ í™•ì‹ í•  ìˆ˜ ìˆë‹¤. ìš°ë¦¬ëŠ” ì´ ëª¨ë¸ì´ ì ëŒ€ì  ì˜ˆì œì— ì·¨ì•½í•˜ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆë‹¤. $\\epsilon=0.25$ì¼ ë•Œ, MNIST í…ŒìŠ¤íŠ¸ ì…‹ì—ì„œ ìƒì„±ëœ ì ëŒ€ì  ì˜ˆì œì˜ ì—ëŸ¬ìœ¨ì€ 97.5%ì˜€ë‹¤. ë‹¤ë¥¸ í˜•íƒœì˜ generative í›ˆë ¨ì´ ë‚´ì„±ì„ ê°€ì§ˆ ìˆ˜ ìˆê²Œ í•œë‹¤ëŠ” ê²ƒì€ ì—¬ì „íˆ ê°€ëŠ¥í•˜ì§€ë§Œ, generatvieë¼ëŠ” ì‚¬ì‹¤ë§Œìœ¼ë¡œëŠ” ë¶„ëª…íˆ ì¶©ë¶„í•˜ì§€ëŠ” ì•Šë‹¤.ì ëŒ€ì  ì˜ˆì œì˜ ì¡´ì¬ì— ëŒ€í•œ ë‹¤ë¥¸ ê°€ì„¤ì€ ê°œë³„ ëª¨ë¸ì´ ê¸°ë³µì´ ìˆì„ì§€ë¼ë„ ì—¬ëŸ¬ ëª¨ë¸ì„ í‰ê· í™”í•˜ë©´ ì ëŒ€ì  ì‚¬ë¡€ë¥¼ ê·¹ë³µí•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤. ì´ ê°€ì„¤ì„ ì‹œí—˜í•´ë³´ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” MNIST ë°ì´í„°ì…‹ì—ì„œ 20ê°œì˜ maxout networkë¥¼ í›ˆë ¨ì‹œì¼œ ë³´ì•˜ë‹¤. ê°ê°ì˜ networkëŠ” ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”, drop out mask ìƒì„±, stochastic gradient descentë¥¼ ìœ„í•œ ë¯¸ë‹ˆë°°ì¹˜ ì„ íƒì„ ìœ„í•´ ì„œë¡œ ë‹¤ë¥¸ ë‚œìˆ˜ ìƒì„± seedë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤. ì´ ì•™ìƒë¸”ì€ ì „ì²´ë¥¼ êµë€ì‹œí‚¤ë„ë¡ ì„¤ê³„ëœ $\\epsilon=0.25$ì˜ ì ëŒ€ì  ì˜ˆì œë“¤ì—ì„œ 91.1%ì˜ ì—ëŸ¬ìœ¨ì„ ë³´ì˜€ë‹¤. ì˜¤ì§ í•˜ë‚˜ì˜ ê°œë³„ ëª¨ë¸ì„ êµë€ì‹œí‚¤ë„ë¡ ë§Œë“¤ì–´ì§„ ì ëŒ€ì  ì˜ˆì œì—ì„œëŠ” ì—ëŸ¬ìœ¨ì€ 87.9%ë¡œ ë–¨ì–´ì§„ë‹¤. ë”°ë¼ì„œ, ì•™ìƒë¸”ì€ ì ëŒ€ì  êµë€ì— ëŒ€í•´ ë‹¨ì§€ ì œí•œì ì¸ ì €í•­ë§Œì„ ì œê³µí•œë‹¤.10 ìš”ì•½ê³¼ ê²°ë¡ ë³¸ ë¬¸ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê´€ì°°ë¡œ ìš”ì•½í•  ìˆ˜ ìˆë‹¤. ì ëŒ€ì  ì˜ˆì œëŠ” ê³ ì°¨ì› ë‚´ì ì˜ ì„±ì§ˆë¡œ ì„¤ëª…ë  ìˆ˜ ìˆë‹¤. ì´ëŠ” ëª¨ë¸ì˜ ë¹„ì„ í˜•ì„± ë•Œë¬¸ì´ ì•„ë‹ˆë¼, ì„ í˜•ì„±ì˜ ì˜í•œ ê²°ê³¼ì´ë‹¤. ì„œë¡œ ë‹¤ë¥¸ ëª¨ë¸ë“¤ì—ì„œ ì ëŒ€ì  ì˜ˆì œë“¤ì´ ì¼ë°˜í™”ë˜ëŠ” ì ì€ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ ë²¡í„°ì˜ ë†’ì€ ê²½í–¥ìœ¼ë¡œ ì„¤ëª…ëœë‹¤. ì„œë¡œ ë‹¤ë¥¸ ëª¨ë¸ì¼ì§€ë¼ë„ ë™ì¼í•œ ì‘ì—…ì„ ìœ„í•´ í›ˆë ¨ë˜ì—ˆë‹¤ë©´ ìœ ì‚¬í•œ í•¨ìˆ˜ë¥¼ í•™ìŠµí•œë‹¤. ê³µê°„ì˜ íŠ¹ì • ì§€ì ë³´ë‹¤ëŠ” êµë€ì˜ ë°©í–¥ì´ ì¤‘ìš”í•œë‹¤. ê³µê°„ì€ ì ëŒ€ì  ì˜ˆì œë¡œ ê°€ë“ì°¨ ìˆëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ìœ ë¦¬ìˆ˜ì²˜ëŸ¼ ì‹¤ìˆ˜ë¥¼ ë¯¸ì„¸í•˜ê²Œ íƒ€ì¼ë§í•œë‹¤. êµë€ì˜ ë°©í–¥ì´ ì¤‘ìš”í•˜ê¸° ë•Œë¬¸ì—, ì ëŒ€ì  êµë€ì€ ì„œë¡œ ë‹¤ë¥¸ í´-ë¦°í•œ ì…ë ¥ì—ì„œ ì¼ë°˜í™”ë  ìˆ˜ ìˆë‹¤. ì ëŒ€ì  ì˜ˆì œë¥¼ ìƒì„±í•˜ëŠ” ë¹ ë¥¸ ë°©ë²•ë“¤ì˜ ì¢…ë¥˜ë“¤ì„ ì†Œê°œí–ˆë‹¤. ì ëŒ€ì  í›ˆë ¨ì´ drop out ë³´ë‹¤ ë”ìš± ì •ê·œí™”ë¥¼ ìˆ˜í–‰í•œë‹¤ëŠ” ê²ƒì„ ì…ì¦í–ˆë‹¤. ìš°ë¦¬ëŠ” $L^1$ weight decayì™€ ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒì„ í¬í•¨í•œ ë‹¨ìˆœí•˜ì§€ë§Œ ëœ íš¨ìœ¨ì ì¸ regularizeë¡œ ì œì–´ ì‹¤í—˜ì„ í•˜ì—¬, ì´ë“¤ë¡œëŠ” ì ëŒ€ì  í›ˆë ¨ì˜ ì •ê·œí™”ë¥¼ ë”°ë¼ì¡ì„ ìˆ˜ ì—†ë‹¤ëŠ” ê²ƒì„ ë³´ì˜€ë‹¤. ìµœì í™”í•˜ê¸° ì‰¬ìš´ ëª¨ë¸ì€ êµë€í•˜ê¸°ë„ ì‰½ë‹¤. ì„ í˜• ëª¨ë¸ì€ ì ëŒ€ì  êµë€ì— ì €í•­í•  ëŠ¥ë ¥ì´ ë¶€ì¡±í•˜ë‹¤. hidden layerë¥¼ ì‚¬ìš©í•œ êµ¬ì¡° (the approximateor theoremì´ ì ìš©ëœ)ë§Œì´ ì ëŒ€ì  êµë€ì— ëŒ€í•œ ë‚´ì„±ì„ í•™ìŠµí•  ìˆ˜ ìˆë‹¤. RBF networkëŠ” ì ëŒ€ì  ì˜ˆì œì— ë‚´ì„±ì´ë‹¤. ì…ë ¥ì˜ ë¶„í¬ë¥¼ ëª¨ë¸ë§í•˜ë„ë¡ í›ˆë ¨ëœ ëª¨ë¸ì€ ì ëŒ€ì  ì˜ˆì œì— ì €í•­ í•  ìˆ˜ ì—†ë‹¤. ì•™ìƒë¸”ë¡œëŠ” ì ëŒ€ì  ì˜ˆì œì— ì €í•­ í•  ìˆ˜ ì—†ë‹¤.rubbish class ì˜ˆì œì™€ ê°™ì€ ì¼ë¶€ ì¶”ê°€ ê´€ì°° ì‚¬í•­ì€ ë¶€ë¡ì— ìˆ˜ë¡í•˜ì˜€ë‹¤. rubbish class ì˜ˆì œëŠ” ì–´ë””ì—ë‚˜ ìˆê³  ì‰½ê²Œ ë§Œë“¤ ìˆ˜ ìˆë‹¤. ì–•ì€ ì„ í˜• ëª¨ë¸ì€ ì´ëŸ° rubbish classì—ë„ ì €í•­ í•  ìˆ˜ ì—†ë‹¤. RBF networkëŠ” rubbish classì— ì €í•­í•  ìˆ˜ ìˆë‹¤.Gradient-based optimizationì€ ëª¨-ë˜ AIì˜ ì£¼ë¥˜ì´ë‹¤. ì¶©ë¶„íˆ ì„ í˜•ì ìœ¼ë¡œ ì„¤ê³„ëœ network(ReLU, maxout network, LSTM, sigmoid network that has been carefully configured not to saturate too much)ëŠ” ìš°ë¦¬ê°€ ì‹ ê²½ì“°ëŠ” ê±°ì˜ ëŒ€ë¶€ë¶„ì˜ ë¬¸ì œì— ëŒ€í•´ì„œ, ìµœì†Œí•œ í›ˆë ¨ì…‹ì—ì„œ ì í•©í•  ìˆ˜ ìˆê²Œ í•˜ì˜€ë‹¤. ì ëŒ€ì  ì˜ˆì œì˜ ì¡´ì¬ëŠ” ë°ì´í„°ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆê±°ë‚˜, í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì˜¬ë°”ë¥´ê²Œ ë¶„ë¥˜í•˜ëŠ” ê²ƒì´ ê·¸ë ‡ê²Œ ë™ì‘í•˜ë„ë¡ ìš”êµ¬í•œ ì‘ì—…ì„ ì§„ì •ìœ¼ë¡œ ì´í•´í•˜ê³  ìˆì§€ ì•Šë‹¤ëŠ” ê²ƒì„ ì‹œì‚¬í•œë‹¤. ëŒ€ì‹  ê·¸ë“¤ì˜ ì„ í˜•ì ì¸ ë°˜ì‘ì€ ë°ì´í„° ë¶„í¬ì—ì„œ ë‚˜íƒ€ë‚˜ì§€ ì•ŠëŠ” ì§€ì ì—ì„œ ê³¼ë„í•œ ì‹ ë¢°ë„ë¥¼ ë³´ì˜€ê³ , ì´ ì‹ ë¢°ë„ì˜ ì˜ˆì¸¡ì€ ì¢…ì¢… ë†’ì€ ë¶€ì •í™•ë„ë¥¼ ë³´ì¸ë‹¤. ë³¸ ì—°êµ¬ëŠ” ì´ ë¬¸ì œë¥¼ ë¬¸ì œì ì„ ëª…í™•í•˜ê²Œ ì§€ì í•˜ê³  ê° ë¬¸ì œë¥¼ ìˆ˜ì •í•¨ìœ¼ë¡œì¨ ë¶€ë¶„ì ìœ¼ë¡œ í•´ê²°í•˜ì˜€ë‹¤. ê·¸ëŸ¬ë‚˜ ì–´ë–¤ ì´ëŠ” ìš°ë¦¬ê°€ ì§€ê¸ˆê» ì‚¬ìš©í•œ ëª¨ë¸ë“¤ì´ ë³¸ì§ˆì ìœ¼ë¡œ ê²°í•¨ì´ ìˆë‹¤ê³  ê²°ë¡  ë‚¼ ìˆ˜ë„ ìˆë‹¤. ìµœì í™”ì˜ ìš©ì´ì„±ì€ ì´ëŸ¬í•œ ê²°í•¨ìœ¼ë¡œ ëŒ€ê°€ë¥¼ ì¹˜ë¥´ê³  ìˆë‹¤. ì´ëŠ” êµ­ì†Œì ìœ¼ë¡œ ì•ˆì •ì ì¸ ë™ì‘ì„ í•˜ëŠ” ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¬ ìˆ˜ ìˆëŠ” ìµœì í™” ê³¼ì •ì˜ ê°œë°œì— ë™ê¸°ë¶€ì—¬ë¥¼ í•œë‹¤." }, { "title": "4 ë¹… ë°ì´í„° - ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… vs XGBoost", "url": "/posts/gb-vs-xgb/", "categories": "XGB FOR GRADIENT BOOSTING, GRADIENT BOOSTING", "tags": "gradient boosting, XGBoost", "date": "2022-06-02 19:03:00 +0900", "snippet": "í˜„ì‹¤ ì„¸ê³„ì˜ ë°ì´í„°ì…‹ì€ ë§¤ìš° ê±°ëŒ€í•˜ë©° ìˆ˜ì¡° ê°œì˜ ë°ì´í„° í¬ì¸íŠ¸ë¡œ ì´ë£¨ì–´ì§ˆ ìˆ˜ ìˆë‹¤. ì»´í“¨í„° í•œ ëŒ€ì˜ ìì›ì€ ì œì•½ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— í•œ ëŒ€ì˜ ì»´í“¨í„°ë¡œë§Œ ì‘ì—…í•˜ëŠ” ê²ƒì€ ë‹¨ì ì´ ë  ìˆ˜ ìˆë‹¤. ë¹… ë°ì´í„°ë¥¼ ë‹¤ë£° ë•Œ ì¢…ì¢… ë³‘ë ¬ ì»´í“¨íŒ…ìœ¼ í™œìš©í•˜ë ¤ê³  í´ë¼ìš°ë“œë¥¼ ì‚¬ìš©í•œë‹¤.ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ì€ ê³„ì‚°ì˜ í•œê³„ë¥¼ ë„˜ì–´ì„¤ ë•Œê°€ ìˆë‹¤. ì§€ê¸ˆê¹Œì§€ ì‚¬ìš©í•œ ë°ì´í„°ì…‹ì€ ìˆ˜ë§Œ ê°œì˜ í–‰ê³¼ ìˆ˜ ë°±ê°œ ì´í•˜ì˜ ì—´ë¡œ ì´ë£¨ì–´ì ¸ ìˆë‹¤. ì‹¤í–‰ì‹œê°„ì´ ì˜¤ë˜ê±¸ë¦¬ì§€ ì•Šì•„ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì§€ ì•Šì„ ê²ƒì´ë‹¤.ì´ë²ˆì—ëŠ” ì™¸ê»˜ í–‰ì„± ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•  ê²ƒì´ë‹¤. ì´ ë°ì´í„°ì…‹ì€ 5087ê°œì˜ í–‰ê³¼ 3189ê°œì˜ ì—´ë¡œ êµ¬ì„±ëœë‹¤. ë³„ì˜ ìƒëª… ì£¼ê¸° ë™ì•ˆì— ë¹›ì˜ ë°ê¸°ë¥¼ ê¸°ë¡í•œ ê²ƒì´ë‹¤. í–‰ê³¼ ì—´ì˜ ê°œìˆ˜ë¥¼ ê³±í•˜ë©´ 1500ë§Œ ë°ì´í„° í¬ì¸íŠ¸ê°€ ëœë‹¤. 100ê°œì˜ íŠ¸ë¦¬ë¥¼ ì‚¬ìš©í•œë‹¤ë©´ ëª¨ë¸ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•´ 15ì–µê°œ ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ì²˜ë¦¬í•´ì•¼ í•œë‹¤.4.1 ì™¸ê³„ í–‰ì„± ë°ì´í„°ì…‹ ì†Œê°œì™¸ê³„ í–‰ì„± ë°ì´í„°ì…‹ì€ 2017ë…„ ìºê¸€ì— ì†Œê°œëœ ë°ì´í„°ì…‹ì´ë‹¤. ì´ ë°ì´í„°ì…‹ì—ëŠ” ë³„ì˜ ë°ê¸°ì— ëŒ€í•œ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤. ê° í–‰ì€ í•˜ë‚˜ì˜ ë³„ì— ëŒ€í•œ ì •ë³´ë¥¼ ë‚˜íƒ€ë‚´ë©° ê° ì—´ì€ ì‹œê°„ì— ë”°ë¼ ë°ê¸°ì˜ ë³€í™”ë¥¼ ì €ì¥í•˜ê³  ìˆë‹¤. ë°ê¸° ì™¸ì—ë„ LABEL ì—´ì—ëŠ” ë³„ì´ ì™¸ê³„ í–‰ì„±ì„ ê°€ì§€ê³  ìˆìœ¼ë©´ 2 ì•„ë‹ˆë©´ 1ë¡œ ë ˆì´ë¸”ë˜ì–´ ìˆë‹¤.ì´ ë°ì´í„°ì…‹ì€ ìˆ˜ì²œ ê°œì˜ ë³„ì˜ ë°ê¸°ë¥¼ ë‹´ê³  ìˆë‹¤. ë³„ì˜ ë°ê¸°(light flux)ëŠ” ì¢…ì¢… ê´‘ì†(luminous flux)ì´ë¼ê³ ë„ ë¶€ë¥´ë©° ê°ì§€ëœ ë³„ì˜ ë°ê¸°ì´ë‹¤.ë³„ì˜ ë°ê¸°ê°€ ì£¼ê¸°ì ìœ¼ë¡œ ë‹¬ë¼ì§ˆ ë•Œ ì™¸ê³„ í–‰ì„±ì´ ì´ ë³„ì„ ê³µì „í•˜ê³  ìˆì„ ê°€ëŠ¥ì„±ì´ ìˆë‹¤. ì™¸ê³„ í–‰ì„±ì´ ë³„ì˜ ì•ì„ ì§€ë‚˜ê°ˆ ë•Œ ë¹›ì˜ ì¼ë¶€ë¶„ì„ ê°€ë¦¬ê³  ì´ë¡œ ì¸í•´ ë³„ì˜ ë°ê¸°ê°€ ì•½ê°„ ê°ì†Œëœë‹¤ê³  ê°€ì •í•œ ê²ƒì´ë‹¤.ì™¸ê³„ í–‰ì„± ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³  ë¨¸ì‹ ëŸ¬ë‹ ì‘ì—…ì„ ìœ„í•´ ì „ì²˜ë¦¬ í•´ë³´ì.4.2 GB vs XGBë°ì´í„° ì „ì²˜ë¦¬import pandas as pddf = pd.read_csv('./exoTrain.csv')from sklearn.model_selection import train_test_splitX = df.iloc[:, 1:]y = df.iloc[:, 0]X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)ì†ë„ ë¹„êµimport time# ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŠ¸ ëª¨ë¸# ì‹œì‘ ì‹œê°„ ì €ì¥start = time.time()gbr = GradientBoostingClassifier(n_estimators=100, max_depth=2, random_state=2)gbr.fit(X_train, y_train)y_pred = gbr.predict(X_test)score = accuracy_score(y_pred, y_test)print(f'accuracy: {score}')# ì¢…ë£Œ ì‹œê°„ ì €ì¥end = time.time()print(f'runtime: {end-start} sec')accuracy: 0.9874213836477987runtime: 294.03440713882446 sec# XGBoost ëª¨ë¸# ì‹œì‘ ì‹œê°„ ì €ì¥start = time.time()xg_reg = XGBClassifier(n_estimators=100, max_depth=2)xg_reg.fit(X_train, y_train)y_pred = xg_reg.predict(X_test)score = accuracy_score(y_pred, y_test)print(f'accuracy: {score}')# ì¢…ë£Œ ì‹œê°„ ì €ì¥end = time.time()print(f'runtime: {end-start} sec')accuracy: 0.9913522012578616runtime: 53.40976548194885 secì½”ë© ê¸°ì¤€ XGBoostê°€ ëŒ€ëµ 3ë°° ì •ë„ ë¹ ë¥´ë‹¤. ë˜í•œ 0.5%ë” ì •í™•í•˜ë‹¤.(Imbalaced dataë¼ ì˜ë¯¸ì—†ìŒ)" }, { "title": "3 ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹", "url": "/posts/gb-hptunning/", "categories": "XGB FOR GRADIENT BOOSTING, GRADIENT BOOSTING", "tags": "gradient boosting", "date": "2022-06-02 19:02:00 +0900", "snippet": "ì´ë²ˆì—ëŠ” ê°€ì¥ ì¤‘ìš”í•œ ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…ì˜ ë§¤ê°œë³€ìˆ˜ì¸ learning_rateê³¼ ëª¨ë¸ì˜ íŠ¸ë¦¬ ê°œìˆ˜ ë˜ëŠ” ë°˜ë³µì¸ n_estimatorsì— ì´ˆì ì„ ë§ì¶œ ê²ƒì´ë‹¤.ë˜í•œí™•ë¥ ì  ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…(stochastic gradient boosting)ì„ ë§Œë“œëŠ” subsample ë§¤ê°œë³€ìˆ˜ë„ ì•Œì•„ë³¼ ê²ƒì´ë‹¤.ê·¸ë¦¬ê³  RandomizedSearchCVë¥¼ í†µí•´ XGBoostì™€ ê²°ê³¼ë¥¼ ë¹„êµí•´ë³´ê² ë‹¤.3.1 Learning_rateì´ì „ì— GradientBoostingRegressorì˜ learning_rate ë§¤ê°œë³€ìˆ˜ ê°’ì„ 1.0ì—ì„œ ì‚¬ì´í‚·ëŸ° ê¸°ë³¸ê°’ì¸ 0.1ë¡œ ë°”ê¾¸ì–´ì„œ ì„±ëŠ¥ì„ í¬ê²Œ ë†’ì˜€ì—ˆë‹¤.learning_rateì€ ëª¨ë¸ êµ¬ì¶•ì— ë„ˆë¬´ í° ì˜í–¥ì„ ë¼ì¹˜ì§€ ì•Šë„ë¡ ê°œë³„ íŠ¸ë¦¬ì˜ ê¸°ì—¬ë¥¼ ì¤„ì¸ë‹¤.ì´ë¥¼ì¶•ì†Œ(shrinkage)ë¼ê³ ë„ ë¶€ë¥¸ë‹¤.ì´ ë§¤ê°œë³€ìˆ˜ë¥¼ ì£¼ì˜ ê¹Šê²Œ ì¡°ì •í•˜ì§€ ì•Šê³  ê¸°ë³¸ í•™ìŠµê¸°ì˜ ì˜¤ì°¨ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì „ì²´ ì•™ìƒë¸”ì„ ë§Œë“¤ë©´ ëª¨ë¸ì— ì²˜ìŒ ì¶”ê°€ëœ íŠ¸ë¦¬ì˜ ì˜í–¥ì´ ë„ˆë¬´ í¬ê²Œ ëœë‹¤.learning_rateì€ ê°œë³„ íŠ¸ë¦¬ì˜ ì˜í–¥ì„ ì œí•œí•œë‹¤. ì¼ë°˜ì ìœ¼ë¡œ íŠ¸ë¦¬ì˜ ê°œìˆ˜ì¸ n_estimatorsë¥¼ ëŠ˜ë¦¬ë©´ learning_rateì€ ì¤„ì—¬ì•¼ í•œë‹¤.ìµœì ì˜ learning_rate ê°’ì„ ê²°ì •í•˜ëŠ” ê²ƒì€ n_estimatorsì— ë”°ë¼ ë‹¤ë¥´ë‹¤. ë¨¼ì € n_estimatorsë¥¼ ê³ ì •í•˜ê³  learning_rateì˜ íš¨ê³¼ë¥¼ í™•ì¸í•´ë³´ì. learning_rateì„ 0ì—ì„œ 1ê¹Œì§€ ë°”ê¾¸ì–´ë³´ì. learning_rate=1ì´ë©´ íŠ¸ë¦¬ ê²°ê³¼ì— ì–´ë– í•œ ì¡°ì •ë„ í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ì˜ë¯¸ì´ë‹¤. ê¸°ë³¸ê°’ 0.1ì€ íŠ¸ë¦¬ì˜ ì˜í–¥ì„ 10%ë¡œ ì¤„ì¸ë‹¤ëŠ” ë§ì´ë‹¤.learning_rate_values = [.001, .01, .05, .1, .15, .2, .3, .5, 1.0]for value in learning_rate_values: gbr = GradientBoostingRegressor(max_depth=2, n_estimators=300, random_state=2, learning_rate=value) gbr.fit(X_train, y_train) y_pred = gbr.predict(X_test) rmse = MSE(y_test, y_pred)**.5 print(f'lr: {value}, RMSE: {rmse}')lr: 0.001, RMSE: 1633.0261400367258lr: 0.01, RMSE: 831.5430182728547lr: 0.05, RMSE: 685.0192988749717lr: 0.1, RMSE: 653.7456840231495lr: 0.15, RMSE: 687.666134269379lr: 0.2, RMSE: 664.312804425697lr: 0.3, RMSE: 689.4190385930236lr: 0.5, RMSE: 693.8856905068778lr: 1.0, RMSE: 936.3617413678853ì¶œë ¥ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ ê¸°ë³¸ learning_rate ê°’ 0.1ì´ 300ê°œì˜ íŠ¸ë¦¬ì—ì„œ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚¸ë‹¤.ì´ë²ˆì—ëŠ” n_estimatorsë¥¼ ë°”ê¾¸ì–´ ë³´ì. ìœ„ì˜ ì½”ë“œì—ì„œ n_estimatorsë¥¼ 30, 300, 3000ìœ¼ë¡œ ë°”ê¾¸ê³  learning_rateì— ëŒ€í•œ RMSE ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.ê²°ê³¼ì—ì„œ ë³´ë“¯ì´ 30ê°œ íŠ¸ë¦¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° learning_rate=0.3 ê·¼ì²˜ì¼ ë•Œ ìµœìƒì˜ ì„±ëŠ¥ì„ ë‚¸ë‹¤.300ê°œì˜ íŠ¸ë¦¬ë¥¼ ì‚¬ìš©í•  ë•Œ ê·¸ë˜í”„ë¥¼ ê·¸ë ¤ë³´ì.learning_rate=0.1ì¼ ë•Œ ìµœì†Œì„ì´ ì˜ ë‚˜íƒ€ë‚œë‹¤.ì´ì œ 3000ê°œì˜ íŠ¸ë¦¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° learning_rate ê·¸ë˜í”„ë¥¼ ê·¸ë ¤ë³´ì.3000ê°œ íŠ¸ë¦¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° learning_rateì´ 0.01ì¼ ë•Œ ìµœìƒì˜ ì ìˆ˜ë¥¼ ë‚¸ë‹¤.ì´ ê·¸ë˜í”„ë“¤ì€learning_rateê³¼ n_estimator ë§¤ê°œë³€ìˆ˜ë¥¼ í•¨ê»˜ íŠœë‹í•´ì•¼ í•œë‹¤ëŠ” ì ì„ ì•Œë ¤ì¤€ë‹¤.3.2 ê¸°ë³¸ í•™ìŠµê¸°ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…ì˜ íšŒê·€ ëª¨ë¸ì˜ ê¸°ë³¸í•™ìŠµê¸°ëŠ”ê²°ì •íŠ¸ë¦¬ì´ë‹¤. ì´ ê²°ì • íŠ¸ë¦¬ë¥¼ ë¯¸ì„¸ íŠœë‹í•  í•„ìš”ëŠ” ì—†ì§€ë§Œ ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ë§¤ê°œë³€ìˆ˜ë¥¼ ì¡°ì • í•  ìˆ˜ ìˆë‹¤.ì˜ˆë¥¼ ë“¤ì–´, ë‹¤ìŒì²˜ëŸ¼ max_depthë¥¼ 1,2,3,4ë¡œ ë°”ê¾¸ë©´ì„œ ê²°ê³¼ë¥¼ ë¹„êµí•´ ë³¼ ìˆ˜ ìˆë‹¤.depths = [None, 1, 2, 3, 4]for depth in depths: gbr = GradientBoostingRegressor(max_depth=depth, n_estimators=300, random_state=2) gbr.fit(X_train, y_train) y_pred = gbr.predict(X_test) rmse = MSE(y_test, y_pred)**.5 print(f'max depth: {depth}, RMSE: {rmse}')max depth: None, RMSE: 869.2788645118395max depth: 1, RMSE: 707.8261886858736max depth: 2, RMSE: 653.7456840231495max depth: 3, RMSE: 646.4045923317708max depth: 4, RMSE: 663.048387855927max_depth=3ì¼ ë•Œ ìµœìƒì˜ ê²°ê³¼ë¥¼ ë‚¸ë‹¤.3.3 Subsamplesubsample ë§¤ê°œë³€ìˆ˜ëŠ” ê¸°ë³¸ í•™ìŠµê¸°ì— ì‚¬ìš©ë  ìƒ˜í”Œì˜ ë¹„ìœ¨ì„ ì§€ì •í•œë‹¤. subsampleì„ ê¸°ë³¸ê°’ì¸ 1.0ë³´ë‹¤ ì‘ê²Œ ì„¤ì •í•˜ë©´ íŠ¸ë¦¬ë¥¼ í›ˆë ¨í•  ë•Œ ìƒ˜í”Œì˜ ì¼ë¶€ë§Œ ì‚¬ìš©í•˜ê²Œ ëœë‹¤. ì˜ˆë¥¼ ë“¤ì–´ subsample=0.8ì¸ ê²½ìš° 80%ì˜ í›ˆë ¨ ì„¸íŠ¸ë§Œ ì‚¬ìš©í•˜ì—¬ ê° íŠ¸ë¦¬ë¥¼ í›ˆë ¨í•œë‹¤.max_depth=3ìœ¼ë¡œ ì§€ì •í•˜ê³  subsampleì— ë”°ë¼ ì ìˆ˜ ë³€í™”ë¥¼ í™•ì¸í•´ë³´ì.samples = [1, .9, .8, .7, .6, .5]for sample in samples: gbr = GradientBoostingRegressor(max_depth=3, n_estimators=300, subsample=sample, random_state=2) gbr.fit(X_train, y_train) y_pred = gbr.predict(X_test) rmse = MSE(y_test, y_pred)**.5 print(f'subsample: {sample}, RMSE: {rmse}')subsample: 1, RMSE: 646.4045923317708subsample: 0.9, RMSE: 620.1819001443569subsample: 0.8, RMSE: 617.2355650565677subsample: 0.7, RMSE: 612.9879156983139subsample: 0.6, RMSE: 622.6385116402317subsample: 0.5, RMSE: 626.9974073227554300ê°œ íŠ¸ë¦¬, ìµœëŒ€ê¹Šì´ 3ì¼ ë•Œ subsample=.7ì—ì„œ ê°€ì¥ ì¢‹ì€ ì ìˆ˜ë¥¼ ëƒˆë‹¤.subsampleì´ 1ë³´ë‹¤ ì‘ì„ ë•Œ ì´ëŸ° ëª¨ë¸ì„í™•ë¥ ì  ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…ì´ë¼ê³  ë¶€ë¥¸ë‹¤. í™•ë¥ ì ì´ë¼ëŠ” ë§ì€ ëª¨ë¸ì— ë¬´ì‘ìœ„ì„±ì´ ì£¼ì…ëœë‹¤ëŠ” ë§ì´ë‹¤.3.4 RandomizedSearchCVì˜ ë™ì‘í•˜ëŠ” ëª¨ë¸ì„ ì–»ì—ˆì§€ë§Œ ê·¸ë¦¬ë“œ ì„œì¹˜ë¥¼ ìˆ˜í–‰í•˜ì§€ ì•Šì•˜ë‹¤. ì•ì„  ëª¨ë¸ì„ ì°¸ê³ í–ˆì„ ë•Œ max_depth=3, subsample=.7, n_estimators=300, learning_rate=.1 ê·¼ì²˜ê°€ ê·¸ë¦¬ë“œ ì„œì¹˜ë¡œ íƒìƒ‰í•˜ê¸° ì¢‹ì€ ì¶œë°œì ì´ë‹¤. n_estimatorsëŠ” ë†’ì´ê³  learning_rateëŠ” ë‚®ì¶”ëŠ” ê²ƒì´ ì¢‹ì„ ê²ƒ ê°™ë‹¤.params = { 'subsample': [.65, .7, .75], 'n_estimators': [300, 500, 1000], 'learning_rate': [.05, .075, .1]}from sklearn.model_selection import RandomizedSearchCVgbr = GradientBoostingRegressor(max_depth=3, random_state=2)rand_reg = RandomizedSearchCV(gbr, params, n_iter=10, scoring='neg_mean_squared_error', cv=5, n_jobs=-1, random_state=2)rand_reg.fit(X_train, y_train)best_model = rand_reg.best_estimator_best_params = rand_reg.best_params_print(f'best params: {best_params}')best_score = np.sqrt(-rand_reg.best_score_)print(f'train score: {best_score:.3f}')y_pred = best_model.predict(X_test)rmse_test = MSE(y_test, y_pred)**.5print(f'test score: {rmse_test:.3f}')best params: {â€˜subsampleâ€™: 0.65, â€˜n_estimatorsâ€™: 300, â€˜learning_rateâ€™: 0.05}train score: 636.200test score: 625.985ì´ ë§¤ê°œë³€ìˆ˜ì—ì„œ í•œê°œ ì”© í˜¹ì€ ì—¬ëŸ¬ ê°œë¥¼ ë°”ê¿”ì„œ ì‹¤í—˜í•´ë³¼ ìˆ˜ ìˆë‹¤. n_estimators=300ì´ ìµœìƒì˜ ëª¨ë¸ì´ì§€ë§Œ learning_rateë¥¼ ì¡°ì •í•˜ê³  n_estimatorsë¥¼ ì¦ê°€ì‹œì¼œ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤. subsamplesë„ ì‹¤í—˜í•´ë³¼ ìˆ˜ ìˆë‹¤.ëª‡ ë²ˆì˜ ì‹¤í—˜ì„ ë°˜ë³µí•œ í›„ì— ë‹¤ìŒ ê²°ê³¼ë¥¼ ì–»ì—ˆë‹¤.gbr = GradientBoostingRegressor(max_depth=3, n_estimators=1600, subsample=.75, learning_rate=.02, random_state=2)gbr.fit(X_train, y_train)y_pred = gbr.predict(X_test)rmse = MSE(y_test, y_pred)**.5print(f'RMSE: {rmse}')RMSE: 596.9544588974487n_estimatorsë¥¼ 1600ìœ¼ë¡œ í¬ê²Œ ëŠ˜ë¦¬ê³ , learning_rateë¥¼ .02ë¡œ ì¤„ì˜€ë‹¤. ê·¸ ë‹¤ìŒ ì´ì „ê³¼ ë¹„ìŠ·í•œ subsample=.75ì™€ max_depth=3ìœ¼ë¡œ í•˜ì—¬ 597ì˜ RMSEë¥¼ ì–»ì—ˆë‹¤.ì´ì œ XGBoostê°€ ìœ„ì— ì–¸ê¸‰í–ˆë˜ ë§¤ê°œë³€ìˆ˜ì—ì„œ ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…ê³¼ ì–´ë–»ê²Œ ë‹¤ë¥¸ì§€ í™•ì¸í•´ë³´ì.3.5 XGBoostXGBoostì˜ ì¼ë°˜ì ì¸ êµ¬ì¡°ëŠ” ë™ì¼í•œ ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…ì˜ ê³ ê¸‰ë²„ì „ì´ë‹¤. ì¦‰ ì”ì°¨ë¡œë¶€í„° í›ˆë ¨í•œ íŠ¸ë¦¬ë¥¼ ì¶”ê°€í•˜ì—¬ ì•½í•œ í•™ìŠµê¸°ë¥¼ ê°•ë ¥í•œ í•™ìŠµê¸°ë¡œ ë°”ê¾¼ë‹¤.ì´ì „ì— ì†Œê°œí•œ ë§¤ê°œë³€ìˆ˜ì™€ ë‹¤ë¥¸ ê²ƒì€ learning_rateìœ¼ë¡œ XGBoostì—ì„œëŠ” etaì´ë‹¤.ë™ì¼í•œ ë§¤ê°œë³€ìˆ˜ë¡œ XGBoost íšŒê·€ ëª¨ë¸ì„ ë§Œë“¤ì–´ë³´ê³  ê²°ê³¼ë¥¼ ë¹„êµí•´ë³´ì.ë‹¤ìŒì²˜ëŸ¼ xgboost íŒ¨í‚¤ì§€ì—ì„œ XGBRegressorë¥¼ ì„í¬íŠ¸í•˜ê³ , ëª¨ë¸ì„ ì´ˆê¸°í™”í•˜ê³  í›ˆë ¨í•œ ë‹¤ìŒ ì ìˆ˜ë¥¼ ê³„ì‚°í•œë‹¤.from xgboost import XGBRegressorxg_reg = XGBRegressor(max_depth=3, n_estimators=1600, subsample=.75, eta=.02, random_state=2)xg_reg.fit(X_train, y_train)y_pred = xg_reg.predict(X_test)print(MSE(y_test, y_pred)**.5)584.3395337495713ì ìˆ˜ê°€ ë” ì¢‹ë‹¤. ë” ì¢‹ì€ ì ìˆ˜ê°€ ë‚˜ì˜¨ ì´ìœ ëŠ” ë‹¤ìŒì— ìì„¸íˆ ì•Œì•„ë³¼ ê²ƒì´ë‹¤.ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ë§Œë“¤ ë•Œ ì„±ëŠ¥ê³¼ ì†ë„ëŠ” ê°€ì¥ ì¤‘ìš”í•œ ë‘ê°€ì§€ ìš”ì†Œì´ë‹¤. XGBoostê°€ ë§¤ìš° ì„±ëŠ¥ì´ ë†’ë‹¤ëŠ” ê²ƒì„ ì—¬ëŸ¬ ë²ˆ ë³´ì•˜ë‹¤. XGBoostê°€ ì¼ë°˜ì ìœ¼ë¡œ ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…ë³´ë‹¤ ì„ í˜¸ë˜ëŠ” ì´ìœ ëŠ” ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ê³  ë” ë¹ ë¥´ê¸° ë•Œë¬¸ì´ë‹¤." }, { "title": "2 ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… êµ¬í˜„", "url": "/posts/make-gbmodel/", "categories": "XGB FOR GRADIENT BOOSTING, GRADIENT BOOSTING", "tags": "gradient boosting", "date": "2022-06-02 19:01:00 +0900", "snippet": "ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…ì˜ ì‘ë™ ë°©ì‹ì„ ì‚´í´ë³´ê³  ì´ì „ íŠ¸ë¦¬ì˜ ì˜¤ì°¨ì— ìƒˆë¡œìš´ íŠ¸ë¦¬ë¥¼ í›ˆë ¨í•˜ëŠ” ì‹ìœ¼ë¡œ ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ëª¨ë¸ì„ ë§Œë“¤ì–´ë³¸ë‹¤. ì—¬ê¸°ì„œ ìˆ˜í•™ì ì¸ í•µì‹¬ ìš”ì†ŒëŠ” ì”ì°¨(residual)ì´ë‹¤. ê·¸ ë‹¤ìŒ ì‚¬ì´í‚·-ëŸ°ì˜ ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ëª¨ë¸ì„ ì‚¬ìš©í•´ ë™ì¼í•œ ê²°ê³¼ë¥¼ êµ¬í•´ë³¼ ê²ƒì´ë‹¤.2.1 ì”ì°¨ (Residual)ì”ì°¨ëŠ” íƒ€ê¹ƒê³¼ ëª¨ë¸ì˜ ì˜ˆì¸¡ ì‚¬ì´ì˜ ì°¨ì´ì´ë‹¤. í†µê³„ì—ì„œëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì„ í˜• íšŒê·€ ëª¨ë¸ì´ ë°ì´í„°ì— ì–¼ë§ˆë‚˜ ì˜ë§ëŠ”ì§€ í‰ê°€í•˜ê¸° ìœ„í•´ ì”ì°¨ë¥¼ ì‚¬ìš©í•œë‹¤.ë‹¤ìŒê³¼ ê°™ì€ ì˜ˆë¥¼ ìƒê°í•˜ì. ìì „ê±° ëŒ€ì—¬ ì˜ˆì¸¡: 759 íƒ€ê¹ƒ: 799 ì”ì°¨: 799 - 759 = 40 ì†Œë“ ì˜ˆì¸¡: 100,000 íƒ€ê¹ƒ: 88,000 ì”ì°¨: 88,000 - 100,000 = -12,000 ì—¬ê¸°ì„œ ë³´ë“¯ì´ ì”ì°¨ëŠ” ëª¨ë¸ ì˜ˆì¸¡ì´ ì •ë‹µì—ì„œ ì–¼ë§ˆë‚˜ ë–¨ì–´ì ¸ ìˆëŠ”ì§€ ì•Œë ¤ì£¼ë©° ì–‘ìˆ˜ ë˜ëŠ” ìŒìˆ˜ì¼ ìˆ˜ ìˆë‹¤.ë‹¤ìŒì€ ì„ í˜• íšŒê·€ ëª¨ë¸ì˜ ì”ì°¨ë¥¼ ì•Œë ¤ì£¼ëŠ” ê·¸ë¦¼ì´ë‹¤.ì„ í˜• íšŒê·€ì˜ ëª©ì ì€ ì”ì°¨ì˜ ì œê³±ì„ ìµœì†Œí™”í•˜ëŠ” ê²ƒì´ë‹¤. ê·¸ë¦¼ì— ë‚˜ì™€ ìˆë“¯ì´ ì”ì°¨ëŠ” ì„ í˜• íšŒê·€ ì§ì„ ì´ ë°ì´í„°ì— ì–¼ë§ˆë‚˜ ì˜ ë§ëŠ”ì§€ ë³´ì—¬ì¤€ë‹¤. í†µê³„í•™ì—ì„œ ì¢…ì¢… ë°ì´í„°ì— ëŒ€í•œ í†µì°°ì„ ì–»ê¸° ìœ„í•´ ì”ì°¨ë¥¼ ê·¸ë˜í”„ë¡œ ì‹œê°í™”í•˜ì—¬ ì„ í˜• íšŒê·€ ë¶„ì„ì„ ìˆ˜í–‰í•œë‹¤.ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ì•Œê³ ë¦¬ì¦˜ì„ ì§ì ‘ êµ¬í˜„í•´ë³´ê¸° ìœ„í•´ ê° íŠ¸ë¦¬ì˜ ì”ì°¨ë¥¼ ê³„ì‚°í•˜ê³  ì´ ì”ì°¨ì— ìƒˆë¡œìš´ ëª¨ë¸ì„ í›ˆë ¨í•´ë³´ì.2.2 ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ëª¨ë¸ êµ¬í˜„ëª¨ë¸ì„ ì§ì ‘ êµ¬í˜„í•´ë³´ë©´ ì‘ë™ë°©ì‹ì„ ì˜ ì´í•´í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤. ëª¨ë¸ì„ ë§Œë“¤ê¸° ì „ì— ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ê³  ëª¨ë¸ì— ì£¼ì…í•  ìˆ˜ ìˆë„ë¡ ì „ì²˜ë¦¬ í•´ì¤€ë‹¤.ìì „ê±° ëŒ€ì—¬ ë°ì´í„°ì…‹ ë¡œë“œimport pandas as pdimport numpy as npimport warningswarnings.filterwarnings('ignore')import xgboost as xgbxgb.set_config(verbosity=0) # ë¡œê·¸ ì œê±°df_bikes = pd.read_csv('./bike_rentals_cleaned.csv')X_bikes = df_bikes.iloc[:, :-1]y_bikes = df_bikes.iloc[:, -1]from sklearn.model_selection import train_test_splitX_train, X_test, y_train, y_test = train_test_split(X_bikes, y_bikes, random_state=2)ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ëª¨ë¸ êµ¬í˜„1. ê²°ì • íŠ¸ë¦¬ í›ˆë ¨max_depth=1ì¸ ê²°ì •íŠ¸ë¦¬ ìŠ¤í…€í”„ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ max_depth=2 or 3ì¸ ê²°ì •íŠ¸ë¦¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. ê¸°ë³¸í•™ìŠµê¸°ë¼ ë¶€ë¥´ëŠ” ê²°ì •íŠ¸ë¦¬ëŠ” ë†’ì€ ì •í™•ë„ë¥¼ ìœ„í•´ íŠœë‹í•˜ì§€ ì•ŠëŠ”ë‹¤. ê¸°ë³¸ í•™ìŠµê¸°ì— í¬ê²Œ ì˜ì¡´í•˜ëŠ” ëª¨ë¸ì´ ì•„ë‹ˆë¼ ì˜¤ì°¨ì—ì„œ í•™ìŠµí•˜ëŠ” ëª¨ë¸ì„ ì›í•˜ê¸° ë•Œë¬¸ì´ë‹¤. ì•™ìƒë¸”ì˜ ì²«ë²ˆì§¸ì¸ tree_1ì„ max_depth=2ë¡œ ê²°ì •íŠ¸ë¦¬ë¥¼ ì´ˆê¸°í™”í•˜ê³  í›ˆë ¨ ì„¸íŠ¸ì—ì„œ í›ˆë ¨í•œë‹¤.from sklearn.tree import DecisionTreeRegressorimport matplotlib.pyplot as pltfrom sklearn.tree import plot_treetree_1 = DecisionTreeRegressor(max_depth=2, random_state=2)tree_1.fit(X_train, y_train)# ê¸°ë³¸í•™ìŠµê¸° í”Œë¡œíŒ…plt.figure(figsize=(13, 8))plot_tree(tree_1, feature_names=list(X_train.columns), filled=True, rounded=True, fontsize=10)plt.show()2. í›ˆë ¨ ì„¸íŠ¸ì— ëŒ€í•œ ì˜ˆì¸¡í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ê°€ ì•„ë‹ˆë¼ í›ˆë ¨ ì„¸íŠ¸ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ë§Œë“ ë‹¤. ì”ì°¨ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ì„œ í›ˆë ¨ ë‹¨ê³„ì—ì„œ ì˜ˆì¸¡ê³¼ íƒ€ê¹ƒì„ ë¹„êµí•´ì•¼ í•˜ê¸° ë•Œë¬¸ì´ë‹¤. ëª¨ë¸ì˜ í…ŒìŠ¤íŠ¸ ë‹¨ê³„ëŠ” ëª¨ë“  íŠ¸ë¦¬ë¥¼ êµ¬ì„±í•œ í›„ ë§ˆì§€ë§‰ì— ì˜¨ë‹¤. tree_1ì˜ predict() ë©”ì†Œë“œì— X_trainì„ ì…ë ¥í•˜ì—¬ ì²« ë²ˆì§¸ ë°˜ë³µì— ëŒ€í•œ í›ˆë ¨ ì„¸íŠ¸ ì˜ˆì¸¡ì„ ë§Œë“ ë‹¤.y_train_pred = tree_1.predict(X_train)3. ì”ì°¨ ê³„ì‚°ì˜ˆì¸¡ê³¼ íƒ€ê¹ƒì‚¬ì´ì˜ ì°¨ì´ë¥¼ êµ¬í•œë‹¤.# ì”ì°¨ëŠ” ë‹¤ìŒ íŠ¸ë¦¬ì˜ íƒ€ê¹ƒì´ ë˜ê¸° ë•Œë¬¸ì— y2_trainì´ë¼ê³  ëª…ëª…í•¨y2_train = y_train - y_train_pred4. ìƒˆë¡œìš´ íŠ¸ë¦¬ í›ˆë ¨ìƒˆë¡œìš´ íŠ¸ë¦¬ëŠ” ì´ ì”ì°¨ë¥¼ ë§ì¶”ëŠ” ê²ƒì„ ëª©ì ìœ¼ë¡œ í›ˆë ¨í•œë‹¤.ì”ì°¨ì—ì„œ íŠ¸ë¦¬ë¥¼ í›ˆë ¨í•˜ëŠ” ê²ƒì€ í›ˆë ¨ ì„¸íŠ¸ì—ì„œ í›ˆë ¨í•˜ëŠ” ê²ƒê³¼ ë‹¤ë¥´ë‹¤. ì£¼ìš”í•œ ì°¨ì´ëŠ” ì˜ˆì¸¡ê°’ì´ë‹¤. ìì „ê±° ëŒ€ì—¬ ë°ì´í„°ì…‹ì—ì„œ ì”ì°¨ì— ìƒˆë¡œìš´ íŠ¸ë¦¬ë¥¼ í›ˆë ¨í•  ë•Œ ì ì  ë” ì‘ì€ ê°’ì„ ì–»ì„ ê²ƒì´ë‹¤. ìƒˆë¡œìš´ íŠ¸ë¦¬ë¥¼ ì´ˆê¸°í™”í•˜ê³  X_trainê³¼ ì”ì°¨ì¸ y2_trainì—ì„œ í›ˆë ¨í•œë‹¤.tree_2 = DecisionTreeRegressor(max_depth=2, random_state=2)tree_2.fit(X_train, y2_train)5. 2~4 ë‹¨ê³„ ë°˜ë³µì´ ê³¼ì •ì´ ì§€ì†ë˜ë©´ ì”ì°¨ëŠ” ì–‘ìˆ˜ë‚˜ ìŒìˆ˜ ë°©í–¥ìœ¼ë¡œ 0ì— ê°€ê¹Œì›Œ ì§„ë‹¤. ì–‘ìƒë¸”ì— ì¶”ê°€í•  íŠ¸ë¦¬ ê°œìˆ˜ ë§Œí¼ ë°˜ë³µì´ ê³„ì†ëœë‹¤. ì„¸ë²ˆì§¸ íŠ¸ë¦¬ì—ì„œ ì´ ê³¼ì •ì„ ë°˜ë³µí•´ ë³¼ ê²ƒì´ë‹¤.y2_train_pred = tree_2.predict(X_train)y3_train = y2_train - y2_train_predtree_3 = DecisionTreeRegressor(max_depth=2, random_state=2)tree_3.fit(X_train, y3_train)ì´ ê³¼ì •ì´ ìˆ˜ì‹­, ìˆ˜ë°±, ìˆ˜ì²œê°œì˜ íŠ¸ë¦¬ê¹Œì§€ ê³„ì†ë  ìˆ˜ ìˆë‹¤. ì¼ë°˜ì ì¸ ìƒí™©ì´ë¼ë©´ ê³„ì† ì§„í–‰í•  ê²ƒì´ë‹¤. ì•½í•œ í•™ìŠµê¸°ë¥¼ ê°•ë ¥í•œ í•™ìŠµê¸°ë¡œ ë§Œë“œë ¤ë©´ ëª‡ ê°œ íŠ¸ë¦¬ë¡œëŠ” ë¶€ì¡±í•˜ë‹¤. ì—¬ê¸°ì„œ ëª©ì ì€ ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…ì˜ ì‘ë™ë°©ì‹ì„ ì´í•´í•˜ëŠ” ê²ƒì´ê¸° ë•Œë¬´ì— ì¼ë°˜ì ì¸ ê°œë…ì„ ë‹¤ë£¬ ê²ƒì— ë§Œì¡±í•˜ê³  ë‹¤ìŒìœ¼ë¡œ ë„˜ì–´ê°€ì.6. ê²°ê³¼ ë”í•˜ê¸°ë‹¤ìŒ ì²˜ëŸ¼ ìµœì¢… ê²°ê³¼ë¥¼ ìœ„í•´ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ëŒ€í•œ ê° ì˜ˆì¸¡ì„ ë§Œë“ ë‹¤.y1_pred = tree_1.predict(X_test)y2_pred = tree_2.predict(X_test)y3_pred = tree_3.predict(X_test)ê° ì˜ˆì¸¡ì˜ ì”ì°¨ëŠ” ì–‘ìˆ˜ì™€ ìŒìˆ˜ê°€ ë’¤ì„ì—¬ ìˆê¸° ë•Œë¬¸ì— ì´ ì˜ˆì¸¡ì„ ëª¨ë‘ ë”í•˜ë©´ íƒ€ê¹ƒì— ê°€ê¹Œìš´ ê²°ê³¼ë¥¼ ë§Œë“¤ì–´ ë‚¼ ìˆ˜ ìˆë‹¤.\\[R_i = R_{i+1}+y_{i+1}, \\quad where \\quadR_0=y_{true}\\]7. í‰ê°€ë§ˆì§€ë§‰ìœ¼ë¡œ ë‹¤ìŒì²˜ëŸ¼ í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨ (MSE)ë¥¼ ê³„ì‚°í•œë‹¤.from sklearn.metrics import mean_squared_error as MSEMSE(y_test, y_pred)**.5911.0479538776444ê°•ë ¥í•˜ì§€ ì•Šì€ ì•½í•œ í•™ìŠµê¸°ë¥¼ ì‚¬ìš©í•œ ê²ƒ ì¹˜ê³¤ ë‚˜ì˜ì§€ ì•Šë‹¤. ì´ì œ ì‚¬ì´í‚·-ëŸ°ì„ ì‚¬ìš©í•´ ë™ì¼í•œ ê²°ê³¼ë¥¼ ë§Œë“¤ì–´ë³´ì.2.3 ì‚¬ì´í‚·ëŸ°ì˜ ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ëª¨ë¸ì‚¬ì´í‚·ëŸ°ì˜ GradientBoostingRegressorë¥¼ ì‚¬ìš©í•´ ì´ì „ê³¼ ë™ì¼í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆëŠ” ì§€ í™•ì¸í•´ë³´ì. ì´ë¥¼ ìœ„í•´ ëª‡ ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ì¡°ì •í•  ê²ƒì´ë‹¤. GradientBoostingRegressorë¥¼ ì‚¬ìš©í•˜ë©´ ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ì•Œê³ ë¦¬ì¦˜ì„ í›¨ì”¬ ì‰½ê³  ë¹ ë¥´ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.from sklearn.ensemble import GradientBoostingRegressorgbr = GradientBoostingRegressor(max_depth=2, n_estimators=3, random_state=2, learning_rate=1.0)gbr.fit(X_train, y_train)y_pred = gbr.predict(X_test)MSE(y_test, y_pred)**.5911.0479538776439ì´ ê²°ê³¼ëŠ” ì†Œìˆ˜ì  11ìë¦¬ê¹Œì§€ ëª¨ë‘ ê°™ë‹¤! ì´ì œ ë°˜ë³µíšŸìˆ˜ë¥¼ ì ì  ëŠ˜ë ¤ë³¼ ê²ƒì´ë‹¤.gbr = GradientBoostingRegressor(max_depth=2, n_estimators=30, random_state=2, learning_rate=1.0)gbr.fit(X_train, y_train)y_pred = gbr.predict(X_test)MSE(y_test, y_pred)**.5857.1072323426944ì ìˆ˜ê°€ í–¥ìƒë˜ì—ˆë‹¤. ì´ë²ˆì—ëŠ” 300ê°œë¡œ ëŠ˜ë ¤ë³´ì.gbr = GradientBoostingRegressor(max_depth=2, n_estimators=300, random_state=2, learning_rate=1.0)gbr.fit(X_train, y_train)y_pred = gbr.predict(X_test)print(MSE(y_test, y_pred)**.5)936.3617413678853ì˜¤ì‰? ì ìˆ˜ê°€ ë‚˜ë¹ ì¡Œë‹¤. learning_rateì„ ì œê±°í•˜ê³  ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•´ë³´ì.gbr = GradientBoostingRegressor(max_depth=2, n_estimators=300, random_state=2)gbr.fit(X_train, y_train)y_pred = gbr.predict(X_test)print(MSE(y_test, y_pred)**.5)653.7456840231495ì˜¤â€¦ ì‚¬ì´í‚·-ëŸ°ì˜ learning_rateê¸°ë³¸ê°’ì„ ì‚¬ìš©í•´ ì ìˆ˜ë¥¼ 936ì—ì„œ 654ë¡œ ë‚®ì¶”ì—ˆë‹¤.ë‹¤ìŒì—ëŠ” learning_rate ë§¤ê°œë³€ìˆ˜ì— ì´ˆì ì„ ë§ì¶”ë©´ì„œ ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…ì˜ ë‹¤ë¥¸ ë§¤ê°œë³€ìˆ˜ì— ëŒ€í•´ ì•Œì•„ë³´ë„ë¡ í•˜ì." }, { "title": "1 ë°°ê¹…ì—ì„œ ë¶€ìŠ¤íŒ…ê¹Œì§€", "url": "/posts/bagtoboost/", "categories": "XGB FOR GRADIENT BOOSTING, GRADIENT BOOSTING", "tags": "gradient boosting, bagging", "date": "2022-06-02 19:00:00 +0900", "snippet": "ëœë¤ í¬ë ˆìŠ¤íŠ¸ ê°™ì€ ì•™ìƒë¸” ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì´ ë§ì€ ëª¨ë¸ì„ í•˜ë‚˜ë¡œ ì—°ê²°í•˜ì—¬ ë” ë‚˜ì€ ì˜ˆì¸¡ì„ ë§Œë“œëŠ” ì´ìœ ë¥¼ ì•Œê³ ìˆë‹¤.ëœë¤ í¬ë ˆìŠ¤íŠ¸ëŠ” (ê²°ì • íŠ¸ë¦¬ì—ì„œ)ë¶€íŠ¸ ìŠ¤íŠ¸ë© ìƒ˜í”Œì„ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì—ë°°ê¹…ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ë¶„ë¥˜ëœë‹¤.ì´ì™€ ë‹¬ë¦¬ë¶€ìŠ¤íŒ…ì€ ê°œë³„ íŠ¸ë¦¬ì˜ ì‹¤ìˆ˜ë¡œë¶€í„° í•™ìŠµí•œë‹¤.ì´ì „ íŠ¸ë¦¬ì˜ ì˜¤ì°¨ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ íŠ¸ë¦¬ë¥¼ í›ˆë ¨í•˜ëŠ” ê²ƒì´ ê¸°ë³¸ì ì¸ ì•„ì´ë””ì–´ì´ë‹¤.ë¶€ìŠ¤íŒ…ì—ì„œ ê¸°ì¡´ íŠ¸ë¦¬ì— ëŒ€í•œ ì˜¤ì°¨ë¥¼ ìˆ˜ì •í•˜ëŠ” ê²ƒì€ ë°°ê¹…ê³¼ ë‹¤ë¥¸ ì ‘ê·¼ ë°©ë²•ì´ë‹¤.ë°°ê¹… ëª¨ë¸ì—ì„œëŠ” ìƒˆë¡œìš´ íŠ¸ë¦¬ê°€ ì´ì „ íŠ¸ë¦¬ì— ê´€ì‹¬ì„ ì£¼ì§€ ì•ŠëŠ”ë‹¤.ë˜í•œ ìƒˆë¡œìš´ íŠ¸ë¦¬ëŠ” ë¶€íŠ¸ìŠ¤íŠ¸ë© ìƒ˜í”Œë§ì„ ì‚¬ìš©í•´ ì²˜ìŒë¶€í„° í›ˆë ¨ë˜ë©° ìµœì¢… ëª¨ë¸ì€ ëª¨ë“  ê°œë³„ íŠ¸ë¦¬ì˜ ê²°ê³¼ë¥¼ í•©ì¹œ ê²ƒì´ë‹¤.í•˜ì§€ë§Œ ë¶€ìŠ¤íŒ…ì—ì„œëŠ” ê°œë³„ íŠ¸ë¦¬ê°€ ì´ì „ íŠ¸ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ë‹¤.ë…ë¦½ì ìœ¼ë¡œ íŠ¸ë¦¬ê°€ ë™ì‘í•˜ì§€ ì•Šìœ¼ë©° ë‹¤ë¥¸ íŠ¸ë¦¬ ìœ„ì— ë§Œë“¤ì–´ì§„ë‹¤.1.1 ì—ì´ë‹¤ ë¶€ìŠ¤íŠ¸ì—ì´ë‹¤ ë¶€ìŠ¤íŠ¸ëŠ” ì¸ê¸° ìˆëŠ” ì´ˆê¸° ë¶€ìŠ¤íŒ… ëª¨ë¸ ì¤‘ í•˜ë‚˜ì´ë‹¤.ì—ì´ë‹¤ ë¶€ìŠ¤íŠ¸ì—ì„œëŠ” ìƒˆë¡œìš´ íŠ¸ë¦¬ê°€ ì´ì „ íŠ¸ë¦¬ì˜ ì˜¤ì°¨ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •í•œë‹¤.ì˜¤ë¥˜ ìƒ˜í”Œì˜ ê°€ì¤‘ì¹˜ë¥¼ ë†’ì—¬ ì˜ëª»ëœ ì˜ˆì¸¡ì— ë” ë§ì€ ì£¼ì˜ë¥¼ ê¸°ìš¸ì¸ë‹¤.ì—ì´ë‹¤ ë¶€ìŠ¤íŠ¸ëŠ” ì´ë ‡ê²Œ ì‹¤ìˆ˜ì—ì„œ í•™ìŠµí•˜ê¸° ë•Œë¬¸ì— ì•½í•œ í•™ìŠµê¸°ë¥¼ ê°•ë ¥í•œ í•™ìŠµê¸°ë¡œ ë§Œë“¤ ìˆ˜ ìˆë‹¤.ì•½í•œ í•™ìŠµê¸°ëŠ” ìš°ì—°ë³´ë‹¤ ì¡°ê¸ˆ ë‚˜ì€ ì„±ëŠ¥ì„ ë‚´ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ë§í•œë‹¤.ê°•í•œ í•™ìŠµê¸°ëŠ” ë§ì€ ì–‘ì˜ ë°ì´í„°ì—ì„œ í•™ìŠµí•˜ì—¬ ë§¤ìš° ì˜ ìˆ˜í–‰ë˜ëŠ” ëª¨ë¸ì´ë‹¤.ì•½í•œ í•™ìŠµê¸°ë¥¼ ê°•ë ¥í•œ í•™ìŠµê¸°ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì´ ë¶€ìŠ¤íŒ… ì•Œê³ ë¦¬ì¦˜ì˜ ì¼ë°˜ì ì¸ ì•„ì´ë””ì–´ì´ë‹¤.ì•½í•œ í•™ìŠµê¸°ëŠ” ë¬´ì‘ìœ„ ì˜ˆì¸¡ë³´ë‹¤ ì¡°ê¸ˆ ë‚«ë‹¤.í•˜ì§€ë§Œ ì•½í•œ í•™ìŠµê¸°ë¡œ ì‹œì‘í•˜ëŠ” ë°ëŠ” ëª©ì ì´ ìˆë‹¤.ì¼ë°˜ì ìœ¼ë¡œ ë¶€ìŠ¤íŒ…ì€ ê°•ë ¥í•œ ê¸°ë°˜ ëª¨ë¸ì„ ë§Œë“œëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ë°˜ë³µì ìœ¼ë¡œ ì˜¤ë¥˜ë¥¼ ê³ ì¹˜ëŠ” ë° ì´ˆì ì„ ë‘”ë‹¤.ê¸°ë°˜ ëª¨ë¸ì´ ë„ˆë¬´ ê°•ë ¥í•˜ë©´ í•™ìŠµ ê³¼ì •ì´ ì œí•œë˜ì–´ ë¶€ìŠ¤íŒ… ëª¨ë¸ì˜ ì „ëµì„ ì•½í™”ì‹œí‚¨ë‹¤.ìˆ˜ë°±ë²ˆì˜ ë°˜ë³µì„ í†µí•´ ì•½í•œ í•™ìŠµê¸°ê°€ ê°•ë ¥í•œ í•™ìŠµê¸°ë¡œ ë°”ë€ë‹¤.ì¦‰, ì‘ì€ ì„±ëŠ¥ ê°œì„ ì„ ì˜¤ë˜ ì§€ì†í•œë‹¤.ë¶€ìŠ¤íŒ…ì€ ì§€ë‚œ ìˆ˜ì‹­ë…„ ë™ì•ˆ ìµœì ì˜ ê²°ê³¼ë¥¼ ë§Œë“œëŠ” ì ì—ì„œ ê°€ì¥ ë›°ì–´ë‚œ ë¨¸ì‹ ëŸ¬ë‹ ì „ëµ ì¤‘ í•˜ë‚˜ì´ë‹¤.ì—ì´ë‹¤ ë¶€ìŠ¤íŠ¸ì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…ì€ ìƒëµí•œë‹¤.ì´ì œ ì„±ëŠ¥ë©´ì—ì„œ ì•½ê°„ ë” ë›°ì–´ë‚œ ì—ì´ë‹¤ ë¶€ìŠ¤íŠ¸ì˜ ê°•ë ¥í•œ ëŒ€ì•ˆì¸ ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…ì„ ì•Œì•„ë³´ì.1.2 ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… (gradient boosting) ì˜ íŠ¹ì§•ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…ì€ ì—ì´ë‹¤ ë¶€ìŠ¤íŠ¸ì™€ëŠ” ë‹¤ë¥¸ ì „ëµì„ ì‚¬ìš©í•œë‹¤.ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…ë„ ì˜ëª»ëœ ì˜ˆì¸¡ì„ ê¸°ë°˜ìœ¼ë¡œ ì¡°ì •ë˜ì§€ë§Œ í•œ ë‹¨ê³„ ë” ë‚˜ì•„ê°„ë‹¤.ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…ì€ ì´ì „ íŠ¸ë¦¬ì˜ ì˜ˆì¸¡ ì˜¤ì°¨ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì™„ì „íˆ ìƒˆë¡œìš´ íŠ¸ë¦¬ë¥¼ í›ˆë ¨í•œë‹¤.ì¦‰, ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…ì€ ê° íŠ¸ë¦¬ì˜ ì‹¤ìˆ˜ë¥¼ ì‚´í´ë³´ê³  ì´ëŸ° ì‹¤ìˆ˜ì— ëŒ€í•œ ì™„ì „í•œ ìƒˆë¡œìš´ íŠ¸ë¦¬ë¥¼ ë§Œë“ ë‹¤.ìƒˆë¡œìš´ íŠ¸ë¦¬ëŠ” ì´ì „ íŠ¸ë¦¬ì—ì„œ ì˜¬ë°”ë¥´ê²Œ ì˜ˆì¸¡ëœ ê°’ì—ëŠ” ì˜í–¥ì„ ë°›ì§€ ì•ŠëŠ”ë‹¤.ì˜¤ì°¨ì—ë§Œ ì´ˆì ì„ ë§ì¶”ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì„ ë§Œë“œë ¤ë©´ ì •í™•í•œ ìµœì¢… ì˜ˆì¸¡ì„ ë§Œë“¤ê¸° ìœ„í•´ ì˜¤ì°¨ë¥¼ ê³„ì‚°í•˜ëŠ” ë°©ë²™ì´ í•„ìš”í•˜ë‹¤.ì´ëŸ° ë°©ë²•ì€ ëª¨ë¸ì˜ ì˜ˆì¸¡ê³¼ ì‹¤ì œ ê°’ ì‚¬ì´ì˜ ì°¨ì´ì¸ì”ì°¨ (residual)ë¥¼ í™œìš©í•œë‹¤.ì¼ë°˜ì ì¸ ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…ì€ ê° íŠ¸ë¦¬ ì˜ˆì¸¡ê°’ì„ ë”í•´ ëª¨ë¸ í‰ê°€ì— ì‚¬ìš©í•œë‹¤.ì´ ì•„ì´ë””ì–´ëŠ” ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…ì˜ ê³ ê¸‰ ë²„ì „ì¸ XGBoostì˜ í•µì‹¬ì´ë¯€ë¡œ íŠ¸ë¦¬ì˜ ì˜ˆì¸¡ì„ ê³„ì‚°í•˜ê³  ë”í•˜ëŠ” ê²ƒì„ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤.ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ëª¨ë¸ì„ ì§ì ‘ ë§Œë“¤ì–´ ë³´ë©´ ì˜ˆì¸¡ì„ ê³„ì‚°í•˜ê³  ë”í•˜ëŠ” ê³¼ì •ì„ ì˜ ë³¼ ìˆ˜ ìˆë‹¤.ë‹¤ìŒ ì ˆì—ì„œ ì§ì ‘ ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ëª¨ë¸ì„ ë§Œë“¤ì–´ ë³¼ ê²ƒì´ë‹¤.ë¨¼ì € ê·¸ë ˆë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…ì˜ ì‘ë™ ë°©ì‹ì— ëŒ€í•´ ë°°ì›Œë³´ì." }, { "title": "4 ëœë¤ í¬ë ˆìŠ¤íŠ¸ ì„±ëŠ¥ í–¥ìƒ", "url": "/posts/rfperform/", "categories": "XGB FOR GRADIENT BOOSTING, RANDOM FOREST", "tags": "random forest", "date": "2022-06-02 06:02:00 +0900", "snippet": "ì§€ë‚œë²ˆ ëœë¤ í¬ë ˆìŠ¤íŠ¸ íšŒê·€ ëª¨ë¸ë¡œ ìì „ê±°ì˜ ì¼ë³„ ëŒ€ì—¬ëŸ‰ì„ ì˜ˆì¸¡í•˜ì—¬ RMSE ì ìˆ˜ 945ê°€ ë‚˜ì™”ì—ˆë‹¤. ì´ë²ˆì—ëŠ” í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹ì„ í†µí•˜ì—¬ ê°€ëŠ¥í•œ ë” ë‚®ì€ ì ìˆ˜ë¥¼ ì–»ì–´ë³¼ ê²ƒì´ë‹¤.4.1 ë°ì´í„° ì…‹ ì¤€ë¹„from sklearn.model_selection import train_test_splitX_train, X_test, y_train, y_test = train_test_split(X_bikes, y_bikes, random_state=2)4.2 n_estimatorsí•©ë¦¬ì ì¸ n_estimators ê°’ì„ ì„ íƒí•´ë³´ì. n_estimatorë¥¼ ì¦ê°€ì‹œí‚¤ë©´ ì‹œê°„ê³¼ ë¹„ìš©ì´ ëŠ˜ì–´ë‚˜ì§€ë§Œ ì •í™•ë„ëŠ” í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆë‹¤.from sklearn.metrics import mean_squared_errorrmse_scores = []estimators = []rf = RandomForestRegressor(warm_start=True, n_jobs=-1, random_state=2)est = 10for i in range(21): rf.set_params(n_estimators=est) rf.fit(X_train, y_train) rmse = mean_squared_error(y_test, rf.predict(X_test), squared=False) rmse_scores.append(rmse) estimators.append(est) est += 25plt.figure(figsize=(15, 7))plt.plot(estimators, rmse_scores)plt.xlabel('Number of Trees')plt.ylabel('RMSE')plt.title('Random Forest Bike Rentals', fontsize=15)plt.show()50ê°œ ì–¸ì €ë¦¬ì—ì„œ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë°œíœ˜í•œë‹¤. 100ê°œê°€ ë„˜ì–´ê°€ë©´ ì—ëŸ¬ê°€ ìƒìŠ¹í•˜ê¸° ì‹œì‘í•œë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‚´í´ë³¸ë‹¤.4.3 cross_val_scoreìœ„ ê·¸ë˜í”„ë¥¼ ë³´ë©´ RMSE ë²”ìœ„ê°€ 620ì—ì„œ 690ì‚¬ì´ì´ë‹¤. cross_val_score() í•¨ìˆ˜ë¡œ ì´ ë°ì´í„°ì…‹ì— ëŒ€í•´ êµì°¨ê²€ì¦ì„ í•´ë³´ì. êµì°¨ ê²€ì¦ í•¨ìˆ˜ëŠ” í›ˆë ¨ëœ ëª¨ë¸ì„ ë°˜í™˜í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— oob_score_ë¥¼ í™•ì¸ í•  ìˆ˜ ì—†ë‹¤.rf = RandomForestRegressor(n_estimators=50, warm_start=True, n_jobs=-1, random_state=2)scores = cross_val_score(rf, X_bikes, y_bikes, scoring='neg_mean_squared_error', cv=10)rmse = np.sqrt(-scores)print(f'RMSE:{np.round(rmse, 3)}')print(f'RMSE mean:{rmse.mean():.3f}')RMSE:[ 836.482 541.898 533.086 812.782 894.877 881.117 794.103 828.968772.517 2128.148]RMSE mean:902.398ì´ ì ìˆ˜ëŠ” ì´ì „ë³´ë‹¤ ë” ì¢‹ë‹¤. ê·¸ëŸ¬ë‚˜ RMSE ë§ˆì§€ë§‰ í´ë“œì˜ ì—ëŸ¬ê°€ ë§¤ìš° ë†’ë‹¤. ì´ëŠ” ë°ì´í„°ì— ìˆëŠ” ì˜¤ë¥˜ë‚˜ ì´ìƒì¹˜(outline) ë•Œë¬¸ì¼ ìˆ˜ ìˆë‹¤.4.4 í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì´ì œ RandomizedSearchCVë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ ìˆ˜í–‰í•´ë³´ì.ì•„ë˜ëŠ” ì—¬ëŸ¬ê°€ì§€ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ë„£ê³  ì„±ëŠ¥ì„ ë³´ê¸° ìœ„í•œ í•¨ìˆ˜ì´ë‹¤.from sklearn.model_selection import RandomizedSearchCVfrom sklearn.metrics import mean_squared_error as MSEdef randomized_search_reg(params, runs=16, reg=RandomForestRegressor(random_state=2,n_jobs=-1)): rand_reg = RandomizedSearchCV(reg, params, n_iter=runs, scoring='neg_mean_squared_error', cv=10, n_jobs=-1, random_state=2) rand_reg.fit(X_train, y_train) best_model = rand_reg.best_estimator_ best_params = rand_reg.best_params_ print(f'best parameters: {best_params}') best_score = np.sqrt(-rand_reg.best_score_) print(f'train score: {best_score}') y_pred = best_model.predict(X_test) rmse_test = MSE(y_test, y_pred)**.5 print(f'test score: {rmse_test:.3f}')1íŠ¸ì´ˆê¸° ë§¤ê°œë³€ìˆ˜ ê·¸ë¦¬ë“œë¡œ ìœ„ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•´ ì²«ë²ˆì¨° ê²°ê³¼ë¥¼ í™•ì¸í•œë‹¤%%timeparams = { 'min_weight_fraction_leaf': [0, .0025, .005, .00785, .01, .05], 'min_samples_split': [2, .01, .02, .03, .04, .06, .08, .1], 'min_samples_leaf': [1, 2, 4, 6, 8, 10, 20, 30], 'min_impurity_decrease': [0, .01, .05, .1, .15, .2], 'max_leaf_nodes': [10, 15, 20, 25, 30, 35, 40, 45, 50, None], 'max_features': ['auto', .8, .7, .6, .5, .4], 'max_depth': [None, 2, 4, 6, 8, 10, 20]}randomized_search_reg(params)best parameters: {â€˜min_weight_fraction_leafâ€™: 0, â€˜min_samples_splitâ€™: 0.03, â€˜min_samples_leafâ€™: 6, â€˜min_impurity_decreaseâ€™: 0.05, â€˜max_leaf_nodesâ€™: 25, â€˜max_featuresâ€™: 0.7, â€˜max_depthâ€™: None}train score: 759.0756188493968test score: 701.802CPU times: user 1.1 s, sys: 68.4 ms, total: 1.17 sWall time: 10 s2íŠ¸íƒìƒ‰ë²”ìœ„ë¥¼ ì¢í˜€ë³¸ë‹¤%%timeparams = { 'min_samples_leaf': [1, 2, 4, 6, 8, 10, 20, 30], 'min_impurity_decrease': [0, .01, .05, .1, .15, .2], 'max_features': ['auto', .8, .7, .6, .5, .4], 'max_depth': [None, 2, 4, 6, 8, 10, 20]}randomized_search_reg(params)best parameters: {â€˜min_samples_leafâ€™: 1, â€˜min_impurity_decreaseâ€™: 0.1, â€˜max_featuresâ€™: 0.6, â€˜max_depthâ€™: 10}train score: 679.0520498695299test score: 626.541CPU times: user 1.13 s, sys: 72.7 ms, total: 1.2 sWall time: 10.2 s3íŠ¸íƒìƒ‰íšŸìˆ˜ë¥¼ ëŠ˜ë¦¬ê³  max_depthë¥¼ ë” ëŠ˜ë ¤ë³¸ë‹¤%%timeparams = { 'min_samples_leaf': [1, 2, 4, 6, 8, 10, 20, 30], 'min_impurity_decrease': [0, .01, .05, .1, .15, .2], 'max_features': ['auto', .8, .7, .6, .5, .4], 'max_depth': [None, 4, 6, 8, 10, 12, 15, 20]}randomized_search_reg(params, runs=20)best parameters: {â€˜min_samples_leafâ€™: 1, â€˜min_impurity_decreaseâ€™: 0.1, â€˜max_featuresâ€™: 0.6, â€˜max_depthâ€™: 12}train score: 675.1280049404816test score: 619.014CPU times: user 1.35 s, sys: 84.1 ms, total: 1.44 sWall time: 12.9 s4íŠ¸:ì´ì „ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë²”ìœ„ë¥¼ ë” ì¢í˜€ë³¸ë‹¤%%timeparams = { 'min_samples_leaf': [1, 2, 3, 4, 5, 6], 'min_impurity_decrease': [0, .01, .05, .08, .1, .12, .15], 'max_features': ['auto', .8, .7, .6, .5, .4], 'max_depth': [None, 8, 10, 12, 14, 16, 18, 20]}randomized_search_reg(params)best parameters: {â€˜min_samples_leafâ€™: 1, â€˜min_impurity_decreaseâ€™: 0.05, â€˜max_featuresâ€™: 0.7, â€˜max_depthâ€™: 18}train score: 679.5945071230298test score: 630.954CPU times: user 1.19 s, sys: 77.8 ms, total: 1.27 sWall time: 10.9 sì—ëŸ¬ê°€ ëŠ˜ì–´ë‚¬ìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œ ë©ˆì¶”ê³ , n_estimatorë‚˜ ë” ëŠ˜ë ¤ë³¸ë‹¤.5íŠ¸: ë°ì´í„° ì´ìƒìœ¼ë¡œ ì¸í•œ ì €ì¡°í•œ ì„±ëŠ¥n-estimators ëŠ˜ë ¤ë³´ê¸°%%timeparams = { 'min_samples_leaf': [1, 2, 4, 6, 8, 10, 20, 30], 'min_impurity_decrease': [0, .01, .05, .1, .15, .2], 'max_features': ['auto', .8, .7, .6, .5, .4], 'max_depth': [None, 4, 6, 8, 10, 12, 15, 20], 'n_estimators': [100]}randomized_search_reg(params, runs=20)best parameters: {â€˜n_estimatorsâ€™: 100, â€˜min_samples_leafâ€™: 1, â€˜min_impurity_decreaseâ€™: 0.1, â€˜max_featuresâ€™: 0.6, â€˜max_depthâ€™: 12}train score: 675.1280049404816test score: 619.014CPU times: user 1.34 s, sys: 113 ms, total: 1.45 sWall time: 13.1 së§ˆì§€ë§‰ìœ¼ë¡œ cross_val_score()ë¡œ ê²°ê³¼ë¥¼ í™•ì¸í•´ë³¸ë‹¤.rf = RandomForestRegressor(n_estimators=100, min_impurity_decrease=.1, max_features=.6, max_depth=12, n_jobs=-1, random_state=2)scores = cross_val_score(rf, X_bikes, y_bikes, scoring='neg_mean_squared_error', cv=10)rmse = np.sqrt(-scores)print(f'RMSE:{np.round(rmse, 3)}')print(f'RMSE mean:{rmse.mean():.3f}')RMSE:[ 818.354 514.173 547.392 814.059 769.54 730.025 831.376 794.634756.83 1595.237]RMSE mean:817.162ì˜¤ì‰?!?!? ì ìˆ˜ê°€ ë” ë‚˜ë¹ ì¡Œë‹¤.cross_val_score()ì˜ ë§ˆì§€ë§‰ í´ë“œì˜ ì ìˆ˜ê°€ ë‹¤ë¥¸ ê²ƒë³´ë‹¤ 2ë°° ê°€ëŸ‰ ë†’ê¸° ë•Œë¬¸ì— ë§ˆì§€ë§‰ í´ë“œì— ë¬¸ì œê°€ ìˆë‹¤ê³  ìœ ì¶”í•´ë³¼ ìˆ˜ ìˆë‹¤. ë°ì´í„°ë¥¼ ë‹¤ì‹œ ì„ì–´ì„œ ì‹œë„í•´ë³´ì.from sklearn.utils import shuffledf_shuffle_bikes = shuffle(df_bikes, random_state=2)X_shuffle_bikes = df_shuffle_bikes.iloc[:, :-1]y_shuffle_bikes = df_shuffle_bikes.iloc[:, -1]rf = RandomForestRegressor(n_estimators=100, min_impurity_decrease=.1, max_features=.6, max_depth=12, n_jobs=-1, random_state=2)scores = cross_val_score(rf, X_shuffle_bikes, y_shuffle_bikes, scoring='neg_mean_squared_error', cv=10)rmse = np.sqrt(-scores)print(f'RMSE:{np.round(rmse, 3)}')print(f'RMSE mean:{rmse.mean():.3f}')RMSE:[630.093 686.673 468.159 526.676 593.033 724.575 774.402 672.63 760.253616.797]RMSE mean:645.329ê¸°ëŒ€í•œ ëŒ€ë¡œ ì ìˆ˜ê°€ í›¨ì”¬ ì¢‹ì•„ì¡ŒìŒì„ ì•Œ ìˆ˜ ìˆë‹¤.4.5 ëœë¤ í¬ë ˆìŠ¤íŠ¸ì˜ ë‹¨ì ê²°êµ­ ëœë¤ í¬ë ˆìŠ¤íŠ¸ëŠ” ê°œë³„ íŠ¸ë¦¬ì— ì œì•½ì´ ìˆë‹¤. ëª¨ë“  íŠ¸ë¦¬ê°€ ë™ì¼í•œ ì‹¤ìˆ˜ë¥¼ ì €ì§€ë¥´ë©´ ëœë¤ í¬ë ˆìŠ¤íŠ¸ë„ ì‹¤ìˆ˜ë¥¼ í•œë‹¤. ì•ì˜ ì‚¬ë¡€ì—ì„œ ë°ì´í„°ë¥¼ ì„ê¸° ì „ì— ì´ëŸ° ê²½ìš°ê°€ ìˆìŒì„ ë³´ì•˜ë‹¤. ê°œë³„ íŠ¸ë¦¬ê°€ í•´ê²°í•  ìˆ˜ ì—†ëŠ” ë°ì´í„° ë‚´ì˜ ë¬¸ì œ ë•Œë¬¸ì— ëœë¤ í¬ë ˆìŠ¤íŠ¸ì˜ ì„±ëŠ¥ì´ í–¥ìƒë  ìˆ˜ ì—†ì—ˆë‹¤.ì´ëŸ´ ë•Œ íŠ¸ë¦¬ì˜ ì‹¤ìˆ˜ë¡œë¶€í„° ë°°ì›Œì„œ ì´ˆë°˜ì˜ ë‹¨ì ì„ ê°œì„ í•  ìˆ˜ ìˆëŠ” ì•™ìƒë¸” ë°©ë²•ì´ ë„ì›€ì´ ë  ìˆ˜ ìˆë‹¤. ë¶€ìŠ¤íŒ…ì€ íŠ¸ë¦¬ê°€ ì €ì§€ë¥¼ ì‹¤ìˆ˜ì—ì„œ ë°°ìš°ë„ë¡ ì„¤ê³„ë˜ì—ˆë‹¤." }, { "title": "3 ëœë¤ í¬ë ˆìŠ¤íŠ¸ í•˜ì´í¼ íŒŒë¼ë¯¸í„°", "url": "/posts/randomforesthyperparameter/", "categories": "XGB FOR GRADIENT BOOSTING, RANDOM FOREST", "tags": "random forest", "date": "2022-06-02 06:02:00 +0900", "snippet": "ì´ë¯¸ ë‹¨ì¼ ê²°ì • íŠ¸ë¦¬ì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ì•Œì•„ë³´ì•˜ê¸° ë•Œë¬´ì— ëœë¤ í¬ë ˆìŠ¤íŠ¸ì—ì„œ ë‹¤ë£° ë§¤ê°œë³€ìˆ˜ëŠ” ì•„ì£¼ ë§ì§€ ì•Šë‹¤.ì—¬ê¸°ì„œëŠ” ëœë¤ í¬ë ˆìŠ¤íŠ¸ì— ì¶”ê°€ëœ ë§¤ê°œë³€ìˆ˜ë¥¼ ë¨¼ì € ì‚´í´ë³´ê³  ì´ì „ ì¥ì—ì„œ ë³´ì•˜ë˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ì–´ì„œ ì•Œì•„ë³¼ ê²ƒì´ë‹¤. ì´ëŸ¬í•œ ë§¤ê°œë³€ìˆ˜ëŠ” XGBoostì—ì„œë„ ë§ì´ ì‚¬ìš©ëœë‹¤.3.1 oob_scoreOOBëŠ” Out of bagì˜ ì¤„ì„ë§ì´ë‹¤.ëœë¤ í¬ë ˆìŠ¤íŠ¸ëŠ” ì¤‘ë³µì„ í—ˆìš©í•œ ìƒ˜í”Œë§ì¸ ë°°ê¹…ì„ í†µí•´ ê²°ì • íŠ¸ë¦¬ë¥¼ ë§Œë“¤ê¸° ë•Œë¬¸ì—, ëª¨ë“  ìƒ˜í”Œ ì¤‘ì— ì¼ë¶€ ìƒ˜í”Œì€ ì„ íƒë˜ì§€ ì•Šê³  ë‚¨ì•„ ìˆê²Œ ëœë‹¤.ì´ëŸ° ìƒ˜í”Œì„ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. oob_score=Trueë¡œ ì„¤ì •í•˜ë©´ ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ì„ í›ˆë ¨í•œ í›„ ê° íŠ¸ë¦¬ì—ì„œ ì‚¬ìš©ë˜ì§€ ì•Šì€ ìƒ˜í”Œì„ ì‚¬ìš©í•´ ê°œë³„ íŠ¸ë¦¬ì˜ ì˜ˆì¸¡ ì ìˆ˜ë¥¼ ëˆ„ì í•˜ì—¬ í‰ê· ì„ ë‚¸ë‹¤.ë‹¤ë¥¸ ë§ë¡œ í•˜ë©´ oob_score ë§¤ê°œë³€ìˆ˜ëŠ” í…ŒìŠ¤íŠ¸ ì ìˆ˜ì˜ ëŒ€ì•ˆì„ ì œì‹œí•˜ëŠ” ê²ƒì´ë‹¤. ëª¨ë¸ì„ í›ˆë ¨í•œ í›„ OOBì ìˆ˜ë¥¼ ë°”ë¡œ ì¶œë ¥í•  ìˆ˜ ìˆë‹¤.ì¸êµ¬ ì¡°ì‚¬ ë°ì´í„°ì…‹ì— oob_score ë§¤ê°œë³€ìˆ˜ë¥¼ ì ìš©í•´ë³´ì•˜ë‹¤. oob_score ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•˜ì˜€ê¸° ë•Œë¬¸ì— ì—¬ê¸°ì—ì„œëŠ” í¸ì˜ìƒ ë°ì´í„°ë¥¼ í›ˆë ¨ ì„¸íŠ¸ì™€ ë°ì´í„° ì„¸íŠ¸ë¡œ ë‚˜ëˆ„ì§€ ì•Šì„ ê²ƒì´ë‹¤.rf = RandomForestClassifier(oob_score=True, n_estimators=10, random_state=2, n_jobs=-1)rf.fit(X_census, y_census)print(rf.oob_score_)0.8343109855348423ë°ì´í„° 1ì„ ì‚¬ìš©í•˜ì§€ ì•Šì€ DT = {DT1, DT3, DT6}ë°ì´í„° 1ì˜ ëŒ€í•œ ê°ê°ì˜ì˜ˆì¸¡í™•ë¥ = {DT1: 0.7, DT3: 0.6, DT6: 0.5}ëœë¤ í¬ë ˆìŠ¤íŠ¸ì˜ ìµœì¢… ì—ì¸¡í™•ë¥ : 0.6ìœ„ ê³¼ì •ì„ ë°˜ë³µ â‡’ OOB Score!ê·¸ëŸ¬ë‚˜ ì—¬ê¸°ì—ì„œ ì²˜ëŸ¼ ëœë¤ í¬ë ˆìŠ¤íŠ¸ì˜ ê°œë³„ íŠ¸ë¦¬ ê°œìˆ˜ê°€ ì‘ì„ ê²½ìš° ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ìˆ˜ì§‘í•  OOB ìƒ˜í”Œì˜ ê°œìˆ˜ê°€ ì¶©ë¶„í•˜ì§€ ì•Šë‹¤.ë” ë§ì€ íŠ¸ë¦¬ëŠ” ë” ë§ì€ ìƒ˜í”Œì„ ì˜ë¯¸í•˜ê³  ì¢…ì¢… ì •í™•ë„ë¥¼ ë†’ì¸ë‹¤.3.2 n_estimatorsëœë¤ í¬ë ˆìŠ¤íŠ¸ëŠ”ë§ì€ íŠ¸ë¦¬ë¥¼ ì•™ìƒë¸” í–ˆì„ ë•Œ ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•œë‹¤. ì–¼ë§ˆë‚˜ ë§ì•„ì•¼ í• ê¹Œ? ì‚¬ì´í‚·-ëŸ°==0.22ë¶€í„° n_estimatorì˜ ê¸°ë³¸ê°’ì„ 10ì—ì„œ 100ìœ¼ë¡œ ë³€ê²½í–ˆë‹¤. 100ê°œì˜ íŠ¸ë¦¬ê°€ ë¶„ì‚°ì„ ì¤„ì´ê³  ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ëŠ” ë° ì¶©ë¶„í•  ìˆ˜ ìˆì§€ë§Œ ë°ì´í„°ì…‹ì´ í¬ë©´ 500ê°œ ì´ìƒì˜ íŠ¸ë¦¬ê°€ í•„ìš”í•  ìˆ˜ ìˆë‹¤.n_estimator=50ìœ¼ë¡œ ì§€ì •í•˜ê³  OOBì ìˆ˜ì˜ ë³€í™”ë¥¼ í™•ì¸í•´ë³´ê² ë‹¤.rf = RandomForestClassifier(oob_score=True, n_estimators=50, random_state=2, n_jobs=-1)rf.fit(X_census, y_census)print(rf.oob_score_)0.8518780135745216í™•ì‹¤íˆ ì„±ëŠ¥ì´ í–¥ìƒë˜ì—ˆë‹¤. ê·¸ë ‡ë‹¤ë©´ 100ê°œëŠ” ì–´ë–¨ê¹Œ?rf = RandomForestClassifier(oob_score=True, n_estimators=100, random_state=2, n_jobs=-1)rf.fit(X_census, y_census)print(rf.oob_score_)0.8551334418476091ì¡°ê¸ˆ í–¥ìƒë˜ì—ˆë‹¤. n_estimatorë¥¼ ê³„ì† ì¦ê°€ì‹œí‚¤ë©´ OOBì ìˆ˜ëŠ” ê²°êµ­ ì¼ì •í•œ ìˆ˜ì¤€ì„ ìœ ì§€í•  ê²ƒì´ë‹¤.3.3 warm_startwarm_start ë§¤ê°œë³€ìˆ˜ëŠ” ëœë¤ í¬ë ˆìŠ¤íŠ¸ì˜ íŠ¸ë¦¬ ê°œìˆ˜(n_estimators)ë¥¼ ê²°ì •í•˜ëŠ”ë° ë„ì›€ì´ ëœë‹¤. warm_start=Trueë¡œ ì„¤ì •í•˜ë©´ ì²˜ìŒë¶€í„° ì‹œì‘í•˜ì§€ ì•Šê³  íŠ¸ë¦¬ë¥¼ ì•™ìƒë¸”ì— ì¶”ê°€í•  ìˆ˜ ìˆë‹¤. n_estimatorsë¥¼ 100ì—ì„œ 200ìœ¼ë¡œë°”ê¾¸ë©´ 200ê°œì˜ íŠ¸ë¦¬ë¥¼ ê°€ì§„ ëœë¤ í¬ë ˆìŠ¤íŠ¸ë¥¼ ë§Œë“œëŠ”ë° 2ë°° ë” ì˜¤ë˜ê±¸ë¦°ë‹¤. warm_start=Trueë¡œ ì§€ì •í•˜ë©´ ì²˜ìŒë¶€í„° 200ê°œì˜ íŠ¸ë¦¬ë¥¼ ë‹¤ì‹œ ë§Œë“¤ì§€ ì•Šê³  ì´ì „ ëª¨ë¸ì— ì´ì–´ì„œ íŠ¸ë¦¬ë¥¼ ì¶”ê°€í•œë‹¤.warm_start ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©í•´ n_estimatorì— ë”°ë¼ OOB ì ìˆ˜ì˜ ë³€í™”ë¥¼ ê·¸ë˜í”„ë¡œ ê·¸ë¦´ ìˆ˜ ìˆë‹¤.import matplotlib.pyplot as pltimport seaborn as snssns.set()oob_scores = []rf = RandomForestClassifier(n_estimators=50, warm_start=True, oob_score=True, n_jobs=-1, random_state=2)rf.fit(X_census, y_census)oob_scores.append(rf.oob_score_)est = 50estimators = [est]for i in range(9): est += 50 estimators.append(est) rf.set_params(n_estimators=est) rf.fit(X_census, y_census) oob_scores.append(rf.oob_score_)plt.figure(figsize=(15, 7))plt.plot(estimators, oob_scores)plt.xlabel('Number of Trees')plt.ylabel('oob_score_')plt.title('Random Forest Warm Start', fontsize=15)plt.show()íŠ¸ë¦¬ ê°œìˆ˜ 300ê°œì—ì„œ ì ìˆ˜ê°€ ê°€ì¥ ë†’ë‹¤. 300ê°œ ì´ìƒì˜ íŠ¸ë¦¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ë¹„ìš©ê³¼ ì‹œê°„ ë‚­ë¹„ì´ë©° ì–»ì„ ìˆ˜ ìˆëŠ” ì´ë“ì´ í¬ì§€ ì•Šë‹¤.3.4 bootstrapbootstrap=Falseë¡œ ì„¤ì •í•˜ë©´ ë¶€íŠ¸ìŠ¤íŠ¸ë˜í•‘ì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤. ë”°ë¼ì„œ oob_score_ ë˜í•œ ì‚¬ìš©í•  ìˆ˜ ì—†ë‹¤.ê³¼ì†Œì í•©ì´ ì¼ì–´ë‚˜ëŠ” ê²½ìš° ì ìš©í•´ë³¼ ìˆ˜ ìˆê² ì§€ë§Œ ì“¸ ì¼ì€ ì—†ì„ ë“¯ í•˜ë‹¤.3.5 verboseê¸°ë³¸ê°’ì€ 0ìœ¼ë¡œ ë†’ì€ ìˆ«ìë¥¼ ì£¼ë©´ ì¤„ìˆ˜ë¡ ì¶œë ¥ì´ ë§ì•„ì§„ë‹¤. í•œë²ˆ ì‹¤í—˜í•´ë³´ëŠ” ê²ƒì„ ì¶”ì²œ3.6 ê²°ì • íŠ¸ë¦¬ ë§¤ê°œë³€ìˆ˜íŠ¸ë¦¬ ê¹Šì´ max_depthë¶„í•  max_features min_samples_split min_impurity_decreaseë¦¬í”„ ë…¸ë“œ min_samples_leaf min_weight_fraction_leaf" }, { "title": "2 ëœë¤ í¬ë ˆìŠ¤íŠ¸", "url": "/posts/randomforest/", "categories": "XGB FOR GRADIENT BOOSTING, RANDOM FOREST", "tags": "random forest", "date": "2022-06-02 06:01:00 +0900", "snippet": "ëœë¤ í¬ë ˆìŠ¤íŠ¸ì˜ ì‘ë™ ë°©ì‹ì„ ì˜ ì´í•´í•˜ê¸° ìœ„í•´ ì‚¬ì´í‚·-ëŸ°ìœ¼ë¡œ ì§ì ‘ ëª¨ë¸-ë§ì„ í•´ë³¼ê²ƒì´ë‹¤.2.1 ëœë¤ í¬ë ˆìŠ¤íŠ¸ ë¶„ë¥˜ ëª¨ë¸ê°„ë‹¨í•œ ì¸êµ¬ì¡°ì‚¬ ë°ì´í„°ì…‹ìœ¼ë¡œ ì—°ë´‰ì´ 5ë§Œë‹¬ëŸ¬ ì´ìƒì¸ì§€ ì˜ˆì¸¡í•˜ëŠ” ëœë¤ í¬ë ˆìŠ¤íŠ¸ ë¶„ë¥˜ê¸°ë¥¼ ë§Œë“¤ì–´ ë³¸ë‹¤. cross_val_score() í•¨ìˆ˜ë¥¼ í†µí•´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì˜ ì¼ë°˜í™” ë˜ëŠ” ì§€ í™•ì¸í•´ ë³¼ ê²ƒì´ë‹¤.import pandas as pdimport numpy as npfrom sklearn.ensemble import RandomForestClassifierfrom sklearn.model_selection import cross_val_scoreimport warningswarnings.filterwarnings('ignore')# ê°„í¸í•˜ê²Œ ë°›ì„ ìˆ˜ ìˆëŠ” ì¸êµ¬ ì¡°ì‚¬ ë°ì´í„°df_census = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', header=None)df_census.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']df_census.drop(['education'], axis=1, inplace=True) # ì¼ë‹¨ ë²„ë ¤df_census = pd.get_dummies(df_census) # ì›í•« ì¸ì½”ë”©df_census.drop(['income_ &lt;=50K'], axis=1, inplace=True) # íƒ€ê¹ƒì´ ìª¼ê°œì¡Œìœ¼ë¯€ë¡œ í•˜ë‚˜ ì§€ì›Œì¤€ë‹¤# featureì™€ targetì„ ë¶„ë¦¬í•´ì¤˜ì•¼ í•œë‹¤X_census = df_census.iloc[:, :-1]y_census = df_census.iloc[:, -1]# ëª¨ë¸ë§rf = RandomForestClassifier(n_estimators=10, random_state=2, n_jobs=-1)scores = cross_val_score(rf, X_census, y_census, cv=5)print(f'accuracy:{np.round(scores, 3)}')print(f'accuracy mean:{scores.mean():.3f}')accuracy:[0.851 0.844 0.851 0.852 0.851]accuracy mean:0.850ê¸°ë³¸ ëœë¤ í¬ë ˆìŠ¤íŠ¸ ë¶„ë¥˜ê¸°ê°€ ê²°ì •íŠ¸ë¦¬ ëª¨ë¸ (81%)ë³´ë‹¤ ì¸êµ¬ì¡°ì‚¬ ë°ì´í„°ì…‹ì—ì„œ ë” ë‚˜ì€ ì ìˆ˜ë¥¼ ë§Œë“ ë‹¤.ì„±ëŠ¥ì´ í–¥ìƒëœ ê²ƒì€ ë°°ê¹… ë•Œë¬¸ì¼ ê²ƒì´ë‹¤. ì´ ëœë¤ í¬ë ˆìŠ¤íŠ¸ëŠ” 10ê°œì˜ íŠ¸ë¦¬(n_estimators=10)ë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— í•œ ê°œê°€ ì•„ë‹ˆë¼ 10ê°œì˜ ê²°ì • íŠ¸ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜ˆì¸¡ì„ ë§Œë“ ë‹¤. ê° íŠ¸ë¦¬ëŠ” ë¶€íŠ¸ ìŠ¤íŠ¸ë˜í•‘ ìƒ˜í”Œì„ ì‚¬ìš©í•˜ë¯€ë¡œ ë‹¤ì–‘ì„±ì´ ë†’ì•„ì§€ê³  ì´ë¥¼ ì§‘ê³„í•˜ë©´ ë¶„ì‚°ì´ ì¤„ì–´ë“ ë‹¤.ê¸°ë³¸ì ìœ¼ë¡œ ëœë¤ í¬ë ˆìŠ¤íŠ¸ ë¶„ë¥˜ê¸°ëŠ” ë…¸ë“œë¥¼ ë¶„í•  í•  ë•Œfeatureê°œìˆ˜ì˜ ì œê³±ê·¼ì„ ì‚¬ìš©í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´ 100ê°œì˜ íŠ¹ì„±ì´ ìˆë‹¤ë©´ ëœë¤ í¬ë ˆìŠ¤íŠ¸ì˜ ê° ê²°ì • íŠ¸ë¦¬ëŠ” 10ê°œì˜ íŠ¹ì„±ë§Œ ì‚¬ìš©í•œë‹¤. ë”°ë¼ì„œ ì¤‘ë³µ ìƒ˜í”Œì„ ê°€ì§„ ë‘ íŠ¸ë¦¬ì˜ ë¶„í• ì´ ë‹¬ë¼ì§€ê¸° ë•Œë¬¸ì— ë§¤ìš° ë‹¤ë¥¸ ì˜ˆì¸¡ì„ ë§Œë“¤ ìˆ˜ ìˆë‹¤. ì´ê²ƒì´ ëœë¤ í¬ë ˆìŠ¤íŠ¸ê°€ ë¶„ì‚°ì„ ì¤„ì´ëŠ” ë˜ í•˜ë‚˜ì˜ ë°©ë²•ì´ë‹¤.2.2 ëœë¤ í¬ë ˆìŠ¤íŠ¸ íšŒê·€ ëª¨ë¸ëœë¤ í¬ë ˆìŠ¤íŠ¸ íšŒê·€ ëª¨ë¸ì€ ë¶„ë¥˜ ëª¨ë¸ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ë¶€íŠ¸ìŠ¤íŠ¸ë© ìƒ˜í”Œì„ ì‚¬ìš©í•˜ì§€ë§Œë…¸ë“œ ë¶„í• ì— feature ê°œìˆ˜ì˜ ì œê³±ê·¼ì´ ì•„ë‹ˆë¼feature ì „ì²´ë¥¼ ì‚¬ìš©í•œë‹¤.ìµœì¢… ì˜ˆì¸¡ì€ ë‹¤ìˆ˜ê²° íˆ¬í‘œê°€ ì•„ë‹ˆë¼ ëª¨ë“  íŠ¸ë¦¬ì˜ ì˜ˆì¸¡ì„ í‰ê· í•˜ì—¬ ë§Œë“ ë‹¤.df_bikes = pd.read_csv('./bike_rentals_cleaned.csv')print(df_bikes.head())X_bikes = df_bikes.iloc[:, :-1]y_bikes = df_bikes.iloc[:, -1]# ëª¨ë¸ë§from sklearn.ensemble import RandomForestRegressorrf = RandomForestRegressor(n_estimators=10, random_state=2, n_jobs=-1)scores = cross_val_score(rf, X_bikes, y_bikes, scoring='neg_mean_squared_error', cv=10)rmse = np.sqrt(-scores)print(f'RMSE:{np.round(rmse, 3)}')print(f'RMSE mean:{rmse.mean():.3f}')RMSE:[ 801.486 579.987 551.347 846.698 895.05 1097.522 893.738 809.284833.488 2145.046]RMSE mean:945.365ì´ ëœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ì€ ì´ì „ì— í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹ì„ í•´ì¤¬ë˜ ë‹¨ì¼ ê²°ì • íŠ¸ë¦¬ ëª¨ë¸ ë§Œí¼ì€ ì•„ë‹ˆì§€ë§Œ ì˜ ìˆ˜í–‰ëœë‹¤. ì´ì— ëŒ€í•œ ì´ìœ ëŠ” ìì „ê±° ëŒ€ì—¬ ë°ì´í„°ì…‹ì„ í†µí•´ ìì„¸íˆ ì•Œì•„ë³¼ ê²ƒì´ë‹¤." }, { "title": "1 ë°°ê¹… ì•™ìƒë¸” (Baggin ensemble)", "url": "/posts/bagginensemble/", "categories": "XGB FOR GRADIENT BOOSTING, RANDOM FOREST", "tags": "random forest", "date": "2022-06-02 06:00:00 +0900", "snippet": "ì•™ìƒë¸” ëª¨ë¸ì´ ê°œë³„ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë³´ë‹¤ ë›°ì–´ë‚œ ì´ìœ ë¥¼ ì•Œì•„ë³¸ë‹¤. ë˜í•œ ë°°ê¹…ì´ ë­”ì§€ ì•Œì•„ë³´ì.ë‘˜ ëª¨ë‘ ëœë¤í¬ë ˆìŠ¤íŠ¸ì˜ í•µì‹¬ì´ì˜¬ì‹œë‹¤.1.1 ì•™ìƒë¸” ë°©ë²•ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ì•™ìƒë¸” ë°©ë²•ì€ ê°œë³„ ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ í•©ì¹˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ë§í•œë‹¤.ì•™ìƒë¸” ë°©ë²•ì´ ì—¬ëŸ¬ ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ì—°ê²°í•˜ê¸° ë•Œë¬¸ì— ì˜¤ì°¨ë¥¼ ì¤„ì´ê³  ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë‚´ëŠ” ê²½í–¥ì´ ìˆë‹¤.ì–´ë–¤ ì§‘ì´ ì‹œì¥ì— ë‚˜ì˜¨ ì²« ë‹¬ë§Œì— íŒ”ë¦´ì§€ ì˜ˆì¸¡í•œë‹¤ê³  ê°€ì •í•˜ì.ì—¬ëŸ¬ ê°œì˜ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ì‹¤í–‰í•˜ì—¬ ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” 80% ì •í™•ë„,ê²°ì • íŠ¸ë¦¬ëŠ” 75% ì •í™•ë„,k-ìµœê·¼ì ‘ ì´ì›ƒ(K-nearest neighbors)ì€ 77% ì •í™•ë„ë¥¼ ì–»ì—ˆë‹¤.ê°€ì¥ ì •í™•í•œ ëª¨ë¸ì¸ ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ìµœì¢… ëª¨ë¸ë¡œ ì •í•  ìˆ˜ ìˆë‹¤.ê·¸ëŸ¬ë‚˜ ë” ë‚˜ì€ ë°©ë²•ì€ ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ í•©ì¹˜ëŠ” ê²ƒì´ë‹¤.ë¶„ë¥˜ê¸°ì˜ ê²½ìš° ì•™ìƒë¸”í•˜ëŠ” ëŒ€í‘œì ì¸ ë°©ë²•ì€ë‹¤ìˆ˜ê²° íˆ¬í‘œ(majority vote)ì´ë‹¤.ì„¸ ëª¨ë¸ ì¤‘ ì ì–´ë„ ë‘ê°œê°€ ì²« ë²ˆì§¸ ë‹¬ì— ì§‘ì´ íŒ”ë¦°ë‹¤ê³  ì˜ˆì¸¡í•˜ë©´ ìµœì¢… ì˜ˆì¸¡ì´ Yes ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ Noê°€ ëœë‹¤.ì „ì²´ì ì¸ ì •í™•ë„ëŠ” ì•™ìƒë¸” ë°©ë²•ì„ ì‚¬ìš©í•  ë•Œ ì¼ë°˜ì ìœ¼ë¡œ ë” ë†’ë‹¤.ì•™ìƒë¸”ì—ì„œëŠ” ì˜ˆì¸¡ì´ í‹€ë¦´ë ¤ë©´ í•œ ëª¨ë¸ì´ í‹€ë¦¬ëŠ” ê²ƒìœ¼ë¡œëŠ” ì¶©ë¶„í•˜ì§€ ì•Šë‹¤.ì¦‰ ë‹¤ìˆ˜ì˜ ë¶„ë¥˜ê¸°ê°€ í‹€ë ¤ì•¼ í•œë‹¤.ì•™ìƒë¸” ë°©ë²•ì€ í¬ê²Œ ë‘ ê°€ì§€ë¡œ ë‚˜ë‰œë‹¤.ì²« ë²ˆì§¸ëŠ” ì‚¬ì´í‚·ëŸ°ì˜ VotingClassfier ì²˜ëŸ¼ ì‚¬ìš©ìê°€ ì„ íƒí•œ ì—¬ëŸ¬ ì¢…ë¥˜ì˜ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ì—°ê²°í•˜ëŠ” ë°©ì‹ì´ë‹¤.ë‘ ë²ˆì¨°ëŠ” XGBoostë‚˜ ëœë¤ í¬ë ˆìŠ¤íŠ¸ ì²˜ëŸ¼ ê°™ì€ ì¢…ë¥˜ì˜ ëª¨ë¸ì„ ì—¬ëŸ¬ê°œ í•©ì¹˜ëŠ” ì•™ìƒë¸”ì´ë‹¤.ëœë¤ í¬ë ˆìŠ¤íŠ¸ëŠ” ëª¨ë“  ì•™ìƒë¸” ë°©ë²• ì¤‘ì—ì„œ ê°€ì¥ ì¸ê¸° ìˆê³  ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì´ë‹¤.ëœë¤ í¬ë ˆìŠ¤íŠ¸ì˜ ê°œë³„ ëª¨ë¸ì€ ê²°ì • íŠ¸ë¦¬ì´ë‹¤.ëœë¤ í¬ë ˆìŠ¤íŠ¸ëŠ” ìµœì¢… ì˜ˆì¸¡ì„ ë§Œë“¤ê¸° ìœ„í•´ ìˆ˜ë°± ë˜ëŠ” ìˆ˜ì²œ ê°œì˜ ê²°ì • íŠ¸ë¦¬ë¡œ êµ¬ì„±ë  ìˆ˜ ìˆë‹¤.ëœë¤ í¬ë ˆìŠ¤íŠ¸ëŠ” ë¶„ë¥˜ì¼ ê²½ìš° ë‹¤ìˆ˜ê²° íˆ¬í‘œë¥¼ ì‚¬ìš©í•˜ê³ íšŒê·€ì¼ ê²½ìš° ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ í‰ê· í•˜ì§€ë§Œ ê°œë³„ íŠ¸ë¦¬ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ë¶€íŠ¸ìŠ¤íŠ¸ë© ì• ê·¸ë¦¬ê²Œì´ì…˜(bootstrap aggregation)ì˜ ì•½ìì¸ë°°ê¹…ì´ë€ íŠ¹ë³„í•œ ë°©ë²•ì„ ì‚¬ìš©í•œë‹¤.1.2 ë°°ê¹… (Bagging)ë¶€íŠ¸ìŠ¤íŠ¸ë˜í•‘(bootstraping)ì€ ì¤‘ë³µì„ í—ˆìš©í•œ ìƒ˜í”Œë§ì„ ì˜ë¯¸í•œë‹¤.2Nê°œì˜ ìƒ‰ êµ¬ìŠ¬ì´ ë“¤ì–´ ìˆëŠ” ê°€ë°©ì´ ìˆë‹¤.í•œ ë²ˆì— í•˜ë‚˜ì”© Nê°œì˜ êµ¬ìŠ¬ì„ ì„ íƒí•˜ë ¤ê³  í•œë‹¤.êµ¬ìŠ¬ì„ ì„ íƒí•  ë•Œë§ˆë‹¤ ì´ë¥¼ ê°€ë°©ì— ë‹¤ì‹œ ë„£ëŠ”ë‹¤.ì•„ì£¼ ìš´ì´ ë‚˜ì˜ë©´ ë™ì¼í•œ êµ¬ìŠ¬ì„ 10ë²ˆ ì„ íƒí•  ìˆ˜ë„ ìˆë‹¤.ì–´ë–¤ êµ¬ìŠ¬ì€ í•œ ë²ˆ ì„ íƒí•˜ê²Œ ë˜ê³  ì–´ë–¤ êµ¬ìŠ¬ì€ ì „í˜€ ì„ íƒí•˜ì§€ ì•Šì„ ìˆ˜ë„ ìˆë‹¤.ë‹¤ìŒì€ Nê°œì˜ êµ¬ìŠ¬ì„ ì„ íƒí•˜ëŠ” ì˜ˆì‹œì´ë‹¤.ìœ„ ê·¸ë¦¼ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ ë¶€íŠ¸ìŠ¤íŠ¸ë© ìƒ˜í”Œì€ ì¤‘ë³µì„ í—ˆìš©í•œ ìƒ˜í”Œë§ìœ¼ë¡œ ë§Œë“ ë‹¤.ì¦‰, ê°™ì€ ìƒ˜í”Œì„ í•œ ë¶€íŠ¸ìŠ¤íŠ¸ë© ìƒ˜í”Œì— ì—¬ëŸ¬ë²ˆ ë„£ì„ ìˆ˜ ìˆë‹¤ëŠ” ì†Œë¦¬ì´ë‹¤.ëœë¤ í¬ë ˆìŠ¤íŠ¸ëŠ” ë¶€íŠ¸ìŠ¤íŠ¸ë˜í•‘ì„ ì‚¬ìš©í•œë‹¤.ê°œë³„ ê²°ì • íŠ¸ë¦¬ë¥¼ ë§Œë“¤ ë•Œ ë¶€íŠ¸ìŠ¤íŠ¸ë˜í•‘ì„ ìˆ˜í–‰í•œë‹¤.ëª¨ë“  ê²°ì • íŠ¸ë¦¬ê°€ ë™ì¼í•œ ìƒ˜í”Œë¡œ ë§Œë“¤ì–´ì§„ë‹¤ë©´ ëª¨ë‘ ë¹„ìŠ·í•œ ì˜ˆì¸¡ì„ ë§Œë“¤ê²Œ ë˜ê³  ì•™ìƒë¸”í•œ ê²°ê³¼ë„ ê°œë³„ íŠ¸ë¦¬ì™€ ë¹„ìŠ·í•´ ì§ˆ ê²ƒì´ë‹¤.ëœë¤ í¬ë ˆìŠ¤íŠ¸ëŠ”ì›ë³¸ ë°ì´í„°ì…‹ê³¼ ê°™ì€ í¬ê¸°ì˜ ë¶€íŠ¸ìŠ¤íŠ¸ë˜í•‘ ìƒ˜í”Œì„ ì‚¬ìš©í•´ ê° íŠ¸ë¦¬ë¥¼ ë§Œë“ ë‹¤.ìˆ˜í•™ì ìœ¼ë¡œ ê³„ì‚°í•˜ë©´ í‰ê· ì ìœ¼ë¡œ ê° íŠ¸ë¦¬ì˜ ìƒ˜í”Œì€ ì „ì²´ ìƒ˜í”Œì˜ 2/3ì„ í¬í•¨í•˜ë©° 1/3ì€ ì¤‘ë³µëœ ìƒ˜í”Œì´ë‹¤.ë¶€íŠ¸ìŠ¤íŠ¸ë˜í•‘ ë‹¨ê³„ í›„ì— ê° ê²°ì • íŠ¸ë¦¬ëŠ” ìì‹ ë§Œì˜ ì˜ˆì¸¡ì„ ë§Œë“ ë‹¤.ì´ íŠ¸ë¦¬ì˜ ì˜ˆì¸¡ì„ ëª¨ì•„ì„œ ìµœì¢…ì˜ˆì¸¡ì„ ë§Œë“ ë‹¤. ë¶„ë¥˜ì¼ ê²½ìš° ë‹¤ìˆ˜ê²° íˆ¬í‘œë¥¼ ì‚¬ìš©í•˜ê³  íšŒê·€ì¼ ê²½ìš° í‰ê· ì„ ë‚¸ë‹¤.ìš”ì•½í•˜ë©´ ëœë¤ í¬ë ˆìŠ¤íŠ¸ëŠ” ë¶€íŠ¸ìŠ¤íŠ¸ë˜í•‘ì„ ì‚¬ìš©í•œ ê²°ì • íŠ¸ë¦¬ì˜ ì˜ˆì¸¡ì„ í•©ì¹˜ëŠ” ê²ƒì´ë‹¤.ì´ëŸ¬í•œ ì•™ìƒë¸” ë°©ë²•ì„ ë°°ê¹…ì´ë¼ê³  í•œë‹¤." }, { "title": "5 ì‹¬ì¥ ì§ˆí™˜ ì˜ˆì¸¡í•˜ê¸°", "url": "/posts/hd/", "categories": "XGB FOR GRADIENT BOOSTING, DECISION TREE", "tags": "decision tree, modeling", "date": "2022-06-01 17:30:00 +0900", "snippet": "ë¨¸ì‹ ëŸ¬ë‹ì„ ì‚¬ìš©í•´ ì‹¬ì¥ì§ˆí™˜ì„ ì˜ˆì¸¡í•´ë‹¬ë¼ëŠ” ë³‘ì›ì˜ ìš”ì²­ì„ ë°›ì•˜ë‹¤ê³  ê°€ì •í•œë‹¤. ì˜ì‚¬ì™€ ê°„í™”ì‚¬ê°€ í™˜ìì˜ ê±´ê°•ì„ ëŒë³´ê¸° ìœ„í•´ ê´€ì‹¬ì„ ë‘ì–´ì•¼ í•  ì¤‘ìš”í•œ ë‘ ì„¸ê°œì˜ featureë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“œëŠ” ê²ƒì´ ëª©í‘œì´ë‹¤.ê²°ì • íŠ¸ë¦¬ ë¶„ë¥˜ê¸°ë¥¼ ì‚¬ìš©í•˜ê³  í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹ì„ í•´ë³´ì. ëª¨ë¸ì„ ë§Œë“  í›„ ì‹¬ì¥ ì§ˆí™˜ì„ ì˜ˆì¸¡í•˜ëŠ” ë° ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì„±ì„ ê°€ì§„ feature_importance_ ë¥¼ ì‚¬ìš©í•´ ê²°ê³¼ë¥¼ í•´ì„í•  ê²ƒì´ë‹¤.5.1 ì‹¬ì¥ ì§ˆí™˜ ë°ì´í„°ì…‹df_heart = pd.read_csv('./heart_disease.csv')df_heart.head()target=1ì€ ì‹¬ì¥ ì§ˆí™˜ì´ ìˆëŠ” ê²ƒì´ê³  0ì€ ê·¸ë ‡ì§€ ì•ˆë‹¤ëŠ” ê²ƒì´ë‹¤.ë‹¤ìŒì€ ê° featureì˜ ì˜ë¯¸ì´ë‹¤. age: ë‚˜ì´ sex: ì„±ë³„ cp: ê°€ìŠ´ í†µì¦(chest pain) (1=ì „í˜•ì ì¸ í˜‘ì‹¬ì¦, 2=ë¹„ì „í˜•ì ì¸ í˜‘ì‹¬ì¦, 3=í˜‘ì‹¬ì¦ì´ ì•„ë‹Œ í†µì¦, 4=ë¬´ì¦ìƒ) trestbps: ì•ˆì •í˜ˆì•• (ì…ì›ì‹œ mmHg) chol: í˜ˆì¤‘ ì½œë ˆìŠ¤í…Œë¡¤(serum cholesterol) (mg/dl) fbs: ê³µë³µ í˜ˆë‹¹ &gt; 120 mg/dl ? 1 : 0 restecg: ì‹¬ì „ë„ ê²°ê³¼ (0: ì •ìƒ, 1: ST-TíŒŒ ì´ìƒ(TíŒŒ ë°˜ì „ ë°/ë˜ëŠ” 0.05 mVì´ìƒì˜ ST ìƒìŠ¹ ë˜ëŠ” ê°ì†Œ), 2: Estes ê¸°ì¤€ì— ì˜í•´ ì¢Œì‹¬ì‹¤ ë¹„ëŒ€ì¦ ê°€ëŠ¥ì„± ë˜ëŠ” ìœ ë ¥) thalach: ìµœëŒ€ ì‹¬ì¥ ë°•ë™ ìˆ˜ exang: ìš´ë™ìœ¼ë¡œ ì¸í•œ í˜‘ì‹¬ì¦ (1: yes, 0: no) oldpeak: íœ´ì‹ ëŒ€ë¹„ ìš´ë™ìœ¼ë¡œ ì¸í•œ STê°ì†Œ slope: ìµœëŒ€ ìš´ë™ ST ì„¸ê·¸ë¨¼íŠ¸ ê¸°ìš¸ê¸° (1: ìƒìŠ¹ ê¸°ìš¸ê¸°, 2: ìˆ˜í‰, 3: í•˜ê°• ê¸°ìš¸ê¸°) ca: í˜•ê´‘ íˆ¬ì‹œë¡œ ì°©ìƒ‰ëœ ì£¼ìš” í˜ˆê´€ ìˆ˜ (0 ~ 3) thal: íƒˆë¥¨ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸, (3: ì •ìƒ, 6: ê³ ì • ê²°í•¨, 7: ê°€ì—­ì  ê²°í•¨)ë¨¸ì‹ ëŸ¬ë‹ ì‘ì—…ì„ ìœ„í•´ í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë‚˜ëˆˆë‹¤.X = df_heart.iloc[:, :-1]y = df_heart.iloc[:, -1]X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)5.2 ê²°ì • íŠ¸ë¦¬ ë¶„ë¥˜ê¸°í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹ í•˜ê¸° ì „ì— ë¹„êµë¥¼ ìœ„í•´ ê¸°ì¤€ì´ ë ë§Œí•œ ëª¨ë¸ì„ ë§Œë“ ë‹¤.ë‹¤ìŒì²˜ëŸ¼ DecisionTreeClassfier í´ë˜ìŠ¤ì™€ cross_val_score() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•œë‹¤.model = DecisionTreeClassifier(random_state=2)scores = cross_val_score(model, X, y, cv=5)print(f'\\n... accuracy:{np.round(scores, 2)} ...\\n')print(f'\\n... accuracy mean:{scores.mean():.2f} ...\\n') â€¦ accuracy:[0.75 0.85 0.75 0.7 0.72] â€¦ â€¦ accuracy mean:0.76 â€¦ì´ˆê¸° ëª¨ë¸ì˜ ì •í™•ë„ëŠ” 76%ì´ë‹¤. í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹ìœ¼ë¡œ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ì–»ì„ ìˆ˜ ìˆì„ ì§€ í™•ì¸í•´ë³´ì.RandomizedSearchedCVíƒìƒ‰í•  í•˜ì´í¼ íŒŒë¼ë¯¸í„°ê°€ ë§ì„ ë•Œ GridSearchCVë¡œ í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹ì„ í•˜ë©´ ë„ˆë¬´ ì˜¤ëœ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆë‹¤. ì´ë•Œ RandomziedSearchCV ëŠ” GridSearchCVì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ë™ì‘í•˜ì§€ë§Œ ëª¨ë“  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•©ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ëŒ€ì‹  ëœë¤í•œ ì¡°í•©ì„ í…ŒìŠ¤íŠ¸í•œë‹¤. ì¦‰ ëª¨ë“  ê°’ì„ í…ŒìŠ¤íŠ¸í•˜ì§€ ì•Šìœ¼ë©° ì œí•œëœ ì‹œê°„ ì•ˆì— ìµœìƒì˜ ì¡°í•©ì„ ì°¾ëŠ”ë‹¤.RandomizedSearchCVë¥¼ ì‚¬ìš©í•´ì„œ ì ìˆ˜ë¥¼ ì¶œë ¥í•˜ê³  ìµœìƒì˜ ëª¨ë¸ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“ ë‹¤. ì´ í•¨ìˆ˜ì˜ ë§¤ê°œë³€ìˆ˜ëŠ” params, runs(ì‹œë„í•  ì¡°í•©ì˜ íšŸìˆ˜), DecisionTreeClassfier ê°ì²´ì´ë‹¤.from sklearn.model_selection import RandomizedSearchCVdef randomized_search_clf(params, runs=20, clf=DecisionTreeClassifier( random_state=2)): rand_clf = RandomizedSearchCV(clf, params, n_iter=runs, cv=5, n_jobs=-1, random_state=2) rand_clf.fit(X_train, y_train) best_model = rand_clf.best_estimator_ best_score = rand_clf.best_score_ print(f'\\n... train score: {best_score:.3f} ...\\n') y_pred = rand_clf.best_estimator_.predict(X_test) accuracy = accuracy_score(y_test, y_pred) print(f'\\n... test score: {accuracy:.3f} ...\\n') return best_model5.3 í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ê³ ë¥´ëŠ” í•˜ë‚˜ì˜ ì™„ë²½í•œ ë°©ë²•ì€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤. ë‹¤ìŒì€ randomized_search_clf() í•¨ìˆ˜ì— ë„£ì€ ì´ˆê¸° ë§¤ê°œë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸ì´ë‹¤. ë¶„ì‚°ì„ ì¤„ì´ê³  ë„“ì€ ë²”ìœ„ë¥¼ íƒìƒ‰í•˜ê¸° ìœ„í•´ ìˆ˜ì¹˜ë¥¼ ì„ íƒí–ˆë‹¤.%%timeparams = { 'criterion': ['entropy', 'gini'], 'splitter': ['random', 'best'], 'min_samples_split': [2, 3, 4, 5, 6, 8, 10], 'min_samples_leaf': [1, .01, .02, .03, .04], 'min_impurity_decrease': [0, .0005, .005, .05, .1, .15, .2], 'max_leaf_nodes': [10, 15, 20, 25, 30, 35, 40, 45, 50, None], 'max_features': ['auto', .95, .9, .85, .8, .75, .7], 'max_depth': [None, 2, 4, 6, 8], 'min_weight_fraction_leaf': [0, .0025, .005, .0075, .01, .05]}randomized_search_clf(params) â€¦ train score: 0.798 â€¦ â€¦ test score: 0.855 â€¦ â€¦ DecisionTreeClassifier(criterion=â€™entropyâ€™, max_depth=8, max_features=0.8, max_leaf_nodes=45, min_impurity_decrease=0, min_samples_leaf=0.04, min_samples_split=10, min_weight_fraction_leaf=0.05, random_state=2) â€¦ CPU times: user 211 ms, sys: 5.54 ms, total: 217 ms Wall time: 749 msCPU times: user 211 ms, sys: 5.54 ms, total: 217 msWall time: 749 msí™•ì‹¤íˆ í–¥ìƒë˜ì—ˆê³  í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ì˜ ì¼ë°˜í™” ë˜ì—ˆë‹¤. ë²”ìœ„ë¥¼ ì¢í˜€ì„œ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆëŠ”ì§€ ì•Œì•„ë³´ì.5.4 íƒìƒ‰ ë²”ìœ„ ì¢íˆê¸°ë§¤ê°œë³€ìˆ˜ ë²”ìœ„ë¥¼ ì¢íˆëŠ” ê²ƒì´ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆëŠ” í•œ ê°€ì§€ ë°©ë²•ì´ë‹¤.ì˜ˆë¥¼ ë“¤ì–´ ìµœìƒì˜ ëª¨ë¸ì—ì„œ ì–»ì€ max_depth=8ì„ ê¸°ì¤€ìœ¼ë¡œ íƒìƒ‰ ë²”ìœ„ë¥¼ 7~9ë¡œ ì¢í ìˆ˜ ìˆë‹¤.ë˜ ë‹¤ë¥¸ ì „ëµì€ ê¸°ë³¸ê°’ì´ ì˜ ë™í•˜ëŠ” ë§¤ê°œë³€ìˆ˜ë¥¼ íƒìƒ‰ì—ì„œ ì œì™¸ì‹œí‚¤ëŠ” ê²ƒì´ë‹¤. ì˜ˆë¥¼ ë“¤ì–´ â€˜entropyâ€™ëŠ” ì°¨ì´ê°€ í¬ì§€ ì•Šê¸° ë•Œë¬¸ì— â€˜giniâ€™ ëŒ€ì‹ ì— ì¶”ì²œí•˜ì§€ ì•ŠëŠ”ë‹¤. min_impurity_decreaseë„ ê¸°ë³¸ê°’ ê·¸ëŒ€ë¡œ ë‘˜ ìˆ˜ ìˆë‹¤.ìƒˆë¡œìš´ ë§¤ê°œë³€ìˆ˜ ë²”ìœ„ì—ì„œ 100ë²ˆìœ¼ë¡œ íƒìƒ‰ íšŸìˆ˜ë¥¼ ì¦ê°€ì‹œì¼œë³´ì.%%timeparams = { 'max_depth': [None, 6, 7], 'max_features': ['auto', .78], 'max_leaf_nodes': [45, None], 'min_samples_leaf': [1, .035, .04, .045, .05], 'min_samples_split': [2, 9, 10], 'min_weight_fraction_leaf': [0, .05, .06, .07]}model = randomized_search_clf(params, runs=100)print(f'\\n... {model} ...\\n') â€¦ train score: 0.802 â€¦ â€¦ test score: 0.868 â€¦ â€¦ DecisionTreeClassifier(max_depth=7, max_features=0.78, max_leaf_nodes=45, min_samples_leaf=0.045, min_samples_split=9, min_weight_fraction_leaf=0.06, random_state=2) â€¦ CPU times: user 713 ms, sys: 35.2 ms, total: 748 msWall time: 5.13 sì´ ëª¨ë¸ì˜ í›ˆë ¨ ì ìˆ˜ì™€ í…ŒìŠ¤íŠ¸ ì ìˆ˜ëŠ” ë”ìš± ë†’ì•„ì¡Œë‹¤.ë°˜í™˜ëœ ìµœìƒì˜ ëª¨ë¸ì„ ì „ì²´ ë°ì´í„° ì…‹ì—ì„œ êµì°¨ ê²€ì¦ í•¨ìˆ˜ë¥¼ ì ìš©í•´ ê¸°ë³¸ ëª¨ë¸ê³¼ ë¹„êµí•´ë³¸ë‹¤.scores = cross_val_score(best_model, X, y, cv=5)print(f'\\n... accuracy:{np.round(scores, 2)} ...\\n')print(f'\\n... accuracy mean:{scores.mean():.2f} ...\\n') â€¦ accuracy:[0.82 0.9 0.8 0.8 0.78] â€¦ â€¦ accuracy mean:0.82 â€¦ë¬´ë ¤ 6% ì´ë“!5.5 íŠ¹ì„± ì¤‘ìš”ë„ (feature importance)ë§ˆì§€ë§‰ìœ¼ë¡œ ì´ ëª¨ë¸ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ featureë¥¼ í™•ì¸í•´ë³´ì. ê²°ì • íŠ¸ë¦¬ëŠ” ì´ëŸ° ê°’ì„ ì œê³µí•´ì£¼ëŠ” feature_importances_ ì†ì„±ì„ ì œê³µí•œë‹¤.ë¨¼ì € ì•ì„œ ë§Œë“  ëª¨ë¸ì„ ì „ì²´ ë°ì´í„°ì…‹ì—ì„œ í›ˆë ¨í•˜ì.ëª¨ë¸ì„ í›ˆë ¨í•  ë•Œ í›ˆë ¨ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¥¼ ì„ì§€ ì•ŠëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤. í•˜ì§€ë§Œ ìµœì¢… ëª¨ë¸ì„ ì„ íƒí•œ í›„ì—ëŠ” ì „ì²´ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•´ ëª¨ë¸ì„ í›ˆë ¨í•˜ëŠ” ê²ƒì´ ì •í™•ë„ë¥¼ ë” ë†’ì¼ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ë„ì›€ì´ ëœë‹¤.best_model.fit(X, y)best_model.feature_importances_ array([0.04826754, 0.04081653, 0.48409586, 0.00568635, 0. , 0. , 0. , 0.00859483, 0. , 0.02690379, 0. , 0.18069065, 0.20494446])ê²°ê³¼ë¥¼ í•´ì„í•˜ê¸° ë‚œí•´í•˜ë‹¤. feature ì´ë¦„ê³¼ feature importancesë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë§Œë“  ë‹¤ìŒ íŠ¹ì„± ì¤‘ìš”ë„ì˜ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•´ì„œ ë³´ì.feature_dict = dict(zip(X.columns, best_model.feature_importances_))import operatorsorted(feature_dict.items(), key=operator.itemgetter(1), reverse=True)[0:3] [(â€˜cpâ€™, 0.4840958610240171), (â€˜thalâ€™, 0.20494445570568706), (â€˜caâ€™, 0.18069065321397942)]ì´ ê°’ ë“¤ì€ ë…¸ë“œ ë¶„í• ì— ì‚¬ìš©ëœ featureë³„ ê°ì†Œëœ ë¶ˆìˆœë„ ëŸ‰ì„ ë”í•œ í›„ ì „ì²´ ê°’ì´ 1ì´ ë˜ë„ë¡ ì •ê·œí™”í•œ ê²ƒì´ë‹¤.ê°€ì¥ ì¤‘ìš”í•œ ì„¸ ê°œì˜ íŠ¹ì„±ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. cp: ê°€ìŠ´ í†µì¦(chest pain) (1=ì „í˜•ì ì¸ í˜‘ì‹¬ì¦, 2=ë¹„ì „í˜•ì ì¸ í˜‘ì‹¬ì¦, 3=í˜‘ì‹¬ì¦ì´ ì•„ë‹Œ í†µì¦, 4=ë¬´ì¦ìƒ) thalach: ìµœëŒ€ ì‹¬ì¥ ë°•ë™ ìˆ˜ ca: í˜•ê´‘ íˆ¬ì‹œë¡œ ì°©ìƒ‰ëœ ì£¼ìš” í˜ˆê´€ ìˆ˜ (0 ~ 3)ì´ì œ ê°€ì¥ ì¤‘ìš”í•œ ì„¸ ê°œì˜ íŠ¹ì„±ì¸ ê°€ìŠ´í†µì¦, ìµœëŒ€ ì‹¬ì¥ ë°•ë™ìˆ˜, í˜•ê´‘ íˆ¬ì‹œë¡œ ì°©ìƒ‰ëœ ì£¼ìš” í˜ˆê´€ ìˆ˜ë¡œ í™˜ìê°€ ì‹¬ì¥ ì§ˆí™˜ì„ ê°€ì¡ŒëŠ”ì§€ 82% ì •í™•ë„ë¡œ ì˜ˆì¸¡í•  ìˆ˜ ìˆë‹¤ê³  ì˜ì‚¬ì™€ ê°„í˜¸ì‚¬ì—ê²Œ ë§ í•  ìˆ˜ ìˆë‹¤." }, { "title": "4 ê²°ì • íŠ¸ë¦¬ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹", "url": "/posts/dthpt/", "categories": "XGB FOR GRADIENT BOOSTING, DECISION TREE", "tags": "decision tree", "date": "2022-06-01 17:15:00 +0900", "snippet": "í•˜ì´í¼ íŒŒë¼ë¯¸í„°ëŠ” íŒŒë¼ë¯¸í„°ì™€ ë‹¤ë¥¸ê²ƒì´ë‹¤.ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ íŒŒë¼ë¯¸í„°ëŠ” ëª¨ë¸ì´ íŠœë‹ë  ë•Œ ì¡°ì •ëœë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì„ í˜•íšŒê·€ì™€ ë¡œì§€ìŠ¤í‹± íšŒê·€ì˜ ê°€ì¤‘ì¹˜ê°€ ì˜¤ì°¨ë¥¼ ìµœì†Œí™”í•˜ëŠ” ë‹¨ê³„ì—ì„œ ì¡°ì •ë˜ëŠ” íŒŒë¼ë¯¸í„°ì´ë‹¤. ì´ì™€ ë‹¤ë¥´ê²Œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” í›ˆë ¨ ë‹¨ê³„ ì´ì „ì— ë¯¸ë¦¬ ì„ íƒëœë‹¤. í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¥¼ ì„ íƒí•˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ê°’ì´ ì‚¬ìš©ëœë‹¤.4.1 ê²°ì • íŠ¸ë¦¬ íšŒê·€ ëª¨ë¸í•˜ì´í¼ íŒŒë¼ë¯¸í„°ëŠ” ì‹¤ì œë¡œ ì—¬ëŸ¬ê°€ì§€ ë•Œë ¤ë°•ì•„ë³´ëŠ”ê²Œ ë‹µì´ë‹¤. ë‹¤ì–‘í•œ í•˜ì´í¼ íŒŒë¼ë¯¸í„° ì„ íƒì— ê´€í•œ ì´ë¡ ë“¤ì´ ìˆì§€ë§Œ ì‹¤ì „ì´ ì´ë¡ ë³´ë‹¤ ì•ì„ ë‹¤ê³  í•œë‹¤. ë°ì´í„° ì…‹ë§ˆë‹¤ ì„±ëŠ¥ì„ ë†’ì¼ ìˆ˜ ìˆëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’ì´ ë‹¤ë¥¸ë‹¤.í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¥¼ ì„ íƒí•˜ê¸° ì „ì— DecisionTreeRegressor í´ë˜ìŠ¤ì™€ cross_val_score() í•¨ìˆ˜ë¡œ ê¸°ì¤€ ì ìˆ˜ë¥¼ í™•ì¸í•´ë³¸ë‹¤.import pandas as pd# --------------preprocessing------------------df_bikes = pd.read_csv('./bike_rentals_cleaned.csv')X_bikes = df_bikes.iloc[:, :-1]y_bikes = df_bikes.iloc[:, -1]from sklearn.linear_model import LinearRegressionX_train, X_test, y_train, y_test = train_test_split(X_bikes, y_bikes, random_state=1117)# ------------linear regression model-------------from sklearn.tree import DecisionTreeRegressorfrom sklearn.model_selection import cross_val_scorereg = DecisionTreeRegressor(random_state=1117)scores = cross_val_score(reg, X_bikes, y_bikes, scoring='neg_mean_squared_error', cv=5)rmse = np.sqrt(-scores)print(f'\\n... RMSE í‰ê· :{rmse.mean():.2f} ...\\n') â€¦ RMSE í‰ê· :1248.51 â€¦ì¢‹ì§€ ëª»í•œ 1248.51ì˜ RMSEê°€ ë‚˜ì™”ë‹¤.ë¶„ì‚°ì´ ë„ˆë¬´ ë†’ì•„ ëª¨ë¸ì´ ë°ì´í„°ì— ê³¼ëŒ€ì í•©ëœ ê²ƒì¸ê°€? í›ˆë ¨ ì„¸íŠ¸ì— ëŒ€í•œ ê²°ì • íŠ¸ë¦¬ì˜ ì„±ëŠ¥ì„ í™•ì¸í•˜ì—¬ ìœ„ ì§ˆë¬¸ì— ë‹µì„ ì–»ì„ ìˆ˜ ìˆë‹¤.reg = DecisionTreeRegressor()reg.fit(X_train, y_train)y_pred = reg.predict(X_train)from sklearn.metrics import mean_squared_errorreg_mse = mean_squared_error(y_train, y_pred)reg_rmse = np.sqrt(reg_mse)reg_mse 0.0RMSEê°€ 0ì´ë©´ 100% ì‹¹ë‹¤ ë§ì·„ë‹¤ëŠ” ì–˜ê¸°ì´ë‹¤. ì´ ì ìˆ˜ì™€ êµì°¨ ê²€ì¦ ê²°ê³¼ì¸ 1248.51ì„ í•¨ê»˜ ìƒê°í•˜ë©´ ê²°ì • íŠ¸ë¦¬ê°€ ê³¼ëŒ€ ì í•©ë˜ì–´ ë¶„ì‚°ì´ í¬ë‹¤ëŠ” ê²ƒì´ í™•ì‹¤í•˜ë‹¤. í›ˆë ¨ ì„¸íŠ¸ëŠ” ì™„ë²½í•˜ê²Œ ë§ì·„ì§€ë§Œ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œëŠ” í° ì°¨ì´ê°€ ë°œìƒí•´ë²„ë¦° ê²ƒì´ë‹¤.í•˜ì´í¼ íŒŒë¼ë¯¸í„°ëŠ” ì´ëŸ° ìƒí™©ì„ ë°”ë¡œ ì¡ì„ ìˆ˜ ìˆë‹¤.4.2 í•˜ì´í¼ íŒŒë¼ë¯¸í„°max_depthmax_depthëŠ” íŠ¸ë¦¬ì˜ ê¹Šì´ë¥¼ ì •ì˜í•œë‹¤. ê¹Šì´ëŠ” ë¶„í•  íšŸìˆ˜ë¥¼ ê²°ì •í•œë‹¤. max_depthì˜ ê¸°ë³¸ê°’ì€ Noneìœ¼ë¡œ ì œí•œì´ ì—†ë‹¤. ë”°ë¼ì„œ ìˆ˜ë°±ì´ë‚˜ ìˆ˜ì²œë²ˆ ë¶„í• ì´ ì¼ì–´ë‚  ìˆ˜ ìˆìœ¼ë©° ê³¼ëŒ€ì í•©ì„ ë§Œë“ ë‹¤. max_depthë¥¼ ì‘ì€ ê°’ìœ¼ë¡œ ì œí•œí•˜ë©´ ë¶„ì‚°ì´ ì¤„ì–´ë“¤ê³  ëª¨ë¸ì´ ìƒˆë¡œìš´ ë°ì´í„°ì— ì˜ ì¼ë°˜í™” ëœë‹¤.ìµœì„ ì˜ max_depthë¥¼ ì–´ë–»ê²Œ ì„ íƒí•  ìˆ˜ ìˆëŠ”ê°€?GridSearchCVGridSearchCVëŠ” êµì°¨ ê²€ì¦ì„ ì‚¬ìš©í•´ ìµœì„ ì˜ ê²°ê³¼ë¥¼ ë§Œë“œëŠ” ë§¤ê°œë³€ìˆ˜ ì¡°í•©ì„ ì°¾ëŠ”ë‹¤.GridSearchCV í´ë˜ìŠ¤ëŠ” ì‚¬ì´í‚·ëŸ°ì˜ ë‹¤ë¥¸ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì²˜ëŸ¼ ë™ì‘í•œë‹¤. ì¦‰ í›ˆë ¨ ì„¸íŠ¸ì—ì„œ í›ˆë ¨í•˜ê³  í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ì ìˆ˜ë¥¼ ê³„ì‚°í•œë‹¤. ë‹¤ë¥¸ ëª¨ë¸ê³¼ ì£¼ìš”í•œ ì°¨ì´ì ì€ GridSearchCVê°€ ìµœì¢…ëª¨ë¸ì„ ì„ íƒí•˜ê¸° ì „ì— ëª¨ë“  ë§¤ê°œë³€ìˆ˜ë¥¼ ê²€ì‚¬í•œë‹¤ëŠ” ì ì´ë‹¤.GridSearchCVì˜ í•µì‹¬ì€ ë§¤ê°œë³€ìˆ˜ ê°’ì˜ ë”•ì…”ë„ˆë¦¬ë¥¼ ì •ì˜í•œë‹¤ëŠ” ê²ƒì´ë‹¤. ì˜¬ë°”ë¥¸ ì¡°í•©ì´ë€ ê²ƒì€ ì—†ë‹¤. í•œ ê°€ì§€ ë°©ë²•ì€ ê°€ì¥ ì‘ì€ ê°’ê³¼ ê°–ì•„ í° ê°’ ì‚¬ì´ì—ì„œ ì¼ì • ê°„ê²©ì„ ì„ íƒí•˜ëŠ” ê²ƒì´ë‹¤. ê³¼ëŒ€ì í•©ì„ ì¤„ì—¬ì•¼ í•˜ê¸° ë•Œë¬¸ì— max_depthê°’ì„ ì¤„ì—¬ì„œ ì‹œë„í•´ë³´ëŠ” ê²ƒì´ ì¢‹ë‹¤.GridSearchCVë¥¼ ì„í¬íŠ¸í•˜ê³  max_depth íŒŒë¼ë¯¸í„°ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ë‹¤ìŒì²˜ëŸ¼ ì •ì˜í•œë‹¤.from sklearn.model_selection import GridSearchCVparams = {'max_depth': [None, 2, 3, 4, 6, 8, 10, 20]} ì¼ë°˜ì ìœ¼ë¡œ maxë€ ì´ë¦„ì´ ë¶™ì€ ë§¤ê°œë³€ìˆ˜ëŠ” ê°ì†Œì‹œí‚¤ê³  minì´ ë¶™ì€ ë§¤ê°œë³€ìˆ˜ëŠ” ì¦ê°€ì‹œí‚¤ë©´ ë¶„ì‚°ì´ ì¤„ì–´ë“¤ê³  ê³¼ëŒ€ì í•©ì´ ë°©ì§€ëœë‹¤ê·¸ ë‹¤ìŒ DecisionTreeRegressor ê°ì²´ë¥¼ ë§Œë“¤ê³  GridSearchCVì— params ë”•ì…”ë„ˆë¦¬ì™€ í‰ê°€ì§€í‘œë¥¼ í•¨ê»˜ ì „ë‹¬í•œë‹¤.reg = DecisionTreeRegressor(random_state=1117)grid_reg = GridSearchCV(reg, params, scoring='neg_mean_squared_error', cv=5, return_train_score=True,\t\t\t\t\t\t\t\t\t\t\t\tjobs=-1) # CPU í’€ê°€ë™grid_reg.fit(X_train, y_train)ë°ì´í„°ë¥¼ GridSearchCVì— fittingì‹œì¼°ìœ¼ë¯€ë¡œ ì´ì œ ìµœìƒì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ í™•ì¸í•œë‹¤.best_params = grid_reg.best_params_print(f'\\n... best params : {best_params} ...\\n') â€¦ best params : {â€˜max_depthâ€™: 8} â€¦max_depth=8ì¼ ë•Œ í›ˆë ¨ ì„¸íŠ¸ì—ì„œ ìµœìƒì˜ êµì°¨ ê²€ì¦ ì ìˆ˜ë¥¼ ë§Œë“ ë‹¤.í›ˆë ¨ì ìˆ˜ëŠ” best_score_ì— ì €ì¥ë˜ì–´ ìˆë‹¤.best_score = np.sqrt(-grid_reg.best_score_)print(f'\\n... train score : {best_score:.3f} ...\\n') â€¦ train score : 821.074 â€¦í…ŒìŠ¤íŠ¸ ì ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì¶œë ¥í•œë‹¤.best_model = grid_reg.best_estimator_y_pred = best_model.predict(X_test)from sklearn.metrics import mean_squared_errorrmse_test = mean_squared_error(y_test, y_pred)**.5print(f'\\n... test score : {rmse_test:.3f} ...\\n') â€¦ train score : 821.074 â€¦1034ë¡œ í™•ì‹¤íˆ ë¶„ì‚°ì´ ì¤„ì–´ë“¤ì—ˆë‹¤.min_samples_leafmin_samples_leafëŠ” ë¦¬í”„ ë…¸ë“œê°€ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ìµœì†Œ ìƒ˜í”Œì˜ ê°œìˆ˜ë¥¼ ì œí•œí•œë‹¤. max_depthì™€ ë§ˆì°¬ê°€ì§€ë¡œ min_samples_leafëŠ” ê³¼ì í•©ì„ ë°©ì§€í•œë‹¤.min_samples_leafì˜ ê¸°ë³¸ê°’ì€ 1ë¡œ ì œí•œì´ ì—†ì„ ë•Œ ë¦¬í”„ ë…¸ë“œëŠ” í•˜ë‚˜ì˜ ìƒ˜í”Œë¡œ êµ¬ì„±í•  ìˆ˜ ìˆë‹¤.(ê³¼ì í•©ë˜ê¸° ì‰½ë‹¤). min_samples_leafë¥¼ ì¦ê°€ì‹œí‚¤ë©´ ë¶„ì‚°ì„ ì¤„ì¼ ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ min_samples_leaf=8 ì´ë©´ ëª¨ë“  ë¦¬í”„ ë…¸ë“œëŠ” ìµœì†Œí•œ 8ê°œ ì´ìƒì˜ ìƒ˜í”Œì„ ë‹´ê³  ìˆì–´ì•¼ í•œë‹¤.min_samples_leafì˜ ê°’ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ê³¼ì •ì€ ì´ì „ê³¼ ë™ì¼í•˜ë‹¤. ë³µë¶™ì„ í•˜ëŠ” ëŒ€ì‹  DecisionTreeRegressor(random_state=1117)ë¥¼ reg ê°ì²´ì— í• ë‹¹í•˜ê³  GridSearchCVë¥´ ì‚¬ìš©í•´ì„œ ìµœìƒì˜ ë§¤ê°œë³€ìˆ˜, í›ˆë ¨ ì ìˆ˜, í…ŒìŠ¤íŠ¸ ì ìˆ˜ë¥¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ì˜€ë‹¤.def grid_search(params, reg=DecisionTreeRegressor(random_state=1117), X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test): grid_reg = GridSearchCV(reg, params, scoring='neg_mean_squared_error', cv=5, n_jobs=-1) grid_reg.fit(X_train, y_train) best_params = grid_reg.best_params_ best_score = np.sqrt(-grid_reg.best_score_) print(f'\\n... best params: {best_params} ...\\n') print(f'\\n... train score: {best_score:.3f} ...\\n') y_pred = grid_reg.best_estimator_.predict(X_test) rmse_test = mean_squared_error(y_test, y_pred)**.5 print(f'\\n... test score: {rmse_test:.3f} ...\\n')í•˜ì´í¼ íŒŒë¼ë¯¸í„°ì˜ ë²”ìœ„ë¥¼ ì„ íƒí•  ë•Œ í›ˆë ¨ ì„¸íŠ¸ì˜ í¬ê¸°ë¥¼ ì•„ëŠ” ê²ƒì´ ë„ì›€ëœë‹¤.X_train.shape â€¦ train score : 821.074 â€¦í›ˆë ¨ ì„¸íŠ¸ê°€ 548ê°œ í–‰ì„ ê°€ì§€ê³  ìˆê¸° ë•Œë¬¸ì— ì ì ˆí•œ min_samples_leaf ê°’ì„ ê²°ì •í•  ìˆ˜ ìˆë‹¤. grid_searchì˜ ì…ë ¥ìœ¼ë¡œ [1, 2, 4, 8, 20, 30]ì„ ì‹œë„í•´ë³¸ë‹¤.grid_search(params={'min_samples_leaf': [1, 2, 4, 6, 8, 10, 20, 30]}) â€¦ best params: {â€˜min_samples_leafâ€™: 2} â€¦ â€¦ train score: 855.425 â€¦ â€¦ test score: 898.941 â€¦min_samples_leafì™€ max_depthë¥¼ ê°™ì´ ë„£ì–´ë³´ì.grid_search(params={'max_depth': [None, 2, 3, 4, 6, 8, 10, 20], 'min_samples_leaf': [1, 2, 4, 6, 8, 10, 20, 30]}) â€¦ best params: {â€˜max_depthâ€™: 8, â€˜min_samples_leafâ€™: 1} â€¦ â€¦ train score: 821.074 â€¦ â€¦ test score: 1034.835 â€¦ì–´ì²˜êµ¬ë‹ˆê°€ ì—†ê²Œë„ í›ˆë ¨ì ìˆ˜ëŠ” ì¢‹ì•„ì¡Œì§€ë§Œ í…ŒìŠ¤íŠ¸ì ìˆ˜ëŠ” ë‚˜ë¹ ì¡Œë‹¤(ê³¼ì í•©).ì´ì „ ì˜ˆì œì—ì„œ ë¶„ì‚°ì„ ì¤„ì˜€ë˜ ê²ƒì²˜ëŸ¼ min_samples_leafë¥¼ 3ë³´ë‹¤ í¬ê²Œ ì„¤ì •í•´ë³´ì.grid_search(params={'max_depth': [None, 6, 7, 8, 9, 10], 'min_samples_leaf': [3, 5, 7, 9]}) â€¦ best params: {â€˜max_depthâ€™: 8, â€˜min_samples_leafâ€™: 5} â€¦ â€¦ train score: 849.492 â€¦ â€¦ test score: 793.616 â€¦ê²°ê³¼ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ í…ŒìŠ¤íŠ¸ ì ìˆ˜ê°€ í–¥ìƒë˜ì—ˆë‹¤.max_leaf_nodesmax_leaf_nodesëŠ” min_samples_leafì™€ ë¹„ìŠ·í•˜ë‹¤. ë¦¬í”„ ë…¸ë“œ í•˜ë‚˜ë‹¹ ìƒ˜í”Œ ê°œìˆ˜ì˜ í•˜í•œì„ ì§€ì •í•˜ëŠ” ëŒ€ì‹ , ì „ì²´ íŠ¸ë¦¬ì˜ ë¦¬í”„ ë…¸ë“œ ê°œìˆ˜ì˜ ìƒí•œì„ ì§€ì •í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´, max_leaf_nodes=10 ìœ¼ë¡œ ì§€ì •í•˜ë©´ íŠ¸ë¦¬ ë¦¬í”„ ë…¸ë“œê°€ ìµœëŒ€ 10ê°œë¥¼ ë„˜ì„ ìˆ˜ ì—†ë‹¤.max_featuresmax_featuresëŠ” ë¶„ì‚°ì„ ì¤„ì´ëŠ”ë° íš¨ê³¼ì ì¸ ë§¤ê°œë³€ìˆ˜ì´ë‹¤. ë¶„í• ë§ˆë‹¤ ëª¨ë“  featureë¥¼ ê³ ë ¤í•˜ì§€ ì•Šê³  ë§¤ë²ˆ ì§€ì •ëœ ê°œìˆ˜ì˜ feature ì¤‘ì—ì„œ ì„ íƒí•œë‹¤.max_featuresì˜ ì˜µì…˜ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. None(default)ì™€ â€˜autoâ€™ëŠ” ì „ì²´ featureë¥¼ ì‚¬ìš©í•œë‹¤. â€˜sqrtâ€™ëŠ” ì „ì²´ feature ê°œìˆ˜ì˜ ì œê³±ê·¼ì„ ì‚¬ìš©í•œë‹¤. â€˜log2â€™ëŠ” ì „ì²´ log_2(feature ê°œìˆ˜)ë¥¼ ì‚¬ìš©í•œë‹¤. ex) ì „ì²´ feature ê°œìˆ˜ê°€ 32ê°œ â‡’ ë¶„í•  ë‹¹ 5ê°œì˜ featureë§Œ ê³ ë ¤.min_samples_splitë¶„í• ì„ ì œí•œí•˜ëŠ” ë˜ ë‹¤ë¥¸ ë°©ë²•ì€ min_samples_splitì´ë‹¤. ì´ë¦„ì—ì„œ ì•Œ ìˆ˜ ìˆë“¯ì´ 1íšŒ ë¶„í• í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ìµœì†Œ sample ê°œìˆ˜ë¥¼ ì œí•œí•œë‹¤. ê¸°ë³¸ê°’ì€ 2ì´ë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì´ ê°’ì„ 5ë¡œ ì„¤ì •í•˜ë©´ 5ê°œ ë³´ë‹¤ ì ì€ ë…¸ë“œëŠ” ë” ì´ìƒ ë¶„í•  í•˜ì§€ ì•ŠëŠ”ë‹¤.splittersplitter ë§¤ê°œ ë³€ìˆ˜ì—ëŠ” â€˜randomâ€™ê³¼ â€˜bestâ€™ ë‘ê°œì˜ ì˜µì…˜ì´ ìˆë‹¤. ë¶„í• ê¸°ëŠ” ë…¸ë“œë¥¼ ë¶„í• í•˜ê¸° ìœ„í•œ feature ì„ íƒ ë°©ë²•ì´ë‹¤. ê¸°ë³¸ê°’ì€ â€˜bestâ€™ë¡œ ì •ë³´ì´ë“(information gain)ì´ ê°€ì¥ í° íŠ¹ì„±ì„ ì„ íƒí•œë‹¤ (criterionìœ¼ë¡œ ì§€ì •ëœ í‰ê°€ì§€í‘œë¥¼ ê°€ì¥ ì¤„ì´ëŠ” feature). ì´ì™€ ë‹¬ë¦¬ â€˜randomâ€™ì€ ëœë¤í•˜ê²Œ ë…¸ë“œë¥¼ ë¶„í• í•œë‹¤.splitter=â€™randomâ€™ìœ¼ë¡œ í•˜ë©´ ê³¼ëŒ€ì í•©ì„ ë§‰ê³  ë‹¤ì–‘í•œ íŠ¸ë¦¬ë¥¼ ë§Œë“œëŠ” íš¨ê³¼ê°€ ìˆë‹¤.criterionê²°ì • íŠ¸ë¦¬ íšŒê·€ ëª¨ë¸ê³¼ ë¶„ë¥˜ ëª¨ë¸ì˜ criterionê°’ì´ ë‹¤ë¥´ë‹¤. criterionì€ ë¶„í•  í’ˆì§ˆì„ ì¸¡ì •í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì œê³µí•œë‹¤. criterionì— ì§€ì •í•œ í•¨ìˆ˜ë¥¼ ê°€ëŠ¥í•œ ë¶„í• ë§ˆë‹¤ ê³„ì‚°í•˜ì—¬ ë¹„êµí•œë‹¤. ê°€ì¥ ì¢‹ì€ ì ìˆ˜ë¥¼ ì–»ì€ ë¶„í• ì´ ì„ íƒëœë‹¤.íšŒê·€ ëª¨ë¸ì¼ ê²½ìš° â€˜squared_errorâ€™(í‰ê·  ì œê³± ì˜¤ì°¨), â€˜friedman_mseâ€™(í”„ë¦¬ë“œë§Œ MSE), â€˜absolute errorâ€™, â€˜poissonâ€™(í¬ì´ì†¡ í¸ì°¨)ê°€ ìˆë‹¤. ê¸°ë³¸ê°’ì€ â€˜squared_errorâ€™ì´ë‹¤.ë¶„ë¥˜ ëª¨ë¸ì¼ ê²½ìš° ì•ì„œ ì–¸ê¸‰í•œ â€˜giniâ€™(ê¸°ë³¸ê°’)ê³¼ â€˜entropyâ€™ê°€ ìˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ë‘ ì˜µì…˜ì€ ë¹„ìŠ·í•œ ê²°ê³¼ë¥¼ ë§Œë“ ë‹¤.min_impurity_decreasemin_impurity_decreaseëŠ” ë¶„í• í•˜ê¸° ìœ„í•œ ìµœì†Œ ë¶ˆìˆœë„ ê°ì†Œë¥¼ ì§€ì •í•œë‹¤.ë¶ˆìˆœë„ëŠ” ê° ë…¸ë“œì˜ ì˜ˆì¸¡ì´ ì–¼ë§ˆë‚˜ ìˆœìˆ˜í•œì§€ë¥¼ ì¸¡ì •í•œë‹¤. 100%ì˜ ì •í™•ë„ë¥¼ ê°€ì§„ íŠ¸ë¦¬ì˜ ë¶ˆìˆœë„ëŠ” 0.0ì´ë‹¤. 80% ì •í™•ë„ë¥¼ ê°€ì§„ íŠ¸ë¦¬ì˜ í‰ê· ì ì¸ ë¶ˆìˆœë„ëŠ” 0.20ì¼ ê²ƒì´ë‹¤.ë¶ˆìˆœë„ëŠ” ê²°ì • íŠ¸ë¦¬ì—ì„œ ì¤‘ìš”í•œ ê°œë…ì´ë‹¤. íŠ¸ë¦¬ë¥¼ ì„±ì¥ì‹œí‚¤ëŠ” ê³¼ì •ì—ì„œ ë¶ˆìˆœë„ëŠ” ì§€ì†ì ìœ¼ë¡œ ê°ì†Œë˜ì–´ì•¼ í•œë‹¤. ê° ë…¸ë“œì—ê±° ê°€ì¥ í¬ê²Œ ë¶ˆìˆœë„ë¥¼ ê°ì†Œì‹œí‚¤ëŠ” ë¶„í• ì´ ì„ íƒëœë‹¤.ê¸°ë³¸ê°’ì€ 0.0ì´ë‹¤. ì´ ê°’ì„ ì¦ê°€ì‹œí‚¤ë©´ ì„ê³—ê°’ì— ë„ë‹¬í•  ë•Œ íŠ¸ë¦¬ì˜ ì„±ì¥ì´ ë©ˆì¶˜ë‹¤.min_weight_fraction_leafmin_weight_fraction_leafëŠ” ë¦¬í”„ ë…¸ë“œê°€ ë˜ê¸° ìœ„í•œ ì „ì²´ ê°€ì¤‘ì¹˜ì˜ ìµœì†Œ ë¹„ìœ¨ì´ë‹¤. sample_weightë¥¼ ì§€ì •í•´ì£¼ì§€ ì•Šìœ¼ë©´ ìƒ˜í”Œì€ ëª¨ë‘ ë™ì¼í•œ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§„ë‹¤.min_weight_fraction_leafëŠ” ë¶„ì‚°ì„ ì¤„ì´ê³  ê³¼ëŒ€ì í•©ì„ ë§‰ì„ ìˆ˜ ìˆëŠ” ë˜ ë‹¤ë¥¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì´ë‹¤. ê¸°ë³¸ê°’ì€ 0.0ì´ë‹¤. 500ê°œì˜ ìƒ˜í”Œì´ ìˆê³  ê°€ì¤‘ì¹˜ê°€ ë™ì¼í•˜ë‹¤ë©´, ì´ ë§¤ê°œë³€ìˆ˜ë¥¼ 0.01ë¡œ ì§€ì •í•  ë•Œ ë¦¬í”„ ë…¸ë“œê°€ ë˜ê¸° ìœ„í•œ ìµœì†Œ ìƒ˜í”Œ ê°œìˆ˜ëŠ” 5ê°œì´ë‹¤.cca_alphacca_alpha ë§¤ê°œë³€ìˆ˜ëŠ” íŠ¸ë¦¬ë¥¼ ë§Œë“  í›„ ê°€ì§€ì¹˜ê¸°(prunning)ë¥¼ í•˜ëŠ” ê¸°ëŠ¥ìœ¼ë¡œ ì—¬ê¸°ì„œ ì„¤ëª…í•˜ì§€ëŠ” ì•Šì„ ê²ƒì´ë‹¤. ìì„¸í•œ ë‚´ìš©ì€ ìµœì†Œ ë¹„ìš©ë³µì¡ë„ ê°€ì§€ì¹˜ê¸° (minimal cost-complexity prunning)ì— ëŒ€í•´ ì•Œì•„ë³¼ ê²ƒ.4.3 ì •ë¦¬í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹ì„ í•  ë•Œ ëª‡ ê°€ì§€ ê³ ë ¤ì‚¬í•­ì´ ìˆë‹¤. ì†Œìš” ì‹œê°„ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°œìˆ˜ ì›í•˜ëŠ” ì†Œìˆ˜ì  ì •í™•ë„ì†Œìš” ì‹œê°„, íŠœë‹í•  í•˜ì´í¼ íŒŒë¼ë¯¸í„° ê°œìˆ˜, ì›í•˜ëŠ” ì •í™•ë„ëŠ” ë°ì´í„°ì…‹ê³¼ í”„ë¡œì íŠ¸ì— ë”°ë¼ ë‹¤ë¥´ë‹¤. í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ì„œë¡œ ì—°ê´€ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— ëª¨ë‘ ìˆ˜ì •í•  í•„ìš”ëŠ” ì—†ë‹¤. ì‘ì€ ë²”ìœ„ì—ì„œ íŠœë‹í•˜ë©´ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ë§Œë“¤ ìˆ˜ ìˆë‹¤." }, { "title": "3 ë¶„ì‚°(variance)ê³¼ í¸í–¥(bias)", "url": "/posts/varbias/", "categories": "XGB FOR GRADIENT BOOSTING, DECISION TREE", "tags": "decision tree", "date": "2022-06-01 17:00:00 +0900", "snippet": "ë‹¤ìŒ ê·¸ë˜í”„ì— ìˆëŠ” ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ê°€ì§€ê³  ìˆë‹¤ê³  ê°€ì •í•˜ì. ì´ ë°ì´í„°ì— ì§ì„  ë˜ëŠ” ê³¡ì„ ì„ í•™ìŠµì‹œì¼œ ìƒˆë¡œìš´ í¬ì¸íŠ¸ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ë§Œë“¤ì–´ì•¼ í•œë‹¤. ëœë¤í•œ í¬ì¸íŠ¸ë“¤ì˜ ê·¸ë˜í”„3.1 ì„ í˜• íšŒê·€ê° ì ë“¤ê³¼ ì§ì„  ì‚¬ì´ì˜ ê±°ë¦¬ ì œê³±ì„ ìµœì†Œí™”í•˜ëŠ” ì„ í˜•íšŒê·€ë¥¼ ì‚¬ìš©í•œë‹¤.ì§ì„ ì€ ì¼ë°˜ì ìœ¼ë¡œ í¸í–¥ì´ í¬ë‹¤. ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ í¸í–¥ì€ ëª¨ë¸ì„ ì‹¤ì œ ë¬¸ì œì— ì ìš©í•  ë•Œ ì˜¤ì°¨ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë°ì„œ ìœ ë˜í•œë‹¤. ì˜ˆì¸¡ì´ ì§ì„ ì— ì œí•œë˜ì–´ ìˆê³  ë°ì´í„° ë³€í™”ë¥¼ ê³ ë ¤í•˜ì§€ ëª»í•˜ê¸° ë•Œë¬¸ì— í¸í–¥ì´ í¬ë‹¤ê³  í•  ìˆ˜ìˆë‹¤.ë§ì€ ê²½ìš° ì§ì„ ì€ ì •í™•í•œ ì˜ˆì¸¡ì„ í•˜ê¸°ì— ì¶©ë¶„íˆ ë³µì¡í•˜ì§€ ì•Šë‹¤. ì´ëŸ° ê²½ìš°ì— ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì´ í¸í–¥ì´ ë†’ê³  ë°ì´í„°ì— ê³¼ì†Œì í•©ë˜ì—ˆë‹¤ê³  ë§í•œë‹¤.3.2 8ì°¨ ë‹¤í•­ì‹ë‹¤ìŒê³¼ ê°™ì´ 8ì°¨ ë‹¤í•­ì‹ì„ ì ìš©í•œë‹¤. í¬ì¸íŠ¸ê°€ 9ê°œì´ê¸° ë•Œë¬¸ì— ì™„ë²½í•˜ê²Œ ì£¼ì–´ì§„ ë°ì´í„°ì— ì í•©ì‹œí‚¬ ìˆ˜ìˆë‹¤.ì´ëŸ° ê²½ìš°ì— ë¶„ì‚°ì´ ë†’ë‹¤ê³  í•  ìˆ˜ ìˆê² ë‹¤. ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ë¶„ì‚°ì€ ë‹¤ë¥¸ í›ˆë ¨ ë°ì´í„°ê°€ ì£¼ì–´ì¡Œì„ ë•Œ ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ë³€í™”í•˜ëŠ”ì§€ ë‚˜íƒ€ë‚´ëŠ” ìš©ì–´ì´ë‹¤. ë¶„ì‚°ì€ í™•ë¥  ë³€ìˆ˜ì™€ í‰ê·  ì‚¬ì´ì˜ ì°¨ì´ë¥¼ ì œê³±í•œ ê²ƒì´ë‹¤. ì•„í™‰ ê°œì˜ ìƒˆë¡œìš´ ë°ì´í„° í¬ì¸íŠ¸ê°€ í›ˆë ¨ ì„¸íŠ¸ë¡œ ì£¼ì–´ì§€ë©´ ìœ„ì˜ 8ì°¨ ë‹¤í•­ì‹ì€ ì™„ì „íˆ ë‹¤ë¥¸ ëª¨ì–‘ìœ¼ë¡œ ë°”ë€”ê²ƒì´ë‹¤. ë”°ë¼ì„œ ë¶„ì‚°ì´ ë†’ë‹¤.ë¶„ì‚°ì´ ë†’ì€ ëª¨ë¸ì€ ë°ì´í„°ì— ê³¼ëŒ€ì í•©ë˜ê¸° ì‰½ë‹¤. ì´ëŸ° ëª¨ë¸ì€ í›ˆë ¨ ë°ì´í„°ì— ë„ˆë¬´ ë°€ì ‘í•˜ê²Œ ë§ì¶°ì ¸ ìˆê¸° ë•Œë¬¸ì— ìƒˆë¡œìš´ ë°ì´í„° í¬ì¸íŠ¸ì— ì˜ ì¼ë°˜í™”ë˜ì§€ ëª»í•œë‹¤.3.3 3ì°¨ ë‹¤í•­ì‹ë§ˆì§€ë§‰ìœ¼ë¡œ 3ì°¨ ë‹¤í•­ì‹ì„ ì ìš©í•´ë³¸ë‹¤.ì´ 3ì°¨ ë‹¤í•­ì‹ì€ ë¶„ì‚°ê³¼ í¸í–¥ ì‚¬ì´ì— ê· í˜•ì´ ì˜ ì¡í˜€ìˆë‹¤. ì¼ë°˜ì ì¸ ê³¡ì„ ì˜ í˜•íƒœë¥¼ ë”°ë¥´ë©´ì„œ ë³€ë™ì— ì ì‘í•œë‹¤.ë¶„ì‚°ê³¼ í¸í–¥ì˜ ê· í˜•ë‚®ì€ ë¶„ì‚°ì€ í›ˆë ¨ ì„¸íŠ¸ê°€ ë‹¬ë¼ì ¸ë„ í¬ê²Œ ë‹¤ë¥¸ ê³¡ì„ ì„ ë§Œë“¤ì§€ ì•ŠëŠ”ë‹¤ëŠ” ëœ»ì´ë‹¤. ë‚®ì€ í¸í–¥ì€ ì´ ëª¨ë¸ì„ ì‹¤ì „ì— ì ìš©í–ˆì„ ë•Œ ì˜¤ì°¨ê°€ ë„ˆë¬´ í¬ì§€ ì•Šë‹¤ëŠ” ëœ»ì´ë‹¤. ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ë‚®ì€ ë¶„ì‚°ê³¼ í¸í–¥ì„ ê°€ì§€ëŠ” ê²ƒì´ ì´ìƒì ì´ë‹¤.ë¶„ì‚°ê³¼ í¸í–¥ ì‚¬ì´ì— ê· í˜•ì„ ì˜ ì¡ê¸° ìœ„í•œ ê°€ì¥ ì¢‹ì€ ë¨¸ì‹ ëŸ¬ë‹ ë°©ë²• ì¤‘ í•˜ë‚˜ëŠ”í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì´ë‹¤." }, { "title": "2 ê²°ì • íŠ¸ë¦¬ ì•Œê³ ë¦¬ì¦˜", "url": "/posts/dtalg/", "categories": "XGB FOR GRADIENT BOOSTING, DECISION TREE", "tags": "decision tree", "date": "2022-06-01 16:45:00 +0900", "snippet": "ê²°ì • íŠ¸ë¦¬ëŠ” ê°€ì§€(branch)ë¶„í• ì„ í†µí•´ ë°ì´í„°ë¥¼ ë‘ ê°œì˜ ë…¸ë“œë¡œ ë‚˜ëˆˆë‹¤. ê°€ì§€ ë¶„í• ì€ ì˜ˆì¸¡ì„ ë§Œë“œëŠ” ë¦¬í”„ë…¸ë“œê¹Œì§€ ê³„ì†ëœë‹¤. ì‹¤ì œ ì˜ˆë¥¼ ë‹¤ë¤„ë³´ë©´ ê°€ì§€ê°€ ë¶„í• ë˜ëŠ” ë°©ë²•ê³¼ ë¦¬í”„ ë…¸ë“œê°€ ë§Œë“¤ì–´ì§€ëŠ” ë°©ë²•ì„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë‹¤. ë” ìì„¸í•œ ë‚´ìš©ì„ ì‚´í´ë³´ê¸° ì „ì— ì²« ë²ˆì§¸ ê²°ì • íŠ¸ë¦¬ ëª¨ë¸ì„ ë§Œë“¤ì–´ ë³´ì.2.1 ì²« ë²ˆì§¸ ê²°ì • íŠ¸ë¦¬ ëª¨ë¸ì¸êµ¬ ì¡°ì‚¬ ë°ì´í„° ì…‹ì„ í†µí•´ ì†Œë“ì´ 5ë§Œ ë‹¬ëŸ¬ ì´ìƒì¸ì§€ ì˜ˆì¸¡í•˜ëŠ” ê²°ì • íŠ¸ë¦¬ë¥¼ ë§Œë“¤ì–´ë³´ìimport pandas as pdimport numpy as npimport warningswarnings.filterwarnings('ignore')# ê°„í¸í•˜ê²Œ ë°›ì„ ìˆ˜ ìˆëŠ” ì¸êµ¬ ì¡°ì‚¬ ë°ì´í„°df_census = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', header=None)df_census.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']df_census.drop(['education'], axis=1, inplace=True) # ì¼ë‹¨ ë²„ë ¤df_census = pd.get_dummies(df_census) # ì›í•« ì¸ì½”ë”©df_census.drop(['income_ &lt;=50K'], axis=1, inplace=True) # íƒ€ê¹ƒì´ ìª¼ê°œì¡Œìœ¼ë¯€ë¡œ í•˜ë‚˜ ì§€ì›Œì¤€ë‹¤# featureì™€ targetì„ ë¶„ë¦¬í•´ì¤˜ì•¼ í•œë‹¤X = df_census.iloc[:, :-1]y = df_census.iloc[:, -1]train_test_split() í•¨ìˆ˜ë¥¼ ì„í¬íŠ¸í•˜ê³  ë°ì´í„°ë¥¼ í›ˆë ¨ê³¼ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìŒìœ¼ë¡œ ë¶„ë¦¬í•´ì¤€ë‹¤. í•  ë•Œë§ˆë‹¤ ê²°ê³¼ê°€ ë‹¬ë¼ì§€ëŠ” ê±´ ì‹«ìœ¼ë‹ˆê¹Œ random_stateë„ ì•„ë¬´ê±°ë‚˜ ë°•ì•„ì¤€ë‹¤from sklearn.model_selection import train_test_splitX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1117)ê·¸ ë‹¤ìŒ ì¼ë°˜ì ì¸ ë‹¨ê³„ì— ë”°ë¼ ê²°ì •íŠ¸ë¦¬ ë¶„ë¥˜ê¸°ë¥¼ ë§Œë“¤ì–´ì¤€ë‹¤. ì—¬ê¸°ì„œ accuracy_score() ëŠ” ì •í™•í•˜ê²Œ ë§ì€ ì˜ˆì¸¡ íšŸìˆ˜ë¥¼ ì „ì²´ ì˜ˆì¸¡ íšŸìˆ˜ë¡œ ë‚˜ëˆˆ ê°’ì„ ë°˜í™˜í•œë‹¤. 20ê°œ ì˜ˆì¸¡ ì¤‘ì— 19ê°œê°€ ë§ì•˜ë‹¤ë©´ accuracy_score() í•¨ìˆ˜ëŠ” 95%ë¥¼ ë°˜í™˜í•œë‹¤from sklearn.tree import DecisionTreeClassifierfrom sklearn.metrics import accuracy_scoreclf = DecisionTreeClassifier(random_state=1117) # 1.ëª¨ë¸ ìƒì„±clf.fit(X_train, y_train) # 2.í›ˆë ¨y_pred = clf.predict(X_test) # 3.ì˜ˆì¸¡accuracy_score(y_pred, y_test) # 4. í‰ê°€2.2 ê²°ì • íŠ¸ë¦¬ì˜ ì‘ë™ ì›ë¦¬ê²°ì •íŠ¸ë¦¬ì˜ ë‚´ë¶€ ì‘ë™ ë°©ì‹ì€ ê·¸ë¦¼ìœ¼ë¡œ ì˜ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤.import matplotlib.pyplot as pltfrom sklearn.tree import plot_treeplt.figure(figsize=(13, 8))plot_tree(clf, max_depth=2, # max_depth ì„¤ì • ì•ˆ í•´ì£¼ë©´ ë°‘ë„ ëë„ ì—†ì´ ê·¸ë¦°ë‹¤\t\t\t\t\tfeature_names=list(X.columns), class_names=['0', '1'], filled=True, rounded=True, fontsize=10)plt.show() ìœ„ì—ì„œ ì‚¬ìš©í•œ ëª¨ë¸ì—ì„œ ë§¨ìœ„ 2ê°œì¸µë§¨ ìœ„ê°€ ë£¨íŠ¸ë…¸ë“œì´ë‹¤. ë§¨ ìœ„/ ë§¨ ì•„ë˜ë¥¼ ì œì™¸í•œ ëª¨ë“  ì‚¬ê°í˜•ì´ ë…¸ë“œì´ë‹¤.ì§€ë‹ˆ ë¶ˆìˆœë„ (gini impurity)ë…¸ë“œì˜ ë‘ ë²ˆì§¸ ì¤„ì€ gini=x.xxx ì´ë‹¤. ì´ ê°’ì„ ì§€ë‹ˆë¶ˆìˆœë„ë¼ê³  í•˜ë©° ê²°ì • íŠ¸ë¦¬ê°€ ì–´ë–»ê²Œ ë¶„í• í• ì§€ ê²°ì •í•˜ëŠ”ë° ì‚¬ìš©ëœë‹¤. ë¶ˆìˆœë„ ê°’ì´ ê°€ì¥ ë‚®ì€ ë¶„í• ì„ ì°¾ëŠ” ê²ƒì´ ëª©í‘œì´ë‹¤. ì§€ë‹ˆ ë¶ˆìˆœë„ê°€ 0ì´ë©´ í•˜ë‚˜ì˜ í´ë˜ìŠ¤ë¡œë§Œ ì´ë£¨ì–´ì§„ ë…¸ë“œì´ë‹¤. ì§€ë‹ˆ ë¶ˆìˆœë„ê°€ 0ì´ë©´ ë…¸ë“œì•ˆ í´ë˜ìŠ¤ë³„ ìƒ˜í”Œê°¯ìˆ˜ê°€ ë™ì¼í•œê²ƒì´ë‹¤. 0ì— ê°€ê¹Œìš¸ ìˆ˜ë¡ ì¢‹ë‹¤.ì§€ë‹ˆ ë¶ˆìˆœë„ë¥¼ ê³„ì‚°í•˜ëŠ” ì‹ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\\[gini=\\sum_{i=1}^c(p_i)^2\\]ì—¬ê¸°ì„œ $p_i$ëŠ” ì „ì²´ ìƒ˜í”Œ ì¤‘ì—ì„œ í•´ë‹¹ í´ë˜ìŠ¤ ìƒ˜í”Œì˜ ë¹„ìœ¨ì´ê³ , $c$ëŠ” ì´ í´ë˜ìŠ¤ ê°€ì§“ìˆ˜ì´ë‹¤. ì´ ì˜ˆì‹œì—ì„œ $c=2$.ìŠ¤í…€í”„ (stump)ë”± í•œë²ˆë§Œ ë¶„í• ëœ íŠ¸ë¦¬ë¥¼ ìŠ¤í…€í”„ë¼ê³  í•œë‹¤. ìŠ¤í…€í”„ ìì²´ëŠ” ê°•ë ¥í•œ ëª¨ë¸ì´ ì•„ë‹ˆì§€ë§Œ ë¶€ìŠ¤í„°ë¡œ ì‚¬ìš©ë˜ë©´ ê°•ë ¥í•´ì§ˆ ìˆ˜ ìˆë‹¤." }, { "title": "1 ê²°ì • íŠ¸ë¦¬ ê°œìš”", "url": "/posts/dtoverview/", "categories": "XGB FOR GRADIENT BOOSTING, DECISION TREE", "tags": "decision tree", "date": "2022-06-01 16:30:00 +0900", "snippet": "ì•™ìƒë¸” ë°©ë²• ì¤‘ í•˜ë‚˜ì¸ XGBoostì˜ê¸°ë³¸í•™ìŠµê¸°(base learner)ë¡œ ê°€ì¥ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ê²°ì • íŠ¸ë¦¬ëŠ” ë…íŠ¹í•œ íŠ¹ì§•ì„ ê°€ì§„ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì´ë‹¤.ì„ í˜• íšŒê·€ì™€ ë¡œì§€ìŠ¤í‹± íšŒê·€ ì²˜ëŸ¼ íŠ¹ì„±ì„ ê°€ì¤‘ì¹˜ì™€ ê³±í•˜ëŠ” ëŒ€ì‹  ê²°ì • íŠ¸ë¦¬ëŠ” íŠ¹ì„±ì— ëŒ€í•œ ì§ˆë¬¸ì— ë”°ë¼ ë°ì´í„°ë¥¼ ë‚˜ëˆˆë‹¤.ì‚¬ì‹¤ ê²°ì • íŠ¸ë¦¬ë¥¼ ë§Œë“œëŠ” ê²ƒì€ìŠ¤ë¬´ê³ ê°œê²Œì„ì„ í•˜ëŠ” ê²ƒê³¼ ê°™ë‹¤.ì˜ˆë¥¼ ë“¤ì–´, ê²°ì • íŠ¸ë¦¬ê°€ ì˜¨ë„ íŠ¹ì„±ì„ ê°€ì§€ê³  ë°ì´í„°ë¥¼ ë‘ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆë‹¤.ì˜¨ë„ê°€ 70ë„ ì´ìƒì¸ ê·¸ë£¹ê³¼ 70ë„ ì´í•˜ì¸ ê·¸ë£¹ì´ë‹¤.ê·¸ ë‹¤ìŒì—ëŠ” ê° ê·¸ë£¹ì„ ê³„ì ˆì„ ê¸°ë°˜ìœ¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆë‹¤.ì—¬ë¦„ì¸ ê²½ìš°ì™€ ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš°ì´ë‹¤.ì´ì œ ë°ì´í„°ëŠ” ë„¤ ê°œì˜ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ë‰˜ì—ˆë‹¤.ì•Œê³ ë¦¬ì¦˜ì´ ì¼ì • ìˆ˜ì¤€ì˜ ì •í™•ë„ì— ë„ë‹¬í•  ë•Œê¹Œì§€ ì´ë ‡ê²Œ ë°ì´í„°ë¥¼ ìƒˆë¡œìš´ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê³¼ì •ì´ ê³„ì†ëœë‹¤.ê²°ì • íŠ¸ë¦¬ëŠ” í›ˆë ¨ì„¸íŠ¸ì— ìˆëŠ” ê° ìƒ˜í”Œì„ ì •í™•í•œ íƒ€ê¹ƒì— ë§¤í•‘í•  ë•Œê¹Œì§€ ìˆ˜ì²œ ê°œì˜ ê·¸ë£¹ì„ ë§Œë“¤ ìˆ˜ ìˆë‹¤.í›ˆë ¨ì„¸íŠ¸ì— ëŒ€í•´ì„œëŠ” 100% ì •í™•ë„ë¥¼ ë‹¬ì„±í•œë‹¤ëŠ” ì˜ë¯¸ì´ë‹¤.í•˜ì§€ë§Œ ì´ëŸ° ëª¨ë¸ì€ ìƒˆë¡œìš´ ë°ì´í„°ì— ì˜ ì¼ë°˜í™”ë˜ì§€ ëª»í•œë‹¤.ê²°ì • íŠ¸ë¦¬ëŠ”ê³¼ëŒ€ì í•©ë˜ê¸° ì‰½ë‹¤.ë‹¤ë¥¸ ë§ë¡œ í•˜ë©´ ê²°ì •íŠ¸ë¦¬ëŠ” í›ˆë ¨ ë°ì´í„°ì—ë§Œ ë„ˆë¬´ ì˜ ë§ì„ ìˆ˜ ìˆë‹¤.ë‚˜ì¤‘ì— ë¶„ì‚°ê³¼ í¸í–¥ì„ ë‹¤ë£° ë•Œ ì‚´í´ë³¼ ê²ƒì´ë‹¤.í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹ì€ ê³¼ëŒ€ì í•©ì„ ë§‰ëŠ” í•œê°€ì§€ ë°©ë²•ì´ë‹¤.ë˜ ë‹¤ë¥¸ ë°©ë²•ì€ëœë¤ í¬ë ˆìŠ¤íŠ¸ì™€ XGBoostê°€ ì‚¬ìš©í•˜ëŠ” ì „ëµìœ¼ë¡œ ë§ì€ íŠ¸ë¦¬ì˜ ì˜ˆì¸¡ì„ ëª¨ìœ¼ëŠ” ê²ƒì´ë‹¤." } ]
