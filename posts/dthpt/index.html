<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="4 결정 트리 하이퍼파라미터 튜닝" /><meta name="author" content="mng" /><meta property="og:locale" content="en" /><meta name="description" content="하이퍼 파라미터는 파라미터와 다른것이다." /><meta property="og:description" content="하이퍼 파라미터는 파라미터와 다른것이다." /><link rel="canonical" href="https://moongthy.github.io/posts/dthpt/" /><meta property="og:url" content="https://moongthy.github.io/posts/dthpt/" /><meta property="og:site_name" content="MNG" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-06-01T17:15:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="4 결정 트리 하이퍼파라미터 튜닝" /><meta name="twitter:site" content="@twitter_username" /><meta name="twitter:creator" content="@mng" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"mng"},"dateModified":"2022-06-02T23:13:50+09:00","datePublished":"2022-06-01T17:15:00+09:00","description":"하이퍼 파라미터는 파라미터와 다른것이다.","headline":"4 결정 트리 하이퍼파라미터 튜닝","mainEntityOfPage":{"@type":"WebPage","@id":"https://moongthy.github.io/posts/dthpt/"},"url":"https://moongthy.github.io/posts/dthpt/"}</script><title>4 결정 트리 하이퍼파라미터 튜닝 | MNG</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="MNG"><meta name="application-name" content="MNG"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="/assets/archan.gif" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">MNG</a></div><div class="site-subtitle font-italic">Student, 26</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/Moongthy" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['mungeunj','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>4 결정 트리 하이퍼파라미터 튜닝</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>4 결정 트리 하이퍼파라미터 튜닝</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1654071300" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Jun 1, 2022 </em> </span> <span> Updated <em class="" data-ts="1654179230" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Jun 2, 2022 </em> </span><div class="d-flex justify-content-between"> <span> By <em> mng </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2915 words"> <em>16 min</em> read</span></div></div></div><div class="post-content"><p>하이퍼 파라미터는 파라미터와 다른것이다.</p><p>머신러닝에서 파라미터는 모델이 튜닝될 때 조정된다. 예를 들어 선형회귀와 로지스틱 회귀의 가중치가 오차를 최소화하는 단계에서 조정되는 파라미터이다. 이와 다르게 하이퍼파라미터는 훈련 단계 이전에 미리 선택된다. 하이퍼 파라미터를 선택하지 않으면 기본값이 사용된다.</p><h1 id="41-결정-트리-회귀-모델">4.1 결정 트리 회귀 모델</h1><hr /><p>하이퍼 파라미터는 실제로 여러가지 때려박아보는게 답이다. 다양한 하이퍼 파라미터 선택에 관한 이론들이 있지만 실전이 이론보다 앞선다고 한다. 데이터 셋마다 성능을 높일 수 있는 하이퍼파라미터 값이 다른다.</p><p>하이퍼 파라미터를 선택하기 전에 <code class="language-plaintext highlighter-rouge">DecisionTreeRegressor</code> 클래스와 <code class="language-plaintext highlighter-rouge">cross_val_score()</code> 함수로 기준 점수를 확인해본다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="c1"># --------------preprocessing------------------
</span><span class="n">df_bikes</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'./bike_rentals_cleaned.csv'</span><span class="p">)</span>
<span class="n">X_bikes</span> <span class="o">=</span> <span class="n">df_bikes</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y_bikes</span> <span class="o">=</span> <span class="n">df_bikes</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_bikes</span><span class="p">,</span> <span class="n">y_bikes</span><span class="p">,</span>
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">1117</span><span class="p">)</span>

<span class="c1"># ------------linear regression model-------------
</span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="n">reg</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1117</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">reg</span><span class="p">,</span> <span class="n">X_bikes</span><span class="p">,</span> <span class="n">y_bikes</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'neg_mean_squared_error'</span><span class="p">,</span>
                         <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="o">-</span><span class="n">scores</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="se">\n</span><span class="s">... RMSE 평균:</span><span class="si">{</span><span class="n">rmse</span><span class="p">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> ...</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
</pre></table></code></div></div><blockquote><p>… RMSE 평균:1248.51 …</p></blockquote><p>좋지 못한 1248.51의 RMSE가 나왔다.</p><p>분산이 너무 높아 모델이 데이터에 과대적합된 것인가? 훈련 세트에 대한 결정 트리의 성능을 확인하여 위 질문에 답을 얻을 수 있다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="n">reg</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">()</span>
<span class="n">reg</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">reg</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="n">reg_mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">reg_rmse</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">reg_mse</span><span class="p">)</span>
<span class="n">reg_mse</span>
</pre></table></code></div></div><blockquote><p>0.0</p></blockquote><p>RMSE가 0이면 100% 싹다 맞췄다는 얘기이다. 이 점수와 교차 검증 결과인 1248.51을 함께 생각하면 결정 트리가 과대 적합되어 분산이 크다는 것이 확실하다. 훈련 세트는 완벽하게 맞췄지만 테스트 세트에서는 큰 차이가 발생해버린 것이다.</p><p>하이퍼 파라미터는 이런 상황을 바로 잡을 수 있다.</p><h1 id="42-하이퍼-파라미터">4.2 하이퍼 파라미터</h1><hr /><h2 id="max_depth"><span class="mr-2">max_depth</span><a href="#max_depth" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>max_depth는 트리의 깊이를 정의한다. 깊이는 분할 횟수를 결정한다. max_depth의 기본값은 None으로 제한이 없다. 따라서 수백이나 수천번 분할이 일어날 수 있으며 과대적합을 만든다. max_depth를 작은 값으로 제한하면 분산이 줄어들고 모델이 새로운 데이터에 잘 일반화 된다.</p><p>최선의 max_depth를 어떻게 선택할 수 있는가?</p><h2 id="gridsearchcv"><span class="mr-2">GridSearchCV</span><a href="#gridsearchcv" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>GridSearchCV는 교차 검증을 사용해 최선의 결과를 만드는 매개변수 조합을 찾는다.</p><p>GridSearchCV 클래스는 사이킷런의 다른 머신러닝 알고리즘처럼 동작한다. 즉 훈련 세트에서 훈련하고 테스트 세트에서 점수를 계산한다. 다른 모델과 주요한 차이점은 GridSearchCV가 최종모델을 선택하기 전에 모든 매개변수를 검사한다는 점이다.</p><p>GridSearchCV의 핵심은 매개변수 값의 딕셔너리를 정의한다는 것이다. 올바른 조합이란 것은 없다. 한 가지 방법은 가장 작은 값과 갖아 큰 값 사이에서 일정 간격을 선택하는 것이다. 과대적합을 줄여야 하기 때문에 max_depth값을 줄여서 시도해보는 것이 좋다.</p><p>GridSearchCV를 임포트하고 max_depth 파라미터의 리스트를 다음처럼 정의한다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s">'max_depth'</span><span class="p">:</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">]}</span>
</pre></table></code></div></div><blockquote><p>일반적으로 max란 이름이 붙은 매개변수는 감소시키고 min이 붙은 매개변수는 증가시키면 분산이 줄어들고 과대적합이 방지된다</p></blockquote><p>그 다음 DecisionTreeRegressor 객체를 만들고 GridSearchCV에 params 딕셔너리와 평가지표를 함께 전달한다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="n">reg</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1117</span><span class="p">)</span>
<span class="n">grid_reg</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">reg</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'neg_mean_squared_error'</span><span class="p">,</span>
                        <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
												<span class="n">jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># CPU 풀가동
</span><span class="n">grid_reg</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></table></code></div></div><p>데이터를 GridSearchCV에 fitting시켰으므로 이제 최상의 매개변수를 확인한다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">best_params</span> <span class="o">=</span> <span class="n">grid_reg</span><span class="p">.</span><span class="n">best_params_</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="se">\n</span><span class="s">... best params : </span><span class="si">{</span><span class="n">best_params</span><span class="si">}</span><span class="s"> ...</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
</pre></table></code></div></div><blockquote><p>… best params : {‘max_depth’: 8} …</p></blockquote><p>max_depth=8일 때 훈련 세트에서 최상의 교차 검증 점수를 만든다.</p><p>훈련점수는 best_score_에 저장되어 있다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">best_score</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="o">-</span><span class="n">grid_reg</span><span class="p">.</span><span class="n">best_score_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="se">\n</span><span class="s">... train score : </span><span class="si">{</span><span class="n">best_score</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s"> ...</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
</pre></table></code></div></div><blockquote><p>… train score : 821.074 …</p></blockquote><p>테스트 점수는 다음과 같이 출력한다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="n">best_model</span> <span class="o">=</span> <span class="n">grid_reg</span><span class="p">.</span><span class="n">best_estimator_</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>

<span class="n">rmse_test</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">**</span><span class="p">.</span><span class="mi">5</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="se">\n</span><span class="s">... test score : </span><span class="si">{</span><span class="n">rmse_test</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s"> ...</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
</pre></table></code></div></div><blockquote><p>… train score : 821.074 …</p></blockquote><p>1034로 확실히 분산이 줄어들었다.</p><h2 id="min_samples_leaf"><span class="mr-2">min_samples_leaf</span><a href="#min_samples_leaf" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>min_samples_leaf는 리프 노드가 가질 수 있는 최소 샘플의 개수를 제한한다. max_depth와 마찬가지로 min_samples_leaf는 과적합을 방지한다.</p><p>min_samples_leaf의 기본값은 1로 제한이 없을 때 리프 노드는 하나의 샘플로 구성할 수 있다.(과적합되기 쉽다). min_samples_leaf를 증가시키면 분산을 줄일 수 있다. 예를 들어 min_samples_leaf=8 이면 모든 리프 노드는 최소한 8개 이상의 샘플을 담고 있어야 한다.</p><p>min_samples_leaf의 값을 테스트하는 과정은 이전과 동일하다. 복붙을 하는 대신 DecisionTreeRegressor(random_state=1117)를 reg 객체에 할당하고 GridSearchCV르 사용해서 최상의 매개변수, 훈련 점수, 테스트 점수를 출력하는 함수를 작성하였다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">grid_search</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">reg</span><span class="o">=</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1117</span><span class="p">),</span>
                <span class="n">X_train</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="o">=</span><span class="n">y_test</span><span class="p">):</span>
  <span class="n">grid_reg</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">reg</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'neg_mean_squared_error'</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                          <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">grid_reg</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

  <span class="n">best_params</span> <span class="o">=</span> <span class="n">grid_reg</span><span class="p">.</span><span class="n">best_params_</span>
  <span class="n">best_score</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="o">-</span><span class="n">grid_reg</span><span class="p">.</span><span class="n">best_score_</span><span class="p">)</span>
  <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="se">\n</span><span class="s">... best params: </span><span class="si">{</span><span class="n">best_params</span><span class="si">}</span><span class="s"> ...</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
  <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="se">\n</span><span class="s">... train score: </span><span class="si">{</span><span class="n">best_score</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s"> ...</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>

  <span class="n">y_pred</span> <span class="o">=</span> <span class="n">grid_reg</span><span class="p">.</span><span class="n">best_estimator_</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
  <span class="n">rmse_test</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">**</span><span class="p">.</span><span class="mi">5</span>
  <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="se">\n</span><span class="s">... test score: </span><span class="si">{</span><span class="n">rmse_test</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s"> ...</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
</pre></table></code></div></div><p>하이퍼 파라미터의 범위를 선택할 때 훈련 세트의 크기를 아는 것이 도움된다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span>
</pre></table></code></div></div><blockquote><p>… train score : 821.074 …</p></blockquote><p>훈련 세트가 548개 행을 가지고 있기 때문에 적절한 min_samples_leaf 값을 결정할 수 있다. grid_search의 입력으로 [1, 2, 4, 8, 20, 30]을 시도해본다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">grid_search</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s">'min_samples_leaf'</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">]})</span>
</pre></table></code></div></div><blockquote><p>… best params: {‘min_samples_leaf’: 2} …</p><p>… train score: 855.425 …</p><p>… test score: 898.941 …</p></blockquote><p>min_samples_leaf와 max_depth를 같이 넣어보자.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">grid_search</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s">'max_depth'</span><span class="p">:</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span>
                    <span class="s">'min_samples_leaf'</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">]})</span>
</pre></table></code></div></div><blockquote><p>… best params: {‘max_depth’: 8, ‘min_samples_leaf’: 1} …</p><p>… train score: 821.074 …</p><p>… test score: 1034.835 …</p></blockquote><p>어처구니가 없게도 훈련점수는 좋아졌지만 테스트점수는 나빠졌다(과적합).</p><p>이전 예제에서 분산을 줄였던 것처럼 min_samples_leaf를 3보다 크게 설정해보자.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">grid_search</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s">'max_depth'</span><span class="p">:</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
                    <span class="s">'min_samples_leaf'</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">]})</span>
</pre></table></code></div></div><blockquote><p>… best params: {‘max_depth’: 8, ‘min_samples_leaf’: 5} …</p><p>… train score: 849.492 …</p><p>… test score: 793.616 …</p></blockquote><p>결과에서 볼 수 있듯이 테스트 점수가 향상되었다.</p><h2 id="max_leaf_nodes"><span class="mr-2">max_leaf_nodes</span><a href="#max_leaf_nodes" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>max_leaf_nodes는 min_samples_leaf와 비슷하다. 리프 노드 하나당 샘플 개수의 하한을 지정하는 대신, 전체 트리의 리프 노드 개수의 상한을 지정한다. 예를 들어, max_leaf_nodes=10 으로 지정하면 트리 리프 노드가 최대 10개를 넘을 수 없다.</p><h2 id="max_features"><span class="mr-2">max_features</span><a href="#max_features" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>max_features는 분산을 줄이는데 효과적인 매개변수이다. 분할마다 모든 feature를 고려하지 않고 매번 지정된 개수의 feature 중에서 선택한다.</p><p>max_features의 옵션은 다음과 같다.</p><ul><li>None(default)와 ‘auto’는 전체 feature를 사용한다.<li>‘sqrt’는 전체 feature 개수의 제곱근을 사용한다.<li>‘log2’는 전체 log_2(feature 개수)를 사용한다. ex) 전체 feature 개수가 32개 ⇒ 분할 당 5개의 feature만 고려.</ul><h2 id="min_samples_split"><span class="mr-2">min_samples_split</span><a href="#min_samples_split" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>분할을 제한하는 또 다른 방법은 min_samples_split이다. 이름에서 알 수 있듯이 1회 분할하기 위해 필요한 최소 sample 개수를 제한한다. 기본값은 2이다. 예를 들어, 이 값을 5로 설정하면 5개 보다 적은 노드는 더 이상 분할 하지 않는다.</p><h2 id="splitter"><span class="mr-2">splitter</span><a href="#splitter" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>splitter 매개 변수에는 ‘random’과 ‘best’ 두개의 옵션이 있다. 분할기는 노드를 분할하기 위한 feature 선택 방법이다. 기본값은 ‘best’로 정보이득(information gain)이 가장 큰 특성을 선택한다 (criterion으로 지정된 평가지표를 가장 줄이는 feature). 이와 달리 ‘random’은 랜덤하게 노드를 분할한다.</p><p>splitter=’random’으로 하면 과대적합을 막고 다양한 트리를 만드는 효과가 있다.</p><h2 id="criterion"><span class="mr-2">criterion</span><a href="#criterion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>결정 트리 회귀 모델과 분류 모델의 criterion값이 다르다. criterion은 분할 품질을 측정할 수 있는 방법을 제공한다. criterion에 지정한 함수를 가능한 분할마다 계산하여 비교한다. 가장 좋은 점수를 얻은 분할이 선택된다.</p><p>회귀 모델일 경우 ‘squared_error’(평균 제곱 오차), ‘friedman_mse’(프리드만 MSE), ‘absolute error’, ‘poisson’(포이송 편차)가 있다. 기본값은 ‘squared_error’이다.</p><p>분류 모델일 경우 앞서 언급한 ‘gini’(기본값)과 ‘entropy’가 있다. 일반적으로 두 옵션은 비슷한 결과를 만든다.</p><h2 id="min_impurity_decrease"><span class="mr-2">min_impurity_decrease</span><a href="#min_impurity_decrease" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>min_impurity_decrease는 분할하기 위한 최소 불순도 감소를 지정한다.</p><p>불순도는 각 노드의 예측이 얼마나 순수한지를 측정한다. 100%의 정확도를 가진 트리의 불순도는 0.0이다. 80% 정확도를 가진 트리의 평균적인 불순도는 0.20일 것이다.</p><p>불순도는 결정 트리에서 중요한 개념이다. 트리를 성장시키는 과정에서 불순도는 지속적으로 감소되어야 한다. 각 노드에거 가장 크게 불순도를 감소시키는 분할이 선택된다.</p><p>기본값은 0.0이다. 이 값을 증가시키면 임곗값에 도달할 때 트리의 성장이 멈춘다.</p><h2 id="min_weight_fraction_leaf"><span class="mr-2">min_weight_fraction_leaf</span><a href="#min_weight_fraction_leaf" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>min_weight_fraction_leaf는 리프 노드가 되기 위한 전체 가중치의 최소 비율이다. sample_weight를 지정해주지 않으면 샘플은 모두 동일한 가중치를 가진다.</p><p>min_weight_fraction_leaf는 분산을 줄이고 과대적합을 막을 수 있는 또 다른 하이퍼파라미터이다. 기본값은 0.0이다. 500개의 샘플이 있고 가중치가 동일하다면, 이 매개변수를 0.01로 지정할 때 리프 노드가 되기 위한 최소 샘플 개수는 5개이다.</p><h2 id="cca_alpha"><span class="mr-2">cca_alpha</span><a href="#cca_alpha" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>cca_alpha 매개변수는 트리를 만든 후 가지치기(prunning)를 하는 기능으로 여기서 설명하지는 않을 것이다. 자세한 내용은 최소 비용복잡도 가지치기 (minimal cost-complexity prunning)에 대해 알아볼 것.</p><h1 id="43-정리">4.3 정리</h1><hr /><p>하이퍼 파라미터 튜닝을 할 때 몇 가지 고려사항이 있다.</p><ul><li>소요 시간<li>하이퍼파라미터 개수<li>원하는 소수점 정확도</ul><p>소요 시간, 튜닝할 하이퍼 파라미터 개수, 원하는 정확도는 데이터셋과 프로젝트에 따라 다르다. 하이퍼파라미터는 서로 연관되어 있기 때문에 모두 수정할 필요는 없다. 작은 범위에서 튜닝하면 더 좋은 결과를 만들 수 있다.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/xgb-for-gradient-boosting/'>XGB FOR GRADIENT BOOSTING</a>, <a href='/categories/decision-tree/'>DECISION TREE</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/decision-tree/" class="post-tag no-text-decoration" >decision tree</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=4+%EA%B2%B0%EC%A0%95+%ED%8A%B8%EB%A6%AC+%ED%95%98%EC%9D%B4%ED%8D%BC%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0+%ED%8A%9C%EB%8B%9D+-+MNG&url=https%3A%2F%2Fmoongthy.github.io%2Fposts%2Fdthpt%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=4+%EA%B2%B0%EC%A0%95+%ED%8A%B8%EB%A6%AC+%ED%95%98%EC%9D%B4%ED%8D%BC%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0+%ED%8A%9C%EB%8B%9D+-+MNG&u=https%3A%2F%2Fmoongthy.github.io%2Fposts%2Fdthpt%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fmoongthy.github.io%2Fposts%2Fdthpt%2F&text=4+%EA%B2%B0%EC%A0%95+%ED%8A%B8%EB%A6%AC+%ED%95%98%EC%9D%B4%ED%8D%BC%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0+%ED%8A%9C%EB%8B%9D+-+MNG" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div><script src="https://utteranc.es/client.js" repo="Moongthy/Moongthy.github.io" issue-term="pathname" theme="github-dark" crossorigin="anonymous" async> </script></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/fgsm/">적대적 예제의 설명과 활용 (Fast Gradient Sign Method, FGSM) - Ian J.Goodfellow, Jonathan Shelens & Christian Szegedy</a><li><a href="/posts/pgd/">적대적 공격에 저항하는 딥러닝 모델을 향하여 (Towards Deep Learning Models Resistant to Adversarial Attacks - Aleksnader Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, Adrian Vladu)</a><li><a href="/posts/dtoverview/">1 결정 트리 개요</a><li><a href="/posts/dtalg/">2 결정 트리 알고리즘</a><li><a href="/posts/varbias/">3 분산(variance)과 편향(bias)</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/nlp/">nlp</a> <a class="post-tag" href="/tags/decision-tree/">decision tree</a> <a class="post-tag" href="/tags/kaggle/">kaggle</a> <a class="post-tag" href="/tags/bert/">bert</a> <a class="post-tag" href="/tags/gradient-boosting/">gradient boosting</a> <a class="post-tag" href="/tags/random-forest/">random forest</a> <a class="post-tag" href="/tags/transformer/">transformer</a> <a class="post-tag" href="/tags/adversarial-example/">adversarial example</a> <a class="post-tag" href="/tags/decoder/">decoder</a> <a class="post-tag" href="/tags/distillbert/">distillbert</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/dtoverview/"><div class="card-body"> <em class="small" data-ts="1654068600" data-df="ll" > Jun 1, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>1 결정 트리 개요</h3><div class="text-muted small"><p> 앙상블 방법 중 하나인 XGBoost 의 기본학습기(base learner) 로 가장 널리 사용되는 결정 트리는 독특한 특징을 가진 머신러닝 알고리즘이다. 선형 회귀와 로지스틱 회귀 처럼 특성을 가중치와 곱하는 대신 결정 트리는 특성에 대한 질문에 따라 데이터를 나눈다. 사실 결정 트리를 만드는 것은 스무고개 게임을 하는 것과 같다. 예를...</p></div></div></a></div><div class="card"> <a href="/posts/dtalg/"><div class="card-body"> <em class="small" data-ts="1654069500" data-df="ll" > Jun 1, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>2 결정 트리 알고리즘</h3><div class="text-muted small"><p> 결정 트리는 가지(branch) 분할 을 통해 데이터를 두 개의 노드로 나눈다. 가지 분할은 예측을 만드는 리프노드까지 계속된다. 실제 예를 다뤄보면 가지가 분할되는 방법과 리프 노드가 만들어지는 방법을 쉽게 이해할 수 있다. 더 자세한 내용을 살펴보기 전에 첫 번째 결정 트리 모델을 만들어 보자. 2.1 첫 번째 결정 트리 모델 인구 조사...</p></div></div></a></div><div class="card"> <a href="/posts/varbias/"><div class="card-body"> <em class="small" data-ts="1654070400" data-df="ll" > Jun 1, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>3 분산(variance)과 편향(bias)</h3><div class="text-muted small"><p> 다음 그래프에 있는 데이터 포인트를 가지고 있다고 가정하자. 이 데이터에 직선 또는 곡선을 학습시켜 새로운 포인트에 대한 예측을 만들어야 한다. 랜덤한 포인트들의 그래프 3.1 선형 회귀 각 점들과 직선 사이의 거리 제곱을 최소화하는 선형회귀를 사용한다. 직선은 일반적으로 편향이 크다. 머신러닝에서 편향은 모델을 실제 문제에...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/varbias/" class="btn btn-outline-primary" prompt="Older"><p>3 분산(variance)과 편향(bias)</p></a> <a href="/posts/hd/" class="btn btn-outline-primary" prompt="Newer"><p>5 심장 질환 예측하기</p></a></div><script src="https://utteranc.es/client.js" repo="" issue-term="" crossorigin="anonymous" async> </script> <script type="text/javascript"> $(function() { const origin = "https://utteranc.es"; const iframe = "iframe.utterances-frame"; const lightTheme = "github-light"; const darkTheme = "github-dark"; let initTheme = lightTheme; if ($("html[data-mode=dark]").length > 0 || ($("html[data-mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches)) { initTheme = darkTheme; } addEventListener("message", (event) => { let theme; /* credit to <https://github.com/utterance/utterances/issues/170#issuecomment-594036347> */ if (event.origin === origin) { /* page initial */ theme = initTheme; } else if (event.source === window && event.data && event.data.direction === ModeToggle.ID) { /* global theme mode changed */ const mode = event.data.message; theme = (mode === ModeToggle.DARK_MODE ? darkTheme : lightTheme); } else { return; } const message = { type: "set-theme", theme: theme }; const utterances = document.querySelector(iframe).contentWindow; utterances.postMessage(message, origin); }); }); </script></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://twitter.com/username">mng</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/nlp/">nlp</a> <a class="post-tag" href="/tags/decision-tree/">decision tree</a> <a class="post-tag" href="/tags/kaggle/">kaggle</a> <a class="post-tag" href="/tags/bert/">bert</a> <a class="post-tag" href="/tags/gradient-boosting/">gradient boosting</a> <a class="post-tag" href="/tags/random-forest/">random forest</a> <a class="post-tag" href="/tags/transformer/">transformer</a> <a class="post-tag" href="/tags/adversarial-example/">adversarial example</a> <a class="post-tag" href="/tags/decoder/">decoder</a> <a class="post-tag" href="/tags/distillbert/">distillbert</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/en.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script>
