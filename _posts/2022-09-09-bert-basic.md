---
title: BERT의 기본 개념
author: mng
date: 2022-09-09 12:10:00 +0900
categories: [NLP, BERT]
tags: [nlp, bert]
math: true
sitemap :
  priority : 1.0
---

BERT (Bidirectional Encoder Representation from Transformer)는 구글에서 발표한 최신 **임베딩 모델**이다. 질문에 대한 대답, 텍스트 생성, 문장 분류 등과 같은 태스크에서 가장 좋은 성능을 도출해 자연어 처리 분야에 크게 기여했다. BERT가 성공한 주된 이유는 문맥이 없는 워드투벡터와 같은 다른 인기 있는 임베딩 모델과 달리 문맥을 고려한 임베딩 모델이기 때문이다.

먼저 다음 두 문장을 통해 문맥 기반 임베딩 모델과 문맥 독립 임베딩 모델의 차이를 이해해 보자.

> A 문장: He got bit by Pythob (파이썬이 그를 물었다.)
> 

> B 문장: Python is my favorite programming language (내가 가장 좋아하는 프로그래밍 언어는 파이썬이다).
> 

두 문장에서 “파이썬” 이라는 단어의 의미가 서로 다르다는 것을 알 수 있다. A 문장에서 “파이썬”이라는 단어는 뱀의 한 종류를 의미하고 B 문장에서 “파이썬”이라는 단어는 프로그래밍 언어를 의미한다.

워드투벡터와 같은 임베딩 모델을 사용해 앞의 두 문장에서 “파이썬” 이라는 단어에 대한 임베딩을 얻는 경우 두 문장에서 동일한 단어가 쓰였으므로 동일하게 표현하게 된다. 이는 워드투벡터가 문맥 독립 모델이기 때문에 문맥과 관계없이 “파이썬”이라는 단어에 대해 항상 동일한 임베딩을 제공하기 때문이다.

반면 BERT는 문맥기반모델이므로 문장의 문맥을 이해한 다음 문맥에 따라 단어 임베딩을 생성한다. 따라서 앞의 두 문장의 문맥을 기반으로 “파이썬”이라는 단어에 대해 서로 다른 임베딩을 제공한다. 그런데 BERT는 어떻게 작동하는 것일까? 문맥을 어떻게 이해할까? 이에 대해 더 자세히 살펴보자.

A 문장 ( He got bit by Python)을 보자. BERT는 모든 단어와 문맥상 의미를 이해하기 위해 문장의 각 단어를 문장의 다른 모든 단어와 연결시켜 이해한다. 따라서 “파이썬”이라는 단어와 문맥상 의미를 이해하기 위해 문장의 다른 모든 단어와 관계를 기반으로 이해하려 시도한다. 이렇게 하면 BERT는 A 문장의 “파이썬”이라는 단어와 “물었다”라는 단어의 강한 연결 관계를 파악해 “파이썬”이 뱀의 한 종류를 의미한다는 것을 파악하게 된다.

<p>
  <img src="/assets/img/bert/fig2-1.png" alt>
  <em>그림 2-1 파이썬과 다른 모든 단어의 관계</em>
</p>

이제 B 문장 (Python is my favorite programming language)을 보자. 마찬가지로 여기서 BERT는 모든 단어의 문맥상 의미를 이해하기 위해 문장의 각 단어를 문장의 모든 단어와 연결한다. 따라서 BERT는 “파이썬”이라는 단어를 가져와서 이 단어의 의미를 이해하기 위해 문장의 모든 단어와 연결한다. 이렇게 함으로써 BERT는 B문장의 “파이썬”이라는 단어가 “프로그래밍” 이라는 단어와 함께 사용되고 있으므로 프로그래밍 언어와 관련이 있음을 인지하게 된다.

<p>
  <img src="/assets/img/bert/fig2-2.png" alt>
  <em>그림 2-2 파이썬과 다른 모든 단어의 관계</em>
</p>

문맥 독립 모델과 달리 문맥과 관계 없이 정적 임베딩을 생성하는 워드투벡터와 달리 BERT는 문맥을 기반으로 동적 임베딩을 생성한다.
