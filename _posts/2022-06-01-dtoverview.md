---
title: 1 결정 트리 개요
author: mng
date: 2022-06-01 16:30:00 +0900
categories: [XGB FOR GRADIENT BOOSTING, DECISION TREE]
tags: [decision tree]
---
<span style="color:red">
앙상블 방법 중 하나인 XGBoost
</span>
의
<span style="color:red">
기본학습기(base learner)
</span>
로 가장 널리 사용되는 결정 트리는 독특한 특징을 가진 머신러닝 알고리즘이다.
선형 회귀와 로지스틱 회귀 처럼 특성을 가중치와 곱하는 대신 결정 트리는 특성에 대한 질문에 따라 데이터를 나눈다.
사실 결정 트리를 만드는 것은
<span style="color:red">
스무고개
</span>
게임을 하는 것과 같다.

예를 들어, 결정 트리가 온도 특성을 가지고 데이터를 두 그룹으로 나눌 수 있다.
온도가 70도 이상인 그룹과 70도 이하인 그룹이다.
그 다음에는 각 그룹을 계절을 기반으로 나눌 수 있다.
여름인 경우와 그렇지 않은 경우이다.
이제 데이터는 네 개의 그룹으로 나뉘었다.
알고리즘이 일정 수준의 정확도에 도달할 때까지 이렇게 데이터를 새로운 그룹으로 나누는 과정이 계속된다.

결정 트리는 훈련세트에 있는 각 샘플을 정확한 타깃에 매핑할 때까지 수천 개의 그룹을 만들 수 있다.
훈련세트에 대해서는 100% 정확도를 달성한다는 의미이다.
하지만 이런 모델은 새로운 데이터에 잘 일반화되지 못한다.

결정 트리는
<span style="color:red">
과대적합
</span>
되기 쉽다.
다른 말로 하면 결정트리는 훈련 데이터에만 너무 잘 맞을 수 있다.
나중에 분산과 편향을 다룰 때 살펴볼 것이다.
하이퍼 파라미터 튜닝은 과대적합을 막는 한가지 방법이다.
또 다른 방법은
<span style="color:red">
**랜덤 포레스트**
</span>
와 XGBoost가 사용하는 전략으로 많은 트리의 예측을 모으는 것이다.
